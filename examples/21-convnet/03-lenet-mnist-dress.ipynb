{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**классификатор изображений LeNet**\n",
    "\n",
    "Евгений Борисов borisov.e@solarl.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Convolution2D \n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1671)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
    "# https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
    "# https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
    "# https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28), (60000,), (10000, 28, 28), (10000,))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, train_labels.shape, test_images.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_images/255.0\n",
    "X_test = test_images/255.0\n",
    "\n",
    "X_train = X_train[:,:,:,np.newaxis].astype('float32')\n",
    "X_test = X_test[:,:,:,np.newaxis].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape, train_labels.shape, x_test.shape, test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_CLASSES = len(set(train_labels))\n",
    "NB_CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class vectors to binary class matrices\n",
    "y_train = utils.to_categorical(train_labels, NB_CLASSES)\n",
    "y_test = utils.to_categorical(test_labels, NB_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000, 10), (10000, 28, 28, 1), (10000, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_ROWS, IMG_COLS = 28, 28 # input image dimensions\n",
    "INPUT_SHAPE = (IMG_ROWS,IMG_COLS,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimizer and model\n",
    "model = Sequential()\n",
    "# CONV => RELU => POOL\n",
    "model.add(Convolution2D(20, kernel_size=5, padding='same', input_shape=INPUT_SHAPE))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(rate=0.7))\n",
    "# CONV => RELU => POOL\n",
    "model.add(Convolution2D(50, kernel_size=5, padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(rate=0.7))\n",
    "# Flatten => RELU layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(rate=0.7))\n",
    "# a softmax classifier\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 28, 28, 20)        520       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 20)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 20)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 50)        25050     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 14, 14, 50)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 50)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2450)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 500)               1225500   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5010      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,256,080\n",
      "Trainable params: 1,256,080\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss=\"categorical_crossentropy\", optimizer='rmsprop',metrics=[\"accuracy\"])\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='sgd',metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network and training\n",
    "NB_EPOCH = 100\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "VALIDATION_SPLIT=0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 28s 584us/sample - loss: 2.1382 - acc: 0.2123 - val_loss: 1.5738 - val_acc: 0.6168\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 27s 564us/sample - loss: 1.3311 - acc: 0.5126 - val_loss: 0.9118 - val_acc: 0.7103\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 27s 562us/sample - loss: 1.0383 - acc: 0.6162 - val_loss: 0.7869 - val_acc: 0.7300\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 27s 560us/sample - loss: 0.9315 - acc: 0.6541 - val_loss: 0.7307 - val_acc: 0.7485\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 27s 565us/sample - loss: 0.8628 - acc: 0.6825 - val_loss: 0.6984 - val_acc: 0.7488\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 27s 565us/sample - loss: 0.8273 - acc: 0.6933 - val_loss: 0.6783 - val_acc: 0.7573\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 27s 573us/sample - loss: 0.7962 - acc: 0.7048 - val_loss: 0.6456 - val_acc: 0.7652\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 28s 579us/sample - loss: 0.7777 - acc: 0.7092 - val_loss: 0.6367 - val_acc: 0.7673\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 28s 576us/sample - loss: 0.7547 - acc: 0.7191 - val_loss: 0.6257 - val_acc: 0.7776\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 27s 562us/sample - loss: 0.7381 - acc: 0.7237 - val_loss: 0.6142 - val_acc: 0.7757\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 26s 547us/sample - loss: 0.7219 - acc: 0.7313 - val_loss: 0.6009 - val_acc: 0.7768\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 27s 554us/sample - loss: 0.7125 - acc: 0.7344 - val_loss: 0.5990 - val_acc: 0.7801\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 27s 562us/sample - loss: 0.7065 - acc: 0.7355 - val_loss: 0.5887 - val_acc: 0.7849\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 27s 570us/sample - loss: 0.6908 - acc: 0.7411 - val_loss: 0.5831 - val_acc: 0.7907\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 28s 575us/sample - loss: 0.6822 - acc: 0.7456 - val_loss: 0.5774 - val_acc: 0.7959\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 26s 537us/sample - loss: 0.6704 - acc: 0.7490 - val_loss: 0.5637 - val_acc: 0.7973\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 27s 564us/sample - loss: 0.6665 - acc: 0.7506 - val_loss: 0.5609 - val_acc: 0.7956\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 27s 562us/sample - loss: 0.6627 - acc: 0.7521 - val_loss: 0.5567 - val_acc: 0.7970\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 28s 579us/sample - loss: 0.6539 - acc: 0.7558 - val_loss: 0.5542 - val_acc: 0.8032\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 28s 577us/sample - loss: 0.6476 - acc: 0.7575 - val_loss: 0.5450 - val_acc: 0.8034\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 27s 571us/sample - loss: 0.6458 - acc: 0.7585 - val_loss: 0.5488 - val_acc: 0.8043\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 27s 557us/sample - loss: 0.6371 - acc: 0.7610 - val_loss: 0.5414 - val_acc: 0.8108\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 26s 531us/sample - loss: 0.6280 - acc: 0.7648 - val_loss: 0.5376 - val_acc: 0.8132\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 27s 560us/sample - loss: 0.6290 - acc: 0.7657 - val_loss: 0.5323 - val_acc: 0.8139\n",
      "Epoch 25/100\n",
      " 2176/48000 [>.............................] - ETA: 24s - loss: 0.6175 - acc: 0.7790"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=BATCH_SIZE, \n",
    "                    epochs=NB_EPOCH, \n",
    "                    verbose=VERBOSE, \n",
    "                    validation_split=VALIDATION_SPLIT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()   # clear figure\n",
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_names = [ 'T-shirt/top', \n",
    "#                 'Trouser', \n",
    "#                 'Pullover', \n",
    "#                 'Dress', \n",
    "#                 'Coat', \n",
    "#                 'Sandal', \n",
    "#                 'Shirt', \n",
    "#                 'Sneaker', \n",
    "#                 'Bag', \n",
    "#                 'Ankle boot' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [ 'футболка', \n",
    "                'брюки', \n",
    "                'свитер', \n",
    "                'платье', \n",
    "                'пальто', \n",
    "                'сандали', \n",
    "                'рубашка', \n",
    "                'тапки', \n",
    "                'сумка', \n",
    "                'полусапожки' ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = model.predict(X_test)\n",
    "r = np.argmax(p,axis=1)\n",
    "n = test_images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=12\n",
    "\n",
    "f, axarr = plt.subplots( m, m, figsize=(20,20))\n",
    "\n",
    "k=0\n",
    "for j in range(m):\n",
    "    for i in range(m):\n",
    "        k=m*j+i \n",
    "        axarr[i][j].set_title(class_names[r[k]])\n",
    "        axarr[i][j].axes.get_xaxis().set_visible(False)\n",
    "        axarr[i][j].axes.get_yaxis().set_visible(False)\n",
    "        # axarr[i][j].imshow(test_images[k,:,:],cmap=plt.cm.plasma)\n",
    "        axarr[i][j].imshow(test_images[k,:,:],cmap=plt.cm.Greys)\n",
    "                        \n",
    "# plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.5, wspace=0.35)\n",
    "plt.subplots_adjust( top=1.0, hspace=0.5, wspace=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "print('tensorflow:', tf.__version__)\n",
    "print('keras:', keras.__version__)\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print('GPU devices:\\n  ',\n",
    "        [ [x.name, x.physical_device_desc] \n",
    "          for x in device_lib.list_local_devices() \n",
    "          if x.device_type == 'GPU' ]\n",
    "    )\n",
    "    print('default GPU device:', tf.test.gpu_device_name() )\n",
    "\n",
    "else:\n",
    "    print('no GPU device found')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
