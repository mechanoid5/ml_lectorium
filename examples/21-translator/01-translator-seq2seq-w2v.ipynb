{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**автоматический переводчик на основе рекуррентных нейросетей seq2seq**\n",
    "\n",
    "кодируем слова word2vec\n",
    "\n",
    "Евгений Борисов <borisov.e@solarl.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(d): return \"{:,.0f}\".format(d).replace(\",\", \" \")\n",
    "def ppr(d): print('записей:', pp(len(d)) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Учебные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/text/rus-eng/rus.txt.gz','rt',encoding='utf8') as f: \n",
    "    pair = pd.DataFrame([ p.split('\\t') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/text/pairs.txt','rt',encoding='utf8') as f: \n",
    "#     pair = pd.DataFrame([ p.split('%%') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.columns=['Q','A']\n",
    "pair['Q'] = pair['Q'].str.strip()\n",
    "pair['A'] = pair['A'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 336 666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65902</th>\n",
       "      <td>Tom is well dressed.</td>\n",
       "      <td>Том хорошо одет.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146970</th>\n",
       "      <td>We'll meet in the theater.</td>\n",
       "      <td>Увидимся в театре.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74855</th>\n",
       "      <td>I'm still mad at her.</td>\n",
       "      <td>Я всё ещё злюсь на неё.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96207</th>\n",
       "      <td>Does your stomach hurt?</td>\n",
       "      <td>У вас болит желудок?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79379</th>\n",
       "      <td>Tom must be punished.</td>\n",
       "      <td>Том должен быть наказан.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141237</th>\n",
       "      <td>I've tried to contact you.</td>\n",
       "      <td>Я пытался с тобой связаться.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74116</th>\n",
       "      <td>I won't vote for Tom.</td>\n",
       "      <td>Я не буду голосовать за Тома.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316017</th>\n",
       "      <td>Tom fixed the roof of his house just yesterday.</td>\n",
       "      <td>Том только вчера починил крышу своего дома.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70615</th>\n",
       "      <td>Don't leave me alone.</td>\n",
       "      <td>Не оставляйте меня одну.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Q  \\\n",
       "65902                              Tom is well dressed.   \n",
       "146970                       We'll meet in the theater.   \n",
       "74855                             I'm still mad at her.   \n",
       "96207                           Does your stomach hurt?   \n",
       "79379                             Tom must be punished.   \n",
       "141237                       I've tried to contact you.   \n",
       "74116                             I won't vote for Tom.   \n",
       "316017  Tom fixed the roof of his house just yesterday.   \n",
       "70615                             Don't leave me alone.   \n",
       "\n",
       "                                                  A  \n",
       "65902                              Том хорошо одет.  \n",
       "146970                           Увидимся в театре.  \n",
       "74855                       Я всё ещё злюсь на неё.  \n",
       "96207                          У вас болит желудок?  \n",
       "79379                      Том должен быть наказан.  \n",
       "141237                 Я пытался с тобой связаться.  \n",
       "74116                 Я не буду голосовать за Тома.  \n",
       "316017  Том только вчера починил крышу своего дома.  \n",
       "70615                      Не оставляйте меня одну.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppr(pair)\n",
    "pair.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = pair.iloc[100000:110000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистим тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_clean'] = pair['Q'].str.lower()\n",
    "pair['Q_clean'] = pair['Q_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "\n",
    "pair['A_clean'] = pair['A'].str.lower()\n",
    "pair['A_clean'] = pair['A_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'(\\W)', ' \\1 ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\W', ' ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\b\\d+\\b', ' digit ', s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем \"служебные\" слова - начало и конец последовательности\n",
    "pair['Q_clean'] = pair['Q_clean'].str.split() + ['<START>']\n",
    "# выстраиваем входные последовательности в обратном порядке\n",
    "pair['Q_clean'] = pair['Q_clean'].apply(lambda t: [ w for w in reversed(t) if w.strip() ] )\n",
    "\n",
    "pair['A_clean'] = pair['A_clean'].str.split() + ['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_clean</th>\n",
       "      <th>A_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107584</th>\n",
       "      <td>[&lt;START&gt;, ., butterfingers, have, you]</td>\n",
       "      <td>[у, тебя, обе, руки, левые, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108058</th>\n",
       "      <td>[&lt;START&gt;, ., time, my, wasting, you're]</td>\n",
       "      <td>[ты, зря, тратишь, моё, время, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106864</th>\n",
       "      <td>[&lt;START&gt;, ?, from, come, you, do, where]</td>\n",
       "      <td>[откуда, ты, ?, &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108182</th>\n",
       "      <td>[&lt;START&gt;, ., harp, playing, is, child, a]</td>\n",
       "      <td>[ребёнок, играет, на, арфе, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106362</th>\n",
       "      <td>[&lt;START&gt;, !, is, that, dog, big, a, what]</td>\n",
       "      <td>[какая, большая, собака, !, &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106143</th>\n",
       "      <td>[&lt;START&gt;, ., house, tom's, to, went, we]</td>\n",
       "      <td>[мы, пошли, в, дом, тома, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101128</th>\n",
       "      <td>[&lt;START&gt;, ., contagious, is, laughter]</td>\n",
       "      <td>[смех, заразителен, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106968</th>\n",
       "      <td>[&lt;START&gt;, ?, to, it, give, you, did, who]</td>\n",
       "      <td>[кому, вы, его, дали, ?, &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109986</th>\n",
       "      <td>[&lt;START&gt;, ., plan, our, to, objected, he]</td>\n",
       "      <td>[он, возражает, против, нашего, плана, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Q_clean  \\\n",
       "107584     [<START>, ., butterfingers, have, you]   \n",
       "108058    [<START>, ., time, my, wasting, you're]   \n",
       "106864   [<START>, ?, from, come, you, do, where]   \n",
       "108182  [<START>, ., harp, playing, is, child, a]   \n",
       "106362  [<START>, !, is, that, dog, big, a, what]   \n",
       "106143   [<START>, ., house, tom's, to, went, we]   \n",
       "101128     [<START>, ., contagious, is, laughter]   \n",
       "106968  [<START>, ?, to, it, give, you, did, who]   \n",
       "109986  [<START>, ., plan, our, to, objected, he]   \n",
       "\n",
       "                                                 A_clean  \n",
       "107584             [у, тебя, обе, руки, левые, ., <EOS>]  \n",
       "108058          [ты, зря, тратишь, моё, время, ., <EOS>]  \n",
       "106864                            [откуда, ты, ?, <EOS>]  \n",
       "108182             [ребёнок, играет, на, арфе, ., <EOS>]  \n",
       "106362                [какая, большая, собака, !, <EOS>]  \n",
       "106143               [мы, пошли, в, дом, тома, ., <EOS>]  \n",
       "101128                     [смех, заразителен, ., <EOS>]  \n",
       "106968                   [кому, вы, его, дали, ?, <EOS>]  \n",
       "109986  [он, возражает, против, нашего, плана, ., <EOS>]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len_a_max = pair['A_clean'].str.len().max()\n",
    "sent_len_q_max = pair['Q_clean'].str.len().max()\n",
    "\n",
    "sent_len_a_max,sent_len_q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выравниваем длинну последовательностей,\n",
    "# дополняем короткие словом \"служебным\" словом PAD\n",
    "pair['Q_clean'] = pair['Q_clean'].apply( lambda t: ['<PAD>']*(sent_len_q_max-len(t)) + t )\n",
    "pair['A_clean'] = pair['A_clean'].apply( lambda t: t+['<PAD>']*(sent_len_a_max-len(t)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_clean</th>\n",
       "      <th>A_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104811</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., around, mary, pushes, tom]</td>\n",
       "      <td>[том, помыкает, мэри, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100075</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., later, you, to, talk, i'll]</td>\n",
       "      <td>[я, поговорю, с, вами, позже, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106617</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ?, drinking, you, were, what]</td>\n",
       "      <td>[что, вы, пили, ?, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102727</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., bad, stayed, weather, the]</td>\n",
       "      <td>[погода, оставалась, плохая, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108414</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ?, all, that's, sure, you, are]</td>\n",
       "      <td>[ты, уверен, ,, что, это, всё, ?, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107741</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., awake, stay, to, need, you]</td>\n",
       "      <td>[ты, должен, бодрствовать, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101686</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., bottle, the, open, please]</td>\n",
       "      <td>[откройте, бутылку, ,, пожалуйста, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109955</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., sweet, anything, likes, he]</td>\n",
       "      <td>[ему, нравится, всё, сладкое, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109214</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ?, die, to, deserve, tom, does]</td>\n",
       "      <td>[том, заслуживает, смерти, ?, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                              Q_clean  \\\n",
       "104811   [<PAD>, <PAD>, <PAD>, <START>, ., around, mary, pushes, tom]   \n",
       "100075         [<PAD>, <PAD>, <START>, ., later, you, to, talk, i'll]   \n",
       "106617   [<PAD>, <PAD>, <PAD>, <START>, ?, drinking, you, were, what]   \n",
       "102727   [<PAD>, <PAD>, <PAD>, <START>, ., bad, stayed, weather, the]   \n",
       "108414        [<PAD>, <PAD>, <START>, ?, all, that's, sure, you, are]   \n",
       "107741         [<PAD>, <PAD>, <START>, ., awake, stay, to, need, you]   \n",
       "101686   [<PAD>, <PAD>, <PAD>, <START>, ., bottle, the, open, please]   \n",
       "109955  [<PAD>, <PAD>, <PAD>, <START>, ., sweet, anything, likes, he]   \n",
       "109214        [<PAD>, <PAD>, <START>, ?, die, to, deserve, tom, does]   \n",
       "\n",
       "                                                                                        A_clean  \n",
       "104811         [том, помыкает, мэри, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "100075               [я, поговорю, с, вами, позже, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "106617               [что, вы, пили, ?, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "102727  [погода, оставалась, плохая, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "108414                     [ты, уверен, ,, что, это, всё, ?, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "107741    [ты, должен, бодрствовать, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "101686   [откройте, бутылку, ,, пожалуйста, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "109955        [ему, нравится, всё, сладкое, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "109214    [том, заслуживает, смерти, ?, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.23 s, sys: 36.6 ms, total: 1.27 s\n",
      "Wall time: 1.32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "w2v_size = 256\n",
    "\n",
    "w2v_q = Word2Vec( pair['Q_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)\n",
    "w2v_a = Word2Vec( pair['A_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_code'] = pair['Q_clean'].apply(lambda t: [ w2v_q.wv.get_vector(w) for w in t ] )\n",
    "pair['A_code'] = pair['A_clean'].apply(lambda t: [ w2v_a.wv.get_vector(w) for w in t ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = pair.sample(1000)\n",
    "# pair = pair.sample(283800)\n",
    "# pair = pair.sample(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 9, 256), (10000, 11, 256), (10000, 12, 256))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data = np.stack( pair['Q_code'].values ).astype(np.float32)\n",
    "\n",
    "decoder_input_data  = np.stack( pair['A_code'].values )[:,:-1,:].astype(np.float32)\n",
    "#decoder_target_data = np.stack( pair['A_code'].values )[:,1:,:].astype(np.float32)\n",
    "decoder_target_data = np.stack( pair['A_code'].values ).astype(np.float32)\n",
    "\n",
    "encoder_input_data.shape, decoder_input_data.shape, decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.abs(encoder_input_data).max(), \n",
    "act_fact = np.ceil(np.abs(decoder_input_data).max())\n",
    "act_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.layers import Reshape\n",
    "\n",
    "from tensorflow.keras.layers import concatenate \n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256  # размер сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, w2v_size))\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.expand_dims(encoder_outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,w2v_size))\n",
    "decoder_inputs = concatenate([ K.expand_dims(encoder_outputs,1), decoder_inputs],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_4:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm( decoder_inputs, initial_state=encoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_3/transpose_1:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(x):  return K.tanh(x)*act_fact\n",
    "\n",
    "decoder_dense = Dense(w2v_size, activation=custom_activation)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/mul:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tf.Tensor 'dense_1/mul:0' shape=(?, ?, 256) dtype=float32>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=50,\n",
    "          epochs=10,\n",
    "          validation_split=0.1\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверяем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # генерируем состояние энкодера\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # вход декодера - последовательность из одного слова GO\n",
    "    output_w2v = w2v_a.wv['<GO>'].reshape([1,1,w2v_size])\n",
    "\n",
    "    # выходная последовательность\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    for i in range(sent_len_a_max): \n",
    "        output_w2v, h, c = decoder_model.predict([output_w2v] + states_value)\n",
    "\n",
    "        # декодируем cлово\n",
    "        cc = output_w2v.reshape(w2v_size)\n",
    "        w = w2v_a.wv.similar_by_vector(cc)[0][0] \n",
    "        \n",
    "        # если очередное слово это EOS\n",
    "        if(w=='<EOS>'): break # то завершаем работу\n",
    "\n",
    "        decoded_sentence.append(w)\n",
    "       \n",
    "        states_value = [h,c] # обновляем состояние сети\n",
    "\n",
    "    return ' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = np.random.permutation(len(encoder_input_data))[:10]\n",
    "for seq_index in ii:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print( pair.iloc[seq_index]['Q'],' -> ', decoded_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['acc']\n",
    "#val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()   # clear figure\n",
    "# acc_values = history_dict['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "# plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tensorflow:', tf.__version__)\n",
    "print('keras:', keras.__version__)\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print('GPU devices:\\n  ',\n",
    "        [ [x.name, x.physical_device_desc] \n",
    "          for x in device_lib.list_local_devices() \n",
    "          if x.device_type == 'GPU' ]\n",
    "    )\n",
    "    print('default GPU device:', tf.test.gpu_device_name() )\n",
    "\n",
    "else:\n",
    "    print('no GPU device found')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_q_vocab = sorted([w for w in w2v_q.wv.vocab])\n",
    "# ppr(w2v_q_vocab)\n",
    "# w2v_a_vocab = sorted([w for w in w2v_a.wv.vocab])\n",
    "# ppr(w2v_a_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii = np.random.permutation(len(w2v_q_vocab))[:10]\n",
    "# for i in ii:\n",
    "#     w = w2v_q_vocab[i]\n",
    "#     ww = [ v[0] for v in w2v_q.wv.most_similar(w, topn=5) ]\n",
    "#     print( w,':',ww )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii = np.random.permutation(len(w2v_a_vocab))[:10]\n",
    "# for i in ii:\n",
    "#     w = w2v_a_vocab[i]\n",
    "#     ww = [ v[0] for v in w2v_a.wv.most_similar(w, topn=5) ]\n",
    "#     print( w,':',ww )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = Input(shape=(16,))\n",
    "# x1 = Dense(8, activation='relu')(input1)\n",
    "#\n",
    "# input2 = Input(shape=(32,))\n",
    "# x2 = Dense(8, activation='relu')(input2)\n",
    "# added = add([x1, x2])\n",
    "#\n",
    "# out = Dense(4)(added)\n",
    "# model = Model( inputs=[input1, input2], outputs=out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1  x2  x3\n",
    "#  \\  /   /\n",
    "#   y1   /\n",
    "#    \\  /\n",
    "#     y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = Sequential()\n",
    "# first.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n",
    "\n",
    "# second = Sequential()\n",
    "# second.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "# third = Sequential()\n",
    "# # of course you must provide the input to result with will be your x3\n",
    "# third.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "# # lets say you add a few more layers to first and second.\n",
    "# # concatenate them\n",
    "# merged = Concatenate([first, second])\n",
    "\n",
    "# # then concatenate the two outputs\n",
    "\n",
    "# result = Concatenate([merged,  third])\n",
    "\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# result.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "# from keras.optimizers import Adagrad\n",
    "\n",
    "# first_input = Input(shape=(2, ))\n",
    "# first_dense = Dense(1, )(first_input)\n",
    "\n",
    "# second_input = Input(shape=(2, ))\n",
    "# second_dense = Dense(1, )(second_input)\n",
    "\n",
    "# merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "# third_input = Input(shape=(1, ))\n",
    "# merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "# model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "# model.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = Input(shape=(None, w2v_size))\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge( [ UpSampling2D(size=(2,2), dim_ordering=\"th\")(conv5), conv4], mode='concat', concat_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1  x2  x3\n",
    "#  \\  /   /\n",
    "#   y1   /\n",
    "#    \\  /\n",
    "#     y2\n",
    "#\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import concatenate\n",
    "# from keras.optimizers import Adagrad\n",
    "\n",
    "# first_input = Input(shape=(2, ))\n",
    "# first_dense = Dense(1, )(first_input)\n",
    "\n",
    "# second_input = Input(shape=(2, ))\n",
    "# second_dense = Dense(1, )(second_input)\n",
    "\n",
    "# merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "# third_input = Input(shape=(1, ))\n",
    "# merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "# model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "# model.compile(optimizer=ada_grad, loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import *\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(100,), dtype='int32', name='input_2D')\n",
    "# input_2D_repeat = RepeatVector(K.shape(input_3D)[1])(input_2D)\n",
    "# merged = Concatenate(axis=1)([input_3D, input_2D_repeat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import *\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(100,), dtype='int32', name='input_2D')\n",
    "# input_2D_repeat = RepeatVector(K.shape(input_3D)[1])(input_2D)\n",
    "# merged = concatenate([input_3D, input_2D_repeat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import Input, Lambda\n",
    "# import keras.backend as K\n",
    "\n",
    "# def repeat_and_concatenate(inputs):\n",
    "#     input_3D, input_2D = inputs\n",
    "#     # Repeat 2D vectors\n",
    "#     input_2D_repeat = K.tile(K.expand_dims(input_2D, 1), [1, K.shape(input_3D)[1], 1])\n",
    "#     # Concatenate feature-wise\n",
    "#     return K.concatenate([input_3D, input_2D_repeat], axis=-1)\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(50,), dtype='int32', name='input_2D')\n",
    "# merged = Lambda(repeat_and_concatenate)([input_3D, input_2D])\n",
    "# print(merged)\n",
    "# # Tensor(\"lambda_1/concat:0\", shape=(?, ?, 150), dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "\n",
    "# decoder_inputs = Input(shape=(None, w2v_size))\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "# # FIXME к данным добавить выход энкодера\n",
    "\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "\n",
    "# # decoder_dense = Dense(w2v_size)\n",
    "# # decoder_dense = Dense(w2v_size, activation='softmax')\n",
    "# # decoder_dense = Dense(w2v_size, activation='tanh')\n",
    "# # decoder_dense = Dense(w2v_size, activation='sigmoid')\n",
    "# decoder_dense = Dense(w2v_size, activation=custom_activation)\n",
    "\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
