{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**автоматический переводчик на основе рекуррентных нейросетей seq2seq**\n",
    "\n",
    "кодируем слова word2vec\n",
    "\n",
    "Евгений Борисов <borisov.e@solarl.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(d): return \"{:,.0f}\".format(d).replace(\",\", \" \")\n",
    "def ppr(d): print('записей:', pp(len(d)) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Учебные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/text/rus-eng/rus.txt.gz','rt',encoding='utf8') as f: \n",
    "    pair = pd.DataFrame([ p.split('\\t') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/text/pairs.txt','rt',encoding='utf8') as f: \n",
    "#     pair = pd.DataFrame([ p.split('%%') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.columns=['Q','A']\n",
    "pair['Q'] = pair['Q'].str.strip()\n",
    "pair['A'] = pair['A'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 336 666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>212608</th>\n",
       "      <td>Tom decided to call the police.</td>\n",
       "      <td>Том решил вызвать полицию.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184723</th>\n",
       "      <td>Tell me what happened to you.</td>\n",
       "      <td>Расскажи мне, что с тобой случилось.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226111</th>\n",
       "      <td>Tom said he was unlikely to win.</td>\n",
       "      <td>Том сказал, что вряд ли выиграет.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301844</th>\n",
       "      <td>I don't know why I bother repeating myself.</td>\n",
       "      <td>Не знаю, зачем я утруждаюсь повторением своих слов.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132647</th>\n",
       "      <td>Tom was three hours late.</td>\n",
       "      <td>Том опоздал на три часа.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82107</th>\n",
       "      <td>You have to stop Tom.</td>\n",
       "      <td>Ты должен остановить Тома.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232881</th>\n",
       "      <td>I was hoping you'd be here today.</td>\n",
       "      <td>Я надеялась, что ты сегодня будешь здесь.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145219</th>\n",
       "      <td>Tom isn't quite ready yet.</td>\n",
       "      <td>Том ещё не совсем готов.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160489</th>\n",
       "      <td>Tom will lend you his book.</td>\n",
       "      <td>Том одолжит вам свою книгу.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Q  \\\n",
       "212608              Tom decided to call the police.   \n",
       "184723                Tell me what happened to you.   \n",
       "226111             Tom said he was unlikely to win.   \n",
       "301844  I don't know why I bother repeating myself.   \n",
       "132647                    Tom was three hours late.   \n",
       "82107                         You have to stop Tom.   \n",
       "232881            I was hoping you'd be here today.   \n",
       "145219                   Tom isn't quite ready yet.   \n",
       "160489                  Tom will lend you his book.   \n",
       "\n",
       "                                                          A  \n",
       "212608                           Том решил вызвать полицию.  \n",
       "184723                 Расскажи мне, что с тобой случилось.  \n",
       "226111                    Том сказал, что вряд ли выиграет.  \n",
       "301844  Не знаю, зачем я утруждаюсь повторением своих слов.  \n",
       "132647                             Том опоздал на три часа.  \n",
       "82107                            Ты должен остановить Тома.  \n",
       "232881            Я надеялась, что ты сегодня будешь здесь.  \n",
       "145219                             Том ещё не совсем готов.  \n",
       "160489                          Том одолжит вам свою книгу.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppr(pair)\n",
    "pair.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = pair.iloc[100000:110000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистим тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_clean'] = pair['Q'].str.lower()\n",
    "pair['Q_clean'] = pair['Q_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "\n",
    "pair['A_clean'] = pair['A'].str.lower()\n",
    "pair['A_clean'] = pair['A_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'(\\W)', ' \\1 ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\W', ' ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\b\\d+\\b', ' digit ', s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем \"служебные\" слова - начало и конец последовательности\n",
    "pair['Q_clean'] = pair['Q_clean'].str.split() + ['<START>']\n",
    "# выстраиваем входные последовательности в обратном порядке\n",
    "pair['Q_clean'] = pair['Q_clean'].apply(lambda t: [ w for w in reversed(t) if w.strip() ] )\n",
    "\n",
    "pair['A_clean'] = pair['A_clean'].str.split() + ['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_clean</th>\n",
       "      <th>A_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109968</th>\n",
       "      <td>[&lt;START&gt;, ., sky, the, at, up, looked, he]</td>\n",
       "      <td>[он, посмотрел, вверх, на, небо, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109486</th>\n",
       "      <td>[&lt;START&gt;, ., that, doing, is, everybody]</td>\n",
       "      <td>[все, это, делают, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103095</th>\n",
       "      <td>[&lt;START&gt;, ., fake, obviously, is, this]</td>\n",
       "      <td>[это, очевидная, подделка, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103906</th>\n",
       "      <td>[&lt;START&gt;, ., eyes, blue, ,, big, has, tom]</td>\n",
       "      <td>[у, тома, большие, голубые, глаза, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105827</th>\n",
       "      <td>[&lt;START&gt;, ., right, always, aren't, we]</td>\n",
       "      <td>[мы, не, всегда, правы, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100254</th>\n",
       "      <td>[&lt;START&gt;, ., both, you, for, happy, i'm]</td>\n",
       "      <td>[счастлива, за, вас, обеих, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101551</th>\n",
       "      <td>[&lt;START&gt;, ., truth, the, knows, nobody]</td>\n",
       "      <td>[никто, не, знает, правды, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103624</th>\n",
       "      <td>[&lt;START&gt;, ., reply, a, get, didn't, tom]</td>\n",
       "      <td>[ответа, том, не, получил, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107560</th>\n",
       "      <td>[&lt;START&gt;, ., know, to, want, don't, you]</td>\n",
       "      <td>[лучше, тебе, об, этом, не, знать, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Q_clean  \\\n",
       "109968  [<START>, ., sky, the, at, up, looked, he]   \n",
       "109486    [<START>, ., that, doing, is, everybody]   \n",
       "103095     [<START>, ., fake, obviously, is, this]   \n",
       "103906  [<START>, ., eyes, blue, ,, big, has, tom]   \n",
       "105827     [<START>, ., right, always, aren't, we]   \n",
       "100254    [<START>, ., both, you, for, happy, i'm]   \n",
       "101551     [<START>, ., truth, the, knows, nobody]   \n",
       "103624    [<START>, ., reply, a, get, didn't, tom]   \n",
       "107560    [<START>, ., know, to, want, don't, you]   \n",
       "\n",
       "                                             A_clean  \n",
       "109968    [он, посмотрел, вверх, на, небо, ., <EOS>]  \n",
       "109486                  [все, это, делают, ., <EOS>]  \n",
       "103095          [это, очевидная, подделка, ., <EOS>]  \n",
       "103906  [у, тома, большие, голубые, глаза, ., <EOS>]  \n",
       "105827             [мы, не, всегда, правы, ., <EOS>]  \n",
       "100254         [счастлива, за, вас, обеих, ., <EOS>]  \n",
       "101551          [никто, не, знает, правды, ., <EOS>]  \n",
       "103624          [ответа, том, не, получил, ., <EOS>]  \n",
       "107560  [лучше, тебе, об, этом, не, знать, ., <EOS>]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len_a_max = pair['A_clean'].str.len().max()\n",
    "sent_len_q_max = pair['Q_clean'].str.len().max()\n",
    "\n",
    "sent_len_a_max,sent_len_q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выравниваем длинну последовательностей,\n",
    "# дополняем короткие словом \"служебным\" словом PAD\n",
    "pair['Q_clean'] = pair['Q_clean'].apply( lambda t: ['<PAD>']*(sent_len_q_max-len(t)) + t )\n",
    "pair['A_clean'] = pair['A_clean'].apply( lambda t: t+['<PAD>']*(sent_len_a_max-len(t)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_clean</th>\n",
       "      <th>A_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108623</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ?, window, the, open, you, can]</td>\n",
       "      <td>[можешь, открыть, окно, ?, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104255</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., thought, in, lost, is, tom]</td>\n",
       "      <td>[том, в, глубокой, задумчивости, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103130</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;START&gt;, ., him, hate, i, why, is, this]</td>\n",
       "      <td>[вот, за, что, я, его, ненавижу, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109562</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., me, contact, to, free, feel]</td>\n",
       "      <td>[не, стесняйтесь, обращаться, ко, мне, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108848</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ?, night, last, work, you, did]</td>\n",
       "      <td>[вчера, вечером, ты, работала, ?, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103829</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;START&gt;, ., bee, a, by, stung, got, tom]</td>\n",
       "      <td>[тома, ужалила, пчела, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105743</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;START&gt;, ?, think, you, do, what, ,, tom]</td>\n",
       "      <td>[том, ,, что, ты, думаешь, ?, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102293</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., correct, almost, is, that]</td>\n",
       "      <td>[это, почти, верно, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105806</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., you, missed, have, all, we]</td>\n",
       "      <td>[мы, все, по, вам, скучали, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                             Q_clean  \\\n",
       "108623       [<PAD>, <PAD>, <START>, ?, window, the, open, you, can]   \n",
       "104255        [<PAD>, <PAD>, <START>, ., thought, in, lost, is, tom]   \n",
       "103130              [<PAD>, <START>, ., him, hate, i, why, is, this]   \n",
       "109562       [<PAD>, <PAD>, <START>, ., me, contact, to, free, feel]   \n",
       "108848       [<PAD>, <PAD>, <START>, ?, night, last, work, you, did]   \n",
       "103829              [<PAD>, <START>, ., bee, a, by, stung, got, tom]   \n",
       "105743             [<PAD>, <START>, ?, think, you, do, what, ,, tom]   \n",
       "102293  [<PAD>, <PAD>, <PAD>, <START>, ., correct, almost, is, that]   \n",
       "105806        [<PAD>, <PAD>, <START>, ., you, missed, have, all, we]   \n",
       "\n",
       "                                                                                     A_clean  \n",
       "108623    [можешь, открыть, окно, ?, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "104255  [том, в, глубокой, задумчивости, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "103130                [вот, за, что, я, его, ненавижу, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "109562   [не, стесняйтесь, обращаться, ко, мне, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "108848    [вчера, вечером, ты, работала, ?, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "103829     [тома, ужалила, пчела, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "105743               [том, ,, что, ты, думаешь, ?, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "102293        [это, почти, верно, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "105806              [мы, все, по, вам, скучали, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 51 ms, total: 1.14 s\n",
      "Wall time: 674 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "w2v_size = 256\n",
    "\n",
    "w2v_q = Word2Vec( pair['Q_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)\n",
    "w2v_a = Word2Vec( pair['A_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_code'] = pair['Q_clean'].apply(lambda t: [ w2v_q.wv.get_vector(w) for w in t ] )\n",
    "pair['A_code'] = pair['A_clean'].apply(lambda t: [ w2v_a.wv.get_vector(w) for w in t ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = pair.sample(1000)\n",
    "# pair = pair.sample(283800)\n",
    "# pair = pair.sample(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.stack( pair['Q_code'].values ).astype(np.float32)\n",
    "\n",
    "decoder_input_data  = np.stack( pair['A_code'].values )[:,:-1,:].astype(np.float32)\n",
    "\n",
    "#decoder_target_data = np.stack( pair['A_code'].values )[:,1:,:].astype(np.float32)\n",
    "decoder_target_data = np.stack( pair['A_code'].values ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 9, 256), (10000, 11, 256), (10000, 12, 256))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape, decoder_input_data.shape, decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.abs(encoder_input_data).max(), \n",
    "act_fact = np.ceil(np.abs(decoder_input_data).max())\n",
    "act_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from tensorflow.keras.layers import Reshape\n",
    "from tensorflow.keras.layers import Concatenate \n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256  # размер сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = Input(shape=(None, w2v_size))\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "encoder_outputs = encoder(encoder_inputs)\n",
    "encoder_states = encoder_outputs[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.expand_dims(encoder_outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,w2v_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_inputs = concatenate([ K.expand_dims(encoder_outputs,1), decoder_inputs],axis=1)\n",
    "decoder_concat_inputs = Concatenate(axis=1)([K.expand_dims(encoder_outputs[0],1), decoder_inputs])\n",
    "# decoder_inputs = Concatenate(axis=1)([encoder_outputs, decoder_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_5/concat:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_concat_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm( decoder_concat_inputs, initial_state=encoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_4/transpose_1:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(x):  return K.tanh(x)*act_fact\n",
    "\n",
    "decoder_dense = Dense(w2v_size, activation=custom_activation)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_2/mul:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tf.Tensor 'dense_1/mul:0' shape=(?, ?, 256) dtype=float32>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(\"dense_2/mul:0\", shape=(?, ?, 256), dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d6d569112c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;31m# Create a cache for iterator get_next op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_get_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWeakKeyDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m         'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     80\u001b[0m       \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m       \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_graph_inputs_and_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_validate_graph_inputs_and_outputs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1671\u001b[0m         raise ValueError('Output tensors to a ' + cls_name + ' must be '\n\u001b[1;32m   1672\u001b[0m                          \u001b[0;34m'the output of a TensorFlow `Layer` '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m                          '(thus holding past layer metadata). Found: ' + str(x))\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Output tensors to a Model must be the output of a TensorFlow `Layer` (thus holding past layer metadata). Found: Tensor(\"dense_2/mul:0\", shape=(?, ?, 256), dtype=float32)"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=50,\n",
    "          epochs=10,\n",
    "          validation_split=0.1\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверяем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # генерируем состояние энкодера\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # вход декодера - последовательность из одного слова GO\n",
    "    output_w2v = w2v_a.wv['<GO>'].reshape([1,1,w2v_size])\n",
    "\n",
    "    # выходная последовательность\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    for i in range(sent_len_a_max): \n",
    "        output_w2v, h, c = decoder_model.predict([output_w2v] + states_value)\n",
    "\n",
    "        # декодируем cлово\n",
    "        cc = output_w2v.reshape(w2v_size)\n",
    "        w = w2v_a.wv.similar_by_vector(cc)[0][0] \n",
    "        \n",
    "        # если очередное слово это EOS\n",
    "        if(w=='<EOS>'): break # то завершаем работу\n",
    "\n",
    "        decoded_sentence.append(w)\n",
    "       \n",
    "        states_value = [h,c] # обновляем состояние сети\n",
    "\n",
    "    return ' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = np.random.permutation(len(encoder_input_data))[:10]\n",
    "for seq_index in ii:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print( pair.iloc[seq_index]['Q'],' -> ', decoded_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['acc']\n",
    "#val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()   # clear figure\n",
    "# acc_values = history_dict['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "# plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tensorflow:', tf.__version__)\n",
    "print('keras:', keras.__version__)\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print('GPU devices:\\n  ',\n",
    "        [ [x.name, x.physical_device_desc] \n",
    "          for x in device_lib.list_local_devices() \n",
    "          if x.device_type == 'GPU' ]\n",
    "    )\n",
    "    print('default GPU device:', tf.test.gpu_device_name() )\n",
    "\n",
    "else:\n",
    "    print('no GPU device found')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_q_vocab = sorted([w for w in w2v_q.wv.vocab])\n",
    "# ppr(w2v_q_vocab)\n",
    "# w2v_a_vocab = sorted([w for w in w2v_a.wv.vocab])\n",
    "# ppr(w2v_a_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii = np.random.permutation(len(w2v_q_vocab))[:10]\n",
    "# for i in ii:\n",
    "#     w = w2v_q_vocab[i]\n",
    "#     ww = [ v[0] for v in w2v_q.wv.most_similar(w, topn=5) ]\n",
    "#     print( w,':',ww )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii = np.random.permutation(len(w2v_a_vocab))[:10]\n",
    "# for i in ii:\n",
    "#     w = w2v_a_vocab[i]\n",
    "#     ww = [ v[0] for v in w2v_a.wv.most_similar(w, topn=5) ]\n",
    "#     print( w,':',ww )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = Input(shape=(16,))\n",
    "# x1 = Dense(8, activation='relu')(input1)\n",
    "#\n",
    "# input2 = Input(shape=(32,))\n",
    "# x2 = Dense(8, activation='relu')(input2)\n",
    "# added = add([x1, x2])\n",
    "#\n",
    "# out = Dense(4)(added)\n",
    "# model = Model( inputs=[input1, input2], outputs=out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1  x2  x3\n",
    "#  \\  /   /\n",
    "#   y1   /\n",
    "#    \\  /\n",
    "#     y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = Sequential()\n",
    "# first.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n",
    "\n",
    "# second = Sequential()\n",
    "# second.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "# third = Sequential()\n",
    "# # of course you must provide the input to result with will be your x3\n",
    "# third.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "# # lets say you add a few more layers to first and second.\n",
    "# # concatenate them\n",
    "# merged = Concatenate([first, second])\n",
    "\n",
    "# # then concatenate the two outputs\n",
    "\n",
    "# result = Concatenate([merged,  third])\n",
    "\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# result.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "# from keras.optimizers import Adagrad\n",
    "\n",
    "# first_input = Input(shape=(2, ))\n",
    "# first_dense = Dense(1, )(first_input)\n",
    "\n",
    "# second_input = Input(shape=(2, ))\n",
    "# second_dense = Dense(1, )(second_input)\n",
    "\n",
    "# merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "# third_input = Input(shape=(1, ))\n",
    "# merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "# model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "# model.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = Input(shape=(None, w2v_size))\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge( [ UpSampling2D(size=(2,2), dim_ordering=\"th\")(conv5), conv4], mode='concat', concat_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1  x2  x3\n",
    "#  \\  /   /\n",
    "#   y1   /\n",
    "#    \\  /\n",
    "#     y2\n",
    "#\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import concatenate\n",
    "# from keras.optimizers import Adagrad\n",
    "\n",
    "# first_input = Input(shape=(2, ))\n",
    "# first_dense = Dense(1, )(first_input)\n",
    "\n",
    "# second_input = Input(shape=(2, ))\n",
    "# second_dense = Dense(1, )(second_input)\n",
    "\n",
    "# merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "# third_input = Input(shape=(1, ))\n",
    "# merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "# model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "# model.compile(optimizer=ada_grad, loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import *\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(100,), dtype='int32', name='input_2D')\n",
    "# input_2D_repeat = RepeatVector(K.shape(input_3D)[1])(input_2D)\n",
    "# merged = Concatenate(axis=1)([input_3D, input_2D_repeat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import *\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(100,), dtype='int32', name='input_2D')\n",
    "# input_2D_repeat = RepeatVector(K.shape(input_3D)[1])(input_2D)\n",
    "# merged = concatenate([input_3D, input_2D_repeat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import Input, Lambda\n",
    "# import keras.backend as K\n",
    "\n",
    "# def repeat_and_concatenate(inputs):\n",
    "#     input_3D, input_2D = inputs\n",
    "#     # Repeat 2D vectors\n",
    "#     input_2D_repeat = K.tile(K.expand_dims(input_2D, 1), [1, K.shape(input_3D)[1], 1])\n",
    "#     # Concatenate feature-wise\n",
    "#     return K.concatenate([input_3D, input_2D_repeat], axis=-1)\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(50,), dtype='int32', name='input_2D')\n",
    "# merged = Lambda(repeat_and_concatenate)([input_3D, input_2D])\n",
    "# print(merged)\n",
    "# # Tensor(\"lambda_1/concat:0\", shape=(?, ?, 150), dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "\n",
    "# decoder_inputs = Input(shape=(None, w2v_size))\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "# # FIXME к данным добавить выход энкодера\n",
    "\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "\n",
    "# # decoder_dense = Dense(w2v_size)\n",
    "# # decoder_dense = Dense(w2v_size, activation='softmax')\n",
    "# # decoder_dense = Dense(w2v_size, activation='tanh')\n",
    "# # decoder_dense = Dense(w2v_size, activation='sigmoid')\n",
    "# decoder_dense = Dense(w2v_size, activation=custom_activation)\n",
    "\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
