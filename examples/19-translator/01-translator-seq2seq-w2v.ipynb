{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**автоматический переводчик на основе рекуррентных нейросетей seq2seq**\n",
    "\n",
    "кодируем слова word2vec\n",
    "\n",
    "Евгений Борисов <borisov.e@solarl.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import gzip\n",
    "\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(d): return \"{:,.0f}\".format(d).replace(\",\", \" \")\n",
    "def ppr(d): print('записей:', pp(len(d)) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Учебные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/text/rus-eng/rus.txt.gz','rt',encoding='utf8') as f: \n",
    "    pair = pd.DataFrame([ p.split('\\t') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/text/pairs.txt','rt',encoding='utf8') as f: \n",
    "#     pair = pd.DataFrame([ p.split('%%') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.columns=['Q','A']\n",
    "pair['Q'] = pair['Q'].str.strip()\n",
    "pair['A'] = pair['A'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 336 666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15772</th>\n",
       "      <td>Those men died.</td>\n",
       "      <td>Те люди погибли.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203454</th>\n",
       "      <td>You didn't answer my question.</td>\n",
       "      <td>Ты не ответила на мой вопрос.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22278</th>\n",
       "      <td>This can't wait.</td>\n",
       "      <td>Это не может ждать.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144928</th>\n",
       "      <td>Tom is completely useless.</td>\n",
       "      <td>Том совершенно бесполезен.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1540</th>\n",
       "      <td>Who drove?</td>\n",
       "      <td>Кто вёл машину?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307800</th>\n",
       "      <td>We'll let you know the result within a week.</td>\n",
       "      <td>Мы сообщим вам о результатах в течение недели.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28952</th>\n",
       "      <td>It's in your bag.</td>\n",
       "      <td>Оно у Вас в сумке.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222518</th>\n",
       "      <td>It was in 1950 that he was born.</td>\n",
       "      <td>Родился он в 1950 году.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256677</th>\n",
       "      <td>Tom won't know anything about that.</td>\n",
       "      <td>Том ничего об этом не узнает.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Q  \\\n",
       "15772                                Those men died.   \n",
       "203454                You didn't answer my question.   \n",
       "22278                               This can't wait.   \n",
       "144928                    Tom is completely useless.   \n",
       "1540                                      Who drove?   \n",
       "307800  We'll let you know the result within a week.   \n",
       "28952                              It's in your bag.   \n",
       "222518              It was in 1950 that he was born.   \n",
       "256677           Tom won't know anything about that.   \n",
       "\n",
       "                                                     A  \n",
       "15772                                 Те люди погибли.  \n",
       "203454                   Ты не ответила на мой вопрос.  \n",
       "22278                              Это не может ждать.  \n",
       "144928                      Том совершенно бесполезен.  \n",
       "1540                                   Кто вёл машину?  \n",
       "307800  Мы сообщим вам о результатах в течение недели.  \n",
       "28952                               Оно у Вас в сумке.  \n",
       "222518                         Родился он в 1950 году.  \n",
       "256677                   Том ничего об этом не узнает.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppr(pair)\n",
    "pair.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair = pair.iloc[100000:110000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистим тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_clean'] = pair['Q'].str.lower()\n",
    "pair['Q_clean'] = pair['Q_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "\n",
    "pair['A_clean'] = pair['A'].str.lower()\n",
    "pair['A_clean'] = pair['A_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'(\\W)', ' \\1 ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\W', ' ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\b\\d+\\b', ' digit ', s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (pair['Q_clean'] + ' <START>').str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавляем \"служебные\" слова - начало и конец последовательности\n",
    "pair['Q_clean'] = (pair['Q_clean'] + ' <START>').str.split() \n",
    "# выстраиваем входные последовательности в обратном порядке\n",
    "pair['Q_clean'] = pair['Q_clean'].apply(lambda t: [ w for w in reversed(t) if w.strip() ] )\n",
    "\n",
    "pair['A_clean'] = (pair['A_clean'] + ' <EOS>').str.split()  \n",
    "\n",
    "# pair['A_clean'].str.split() + ['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_clean</th>\n",
       "      <th>A_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>101734</th>\n",
       "      <td>[&lt;START&gt;, ., begun, has, season, rainy]</td>\n",
       "      <td>[настал, сезон, дождей, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100825</th>\n",
       "      <td>[&lt;START&gt;, ., you, of, kind, very, is, it]</td>\n",
       "      <td>[очень, любезно, с, вашей, стороны, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107637</th>\n",
       "      <td>[&lt;START&gt;, ., be, i'll, where, know, you]</td>\n",
       "      <td>[вы, знаете, ,, где, буду, я, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106709</th>\n",
       "      <td>[&lt;START&gt;, ?, cost, actual, the, what's]</td>\n",
       "      <td>[какова, реальная, стоимость, ?, &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108691</th>\n",
       "      <td>[&lt;START&gt;, ., friend, your, me, consider]</td>\n",
       "      <td>[считайте, меня, своим, другом, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107331</th>\n",
       "      <td>[&lt;START&gt;, ?, car, my, in, you, were, why]</td>\n",
       "      <td>[почему, вы, в, моей, машине, ?, &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103692</th>\n",
       "      <td>[&lt;START&gt;, ., me, impress, doesn't, tom]</td>\n",
       "      <td>[том, не, производит, на, меня, впечатления, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107192</th>\n",
       "      <td>[&lt;START&gt;, ?, us, tell, tom, didn't, why]</td>\n",
       "      <td>[почему, том, нам, не, сказал, ?, &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102522</th>\n",
       "      <td>[&lt;START&gt;, ., ten, at, start, class, the]</td>\n",
       "      <td>[занятие, начинается, в, десять, ., &lt;EOS&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Q_clean  \\\n",
       "101734    [<START>, ., begun, has, season, rainy]   \n",
       "100825  [<START>, ., you, of, kind, very, is, it]   \n",
       "107637   [<START>, ., be, i'll, where, know, you]   \n",
       "106709    [<START>, ?, cost, actual, the, what's]   \n",
       "108691   [<START>, ., friend, your, me, consider]   \n",
       "107331  [<START>, ?, car, my, in, you, were, why]   \n",
       "103692    [<START>, ., me, impress, doesn't, tom]   \n",
       "107192   [<START>, ?, us, tell, tom, didn't, why]   \n",
       "102522   [<START>, ., ten, at, start, class, the]   \n",
       "\n",
       "                                                       A_clean  \n",
       "101734                       [настал, сезон, дождей, ., <EOS>]  \n",
       "100825           [очень, любезно, с, вашей, стороны, ., <EOS>]  \n",
       "107637                 [вы, знаете, ,, где, буду, я, ., <EOS>]  \n",
       "106709                 [какова, реальная, стоимость, ?, <EOS>]  \n",
       "108691               [считайте, меня, своим, другом, ., <EOS>]  \n",
       "107331                 [почему, вы, в, моей, машине, ?, <EOS>]  \n",
       "103692  [том, не, производит, на, меня, впечатления, ., <EOS>]  \n",
       "107192                [почему, том, нам, не, сказал, ?, <EOS>]  \n",
       "102522              [занятие, начинается, в, десять, ., <EOS>]  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 9)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_len_a_max = pair['A_clean'].str.len().max()\n",
    "sent_len_q_max = pair['Q_clean'].str.len().max()\n",
    "\n",
    "sent_len_a_max,sent_len_q_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выравниваем длинну последовательностей,\n",
    "# дополняем короткие словом \"служебным\" словом PAD\n",
    "pair['Q_clean'] = pair['Q_clean'].apply( lambda t: ['<PAD>']*(sent_len_q_max-len(t)) + t )\n",
    "pair['A_clean'] = pair['A_clean'].apply( lambda t: t+['<PAD>']*(sent_len_a_max-len(t)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_clean</th>\n",
       "      <th>A_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>103000</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., dangerous, very, they're]</td>\n",
       "      <td>[они, очень, опасные, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102516</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., sofa, my, ruined, cat, the]</td>\n",
       "      <td>[кот, испортил, мой, диван, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105580</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., later, explain, will, tom]</td>\n",
       "      <td>[том, потом, объяснит, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103904</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., kidnapped, been, has, tom]</td>\n",
       "      <td>[тома, похитили, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107951</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., listener, good, a, you're]</td>\n",
       "      <td>[ты, хороший, слушатель, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105727</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., empty, was, wallet, tom's]</td>\n",
       "      <td>[бумажник, тома, был, пуст, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103195</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., well, me, fits, shoe, this]</td>\n",
       "      <td>[эта, туфля, мне, по, ноге, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108610</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;START&gt;, ?, this, do, me, help, you, can]</td>\n",
       "      <td>[можешь, помочь, мне, это, сделать, ?, &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101731</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, ., sleep, to, child, the, put]</td>\n",
       "      <td>[уложи, ребёнка, спать, ., &lt;EOS&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                   Q_clean  \\\n",
       "103000  [<PAD>, <PAD>, <PAD>, <PAD>, <START>, ., dangerous, very, they're]   \n",
       "102516              [<PAD>, <PAD>, <START>, ., sofa, my, ruined, cat, the]   \n",
       "105580        [<PAD>, <PAD>, <PAD>, <START>, ., later, explain, will, tom]   \n",
       "103904        [<PAD>, <PAD>, <PAD>, <START>, ., kidnapped, been, has, tom]   \n",
       "107951        [<PAD>, <PAD>, <PAD>, <START>, ., listener, good, a, you're]   \n",
       "105727        [<PAD>, <PAD>, <PAD>, <START>, ., empty, was, wallet, tom's]   \n",
       "103195              [<PAD>, <PAD>, <START>, ., well, me, fits, shoe, this]   \n",
       "108610                   [<PAD>, <START>, ?, this, do, me, help, you, can]   \n",
       "101731              [<PAD>, <PAD>, <START>, ., sleep, to, child, the, put]   \n",
       "\n",
       "                                                                                    A_clean  \n",
       "103000     [они, очень, опасные, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "102516      [кот, испортил, мой, диван, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "105580    [том, потом, объяснит, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "103904   [тома, похитили, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "107951  [ты, хороший, слушатель, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "105727      [бумажник, тома, был, пуст, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "103195             [эта, туфля, мне, по, ноге, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "108610     [можешь, помочь, мне, это, сделать, ?, <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  \n",
       "101731   [уложи, ребёнка, спать, ., <EOS>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>]  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.39 s, sys: 33.9 ms, total: 2.42 s\n",
      "Wall time: 2.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "w2v_size = 256\n",
    "\n",
    "w2v_q = Word2Vec( pair['Q_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)\n",
    "w2v_a = Word2Vec( pair['A_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_code'] = pair['Q_clean'].apply(lambda t: [ w2v_q.wv.get_vector(w) for w in t ] )\n",
    "pair['A_code'] = pair['A_clean'].apply(lambda t: [ w2v_a.wv.get_vector(w) for w in t ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair = pair.sample(1000)\n",
    "# pair = pair.sample(283800)\n",
    "# pair = pair.sample(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.stack( pair['Q_code'].values ).astype(np.float32)\n",
    "\n",
    "decoder_input_data  = np.stack( pair['A_code'].values )[:,:-1,:].astype(np.float32)\n",
    "\n",
    "#decoder_target_data = np.stack( pair['A_code'].values )[:,1:,:].astype(np.float32)\n",
    "decoder_target_data = np.stack( pair['A_code'].values ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 9, 256), (10000, 11, 256), (10000, 12, 256))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_input_data.shape, decoder_input_data.shape, decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.abs(encoder_input_data).max(), \n",
    "act_fact = np.ceil(np.abs(decoder_input_data).max())\n",
    "act_fact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/usr/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/mechanoid/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/mechanoid/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/mechanoid/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/mechanoid/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/mechanoid/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/mechanoid/.local/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "from keras.layers import Reshape\n",
    "from keras.layers import Concatenate \n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "# from tensorflow.keras.backend import expand_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256  # размер сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0910 12:05:25.656138 140355813832512 deprecation_wrapper.py:119] From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:72: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0910 12:05:25.678682 140355813832512 deprecation_wrapper.py:119] From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:515: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0910 12:05:25.682814 140355813832512 deprecation_wrapper.py:119] From /usr/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4048: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, w2v_size))\n",
    "\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]\n",
    "\n",
    "encoder_outputs = encoder(encoder_inputs)\n",
    "encoder_states = encoder_outputs[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.expand_dims(encoder_outputs,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None,w2v_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_inputs = concatenate([ K.expand_dims(encoder_outputs,1), decoder_inputs],axis=1)\n",
    "decoder_concat_inputs = Concatenate(axis=1)([K.expand_dims(encoder_outputs[0],1), decoder_inputs])\n",
    "# decoder_inputs = Concatenate(axis=1)([encoder_outputs, decoder_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_concat_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm( decoder_concat_inputs, initial_state=encoder_states )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'lstm_2/transpose_1:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_activation(x):  return K.tanh(x)*act_fact\n",
    "\n",
    "decoder_dense = Dense(w2v_size, activation=custom_activation)\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/mul:0' shape=(?, ?, 256) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <tf.Tensor 'dense_1/mul:0' shape=(?, ?, 256) dtype=float32>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute '_inbound_nodes'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-d6d569112c7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoder_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_inputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[1;32m     92\u001b[0m             \u001b[0;31m# Graph network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;31m# Subclassed network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[0;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Keep track of the network's nodes and layers.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         nodes, nodes_by_depth, layers, layers_by_depth = _map_graph_network(\n\u001b[0;32m--> 237\u001b[0;31m             self.inputs, self.outputs)\n\u001b[0m\u001b[1;32m    238\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_network_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nodes_by_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnodes_by_depth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36m_map_graph_network\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m   1351\u001b[0m                   \u001b[0mlayer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m                   \u001b[0mnode_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m                   tensor_index=tensor_index)\n\u001b[0m\u001b[1;32m   1354\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnodes_in_decreasing_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1340\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1340\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1338\u001b[0m             \u001b[0mtensor_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1339\u001b[0m             build_map(x, finished_nodes, nodes_in_progress, layer,\n\u001b[0;32m-> 1340\u001b[0;31m                       node_index, tensor_index)\n\u001b[0m\u001b[1;32m   1341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1342\u001b[0m         \u001b[0mfinished_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/keras/engine/network.py\u001b[0m in \u001b[0;36mbuild_map\u001b[0;34m(tensor, finished_nodes, nodes_in_progress, layer, node_index, tensor_index)\u001b[0m\n\u001b[1;32m   1310\u001b[0m             \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0mcycle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mdetected\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \"\"\"\n\u001b[0;32m-> 1312\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inbound_nodes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnode_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m         \u001b[0;31m# Prevent cycles.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute '_inbound_nodes'"
     ]
    }
   ],
   "source": [
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.compile(loss='mse', optimizer='sgd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=50,\n",
    "          epochs=10,\n",
    "          validation_split=0.1\n",
    "        ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверяем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # генерируем состояние энкодера\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # вход декодера - последовательность из одного слова GO\n",
    "    output_w2v = w2v_a.wv['<GO>'].reshape([1,1,w2v_size])\n",
    "\n",
    "    # выходная последовательность\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    for i in range(sent_len_a_max): \n",
    "        output_w2v, h, c = decoder_model.predict([output_w2v] + states_value)\n",
    "\n",
    "        # декодируем cлово\n",
    "        cc = output_w2v.reshape(w2v_size)\n",
    "        w = w2v_a.wv.similar_by_vector(cc)[0][0] \n",
    "        \n",
    "        # если очередное слово это EOS\n",
    "        if(w=='<EOS>'): break # то завершаем работу\n",
    "\n",
    "        decoded_sentence.append(w)\n",
    "       \n",
    "        states_value = [h,c] # обновляем состояние сети\n",
    "\n",
    "    return ' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = np.random.permutation(len(encoder_input_data))[:10]\n",
    "for seq_index in ii:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print( pair.iloc[seq_index]['Q'],' -> ', decoded_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc = history.history['acc']\n",
    "#val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()   # clear figure\n",
    "# acc_values = history_dict['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "# plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('tensorflow:', tf.__version__)\n",
    "print('keras:', keras.__version__)\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print('GPU devices:\\n  ',\n",
    "        [ [x.name, x.physical_device_desc] \n",
    "          for x in device_lib.list_local_devices() \n",
    "          if x.device_type == 'GPU' ]\n",
    "    )\n",
    "    print('default GPU device:', tf.test.gpu_device_name() )\n",
    "\n",
    "else:\n",
    "    print('no GPU device found')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_q_vocab = sorted([w for w in w2v_q.wv.vocab])\n",
    "# ppr(w2v_q_vocab)\n",
    "# w2v_a_vocab = sorted([w for w in w2v_a.wv.vocab])\n",
    "# ppr(w2v_a_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii = np.random.permutation(len(w2v_q_vocab))[:10]\n",
    "# for i in ii:\n",
    "#     w = w2v_q_vocab[i]\n",
    "#     ww = [ v[0] for v in w2v_q.wv.most_similar(w, topn=5) ]\n",
    "#     print( w,':',ww )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ii = np.random.permutation(len(w2v_a_vocab))[:10]\n",
    "# for i in ii:\n",
    "#     w = w2v_a_vocab[i]\n",
    "#     ww = [ v[0] for v in w2v_a.wv.most_similar(w, topn=5) ]\n",
    "#     print( w,':',ww )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input1 = Input(shape=(16,))\n",
    "# x1 = Dense(8, activation='relu')(input1)\n",
    "#\n",
    "# input2 = Input(shape=(32,))\n",
    "# x2 = Dense(8, activation='relu')(input2)\n",
    "# added = add([x1, x2])\n",
    "#\n",
    "# out = Dense(4)(added)\n",
    "# model = Model( inputs=[input1, input2], outputs=out )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1  x2  x3\n",
    "#  \\  /   /\n",
    "#   y1   /\n",
    "#    \\  /\n",
    "#     y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first = Sequential()\n",
    "# first.add(Dense(1, input_shape=(2,), activation='sigmoid'))\n",
    "\n",
    "# second = Sequential()\n",
    "# second.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "# third = Sequential()\n",
    "# # of course you must provide the input to result with will be your x3\n",
    "# third.add(Dense(1, input_shape=(1,), activation='sigmoid'))\n",
    "\n",
    "# # lets say you add a few more layers to first and second.\n",
    "# # concatenate them\n",
    "# merged = Concatenate([first, second])\n",
    "\n",
    "# # then concatenate the two outputs\n",
    "\n",
    "# result = Concatenate([merged,  third])\n",
    "\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "# result.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.models import Model\n",
    "# from keras.layers import Concatenate, Dense, LSTM, Input, concatenate\n",
    "# from keras.optimizers import Adagrad\n",
    "\n",
    "# first_input = Input(shape=(2, ))\n",
    "# first_dense = Dense(1, )(first_input)\n",
    "\n",
    "# second_input = Input(shape=(2, ))\n",
    "# second_dense = Dense(1, )(second_input)\n",
    "\n",
    "# merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "# third_input = Input(shape=(1, ))\n",
    "# merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "# model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "# model.compile(optimizer=ada_grad, loss='binary_crossentropy',\n",
    "#                metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_inputs = Input(shape=(None, w2v_size))\n",
    "# encoder = LSTM(latent_dim, return_state=True)\n",
    "# encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge( [ UpSampling2D(size=(2,2), dim_ordering=\"th\")(conv5), conv4], mode='concat', concat_axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x1  x2  x3\n",
    "#  \\  /   /\n",
    "#   y1   /\n",
    "#    \\  /\n",
    "#     y2\n",
    "#\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input\n",
    "# from keras.layers import Dense\n",
    "# from keras.layers import concatenate\n",
    "# from keras.optimizers import Adagrad\n",
    "\n",
    "# first_input = Input(shape=(2, ))\n",
    "# first_dense = Dense(1, )(first_input)\n",
    "\n",
    "# second_input = Input(shape=(2, ))\n",
    "# second_dense = Dense(1, )(second_input)\n",
    "\n",
    "# merge_one = concatenate([first_dense, second_dense])\n",
    "\n",
    "# third_input = Input(shape=(1, ))\n",
    "# merge_two = concatenate([merge_one, third_input])\n",
    "\n",
    "# model = Model(inputs=[first_input, second_input, third_input], outputs=merge_two)\n",
    "\n",
    "# ada_grad = Adagrad(lr=0.1, epsilon=1e-08, decay=0.0)\n",
    "# model.compile(optimizer=ada_grad, loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import *\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(100,), dtype='int32', name='input_2D')\n",
    "# input_2D_repeat = RepeatVector(K.shape(input_3D)[1])(input_2D)\n",
    "# merged = Concatenate(axis=1)([input_3D, input_2D_repeat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import *\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(100,), dtype='int32', name='input_2D')\n",
    "# input_2D_repeat = RepeatVector(K.shape(input_3D)[1])(input_2D)\n",
    "# merged = concatenate([input_3D, input_2D_repeat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "# from keras.layers import Input, Lambda\n",
    "# import keras.backend as K\n",
    "\n",
    "# def repeat_and_concatenate(inputs):\n",
    "#     input_3D, input_2D = inputs\n",
    "#     # Repeat 2D vectors\n",
    "#     input_2D_repeat = K.tile(K.expand_dims(input_2D, 1), [1, K.shape(input_3D)[1], 1])\n",
    "#     # Concatenate feature-wise\n",
    "#     return K.concatenate([input_3D, input_2D_repeat], axis=-1)\n",
    "\n",
    "# input_3D = Input(shape=(None,100,), dtype='int32', name='input_3D')\n",
    "# input_2D = Input(shape=(50,), dtype='int32', name='input_2D')\n",
    "# merged = Lambda(repeat_and_concatenate)([input_3D, input_2D])\n",
    "# print(merged)\n",
    "# # Tensor(\"lambda_1/concat:0\", shape=(?, ?, 150), dtype=int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate\n",
    "\n",
    "# decoder_inputs = Input(shape=(None, w2v_size))\n",
    "# decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "\n",
    "# # FIXME к данным добавить выход энкодера\n",
    "\n",
    "# decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "\n",
    "# # decoder_dense = Dense(w2v_size)\n",
    "# # decoder_dense = Dense(w2v_size, activation='softmax')\n",
    "# # decoder_dense = Dense(w2v_size, activation='tanh')\n",
    "# # decoder_dense = Dense(w2v_size, activation='sigmoid')\n",
    "# decoder_dense = Dense(w2v_size, activation=custom_activation)\n",
    "\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
