{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**автоматический переводчик на основе рекуррентных нейросетей seq2seq**\n",
    "\n",
    "Евгений Борисов borisov.e@solarl.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(d): return \"{:,.0f}\".format(d).replace(\",\", \" \")\n",
    "def ppr(d): print('записей:', pp(len(d)) )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 336 667\n"
     ]
    }
   ],
   "source": [
    "# http://www.manythings.org/anki/\n",
    "    \n",
    "# список фраз на английском с переводом на русский\n",
    "with open('../data/text/rus-eng/rus.txt', 'rt', encoding='utf-8') as f:\n",
    "    lines = f.read().lower().split('\\n')\n",
    "\n",
    "ppr(lines)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 10 000\n"
     ]
    }
   ],
   "source": [
    "# фразы упорядоченны по длине, выберем среднюю длину\n",
    "lines = [ lines[i] for i in range(100000,110000) ]\n",
    "ppr(lines)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# разбираем строки на русские и английские с сохранением порядка\n",
    "\n",
    "# определим специальные символы - начало и конец фразы\n",
    "GO='\\t' # символ <старт>\n",
    "EOS='\\n' # символ <стоп>\n",
    "\n",
    "input_texts  = [ s.split('\\t')[0] for s in lines if s ] \n",
    "target_texts = [ GO + ' ' + s.split('\\t')[1]+ ' ' + EOS for s in lines if s ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# входной и выходной алфавиты\n",
    "input_characters  = sorted(set(' '.join(input_texts)))\n",
    "target_characters = sorted(set(' '.join(target_texts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# размер входного алфавита\n",
    "num_encoder_tokens = len(input_characters) \n",
    "# максимальная длина входной фразы в символах \n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "\n",
    "# размер выходного алфавита\n",
    "num_decoder_tokens = len(target_characters)\n",
    "# максимальная длина выходной фразы в символах \n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# нумеруем символы в алфавите\n",
    "input_token_index = { char:i for i, char in enumerate(input_characters) }\n",
    "target_token_index = { char:i  for i, char in enumerate(target_characters) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## кодируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# строим статистическую модель порождения текста \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares,\n",
    "#     Holger Schwenk, Yoshua Bengio\n",
    "# Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation\n",
    "# 3 Sep 2014\n",
    "# https://arxiv.org/abs/1406.1078\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# statistical machine translation system (SMT)\n",
    "\n",
    "# the goal of the system (decoder,specifically) is to \n",
    "# find a translation f given a source sentence e, which maximizes\n",
    "\n",
    "# p(f|e) ∝ p(e|f)p(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для каждого примера\n",
    "#   строим таблицу индикаторов  {0,1}\n",
    "#     [ номер слова в последовательности, номер символа в алфавите ] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные энкодера \n",
    "\n",
    "# входная последовательность генерирует выход по схеме many2one \n",
    "#   выход энкодера выкидываем\n",
    "#    используем только его конечное состояние\n",
    "#      первым входом декодера есть служебное слово <пуск>\n",
    "encoder_input_data = np.zeros( (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "\n",
    "for s, input_text in enumerate(input_texts):\n",
    "    for w, c in enumerate(input_text):\n",
    "        encoder_input_data[s, w, input_token_index[c]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# данные декодера (для целевой последовательности), \n",
    "\n",
    "# память декодера инициализируеться конечным состянием памяти энкодера \n",
    "#   и на вход подаём служебное слово <пуск>    \n",
    "#    далее рекурсивно - очередной выход декодера подаёться на вход и генерирует следующий выход\n",
    "\n",
    "# вход декодера\n",
    "decoder_input_data = np.zeros( (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "# выход декодера (вход смещённый на один шаг)\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "\n",
    "for i, target_text in enumerate(target_texts):\n",
    "    for t, char in enumerate(target_text):\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 512  # размер сети\n",
    "\n",
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 47)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 67)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 512), (None, 1146880     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 512),  1187840     input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 67)     34371       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 2,369,091\n",
      "Trainable params: 2,369,091\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## обучаем модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/100\n",
      "8000/8000 [==============================] - 104s 13ms/sample - loss: 1.1859 - val_loss: 1.1115\n",
      "Epoch 2/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.9547 - val_loss: 0.9483\n",
      "Epoch 3/100\n",
      "8000/8000 [==============================] - 100s 13ms/sample - loss: 0.8327 - val_loss: 0.8731\n",
      "Epoch 4/100\n",
      "8000/8000 [==============================] - 101s 13ms/sample - loss: 0.7779 - val_loss: 0.8298\n",
      "Epoch 5/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.7187 - val_loss: 0.7985\n",
      "Epoch 6/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.6745 - val_loss: 0.7664\n",
      "Epoch 7/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.6331 - val_loss: 0.7342\n",
      "Epoch 8/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.5971 - val_loss: 0.7164\n",
      "Epoch 9/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.5665 - val_loss: 0.7083\n",
      "Epoch 10/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.5385 - val_loss: 0.6871\n",
      "Epoch 11/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.5132 - val_loss: 0.6821\n",
      "Epoch 12/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.4890 - val_loss: 0.6734\n",
      "Epoch 13/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.4663 - val_loss: 0.6719\n",
      "Epoch 14/100\n",
      "8000/8000 [==============================] - 103s 13ms/sample - loss: 0.4444 - val_loss: 0.6723\n",
      "Epoch 15/100\n",
      "8000/8000 [==============================] - 103s 13ms/sample - loss: 0.4235 - val_loss: 0.6833\n",
      "Epoch 16/100\n",
      "8000/8000 [==============================] - 100s 13ms/sample - loss: 0.4034 - val_loss: 0.6824\n",
      "Epoch 17/100\n",
      "8000/8000 [==============================] - 102s 13ms/sample - loss: 0.3844 - val_loss: 0.6928\n",
      "Epoch 18/100\n",
      "8000/8000 [==============================] - 103s 13ms/sample - loss: 0.3655 - val_loss: 0.6990\n",
      "Epoch 19/100\n",
      "8000/8000 [==============================] - 101s 13ms/sample - loss: 0.3481 - val_loss: 0.7083\n",
      "Epoch 20/100\n",
      "8000/8000 [==============================] - 104s 13ms/sample - loss: 0.3308 - val_loss: 0.7179\n",
      "Epoch 21/100\n",
      "8000/8000 [==============================] - 103s 13ms/sample - loss: 0.3146 - val_loss: 0.7384\n",
      "Epoch 22/100\n",
      "8000/8000 [==============================] - 100s 13ms/sample - loss: 0.2997 - val_loss: 0.7493\n",
      "Epoch 23/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.2851 - val_loss: 0.7552\n",
      "Epoch 24/100\n",
      "8000/8000 [==============================] - 101s 13ms/sample - loss: 0.2711 - val_loss: 0.7710\n",
      "Epoch 25/100\n",
      "8000/8000 [==============================] - 100s 13ms/sample - loss: 0.2582 - val_loss: 0.7901\n",
      "Epoch 26/100\n",
      "8000/8000 [==============================] - 102s 13ms/sample - loss: 0.2462 - val_loss: 0.7928\n",
      "Epoch 27/100\n",
      "8000/8000 [==============================] - 101s 13ms/sample - loss: 0.2349 - val_loss: 0.8134\n",
      "Epoch 28/100\n",
      "8000/8000 [==============================] - 101s 13ms/sample - loss: 0.2246 - val_loss: 0.8352\n",
      "Epoch 29/100\n",
      "8000/8000 [==============================] - 100s 13ms/sample - loss: 0.2149 - val_loss: 0.8433\n",
      "Epoch 30/100\n",
      "8000/8000 [==============================] - 100s 12ms/sample - loss: 0.2063 - val_loss: 0.8587\n",
      "Epoch 31/100\n",
      "8000/8000 [==============================] - 100s 12ms/sample - loss: 0.1979 - val_loss: 0.8702\n",
      "Epoch 32/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1902 - val_loss: 0.8948\n",
      "Epoch 33/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1828 - val_loss: 0.9094\n",
      "Epoch 34/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.1765 - val_loss: 0.9254\n",
      "Epoch 35/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1706 - val_loss: 0.9289\n",
      "Epoch 36/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1654 - val_loss: 0.9323\n",
      "Epoch 37/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1596 - val_loss: 0.9561\n",
      "Epoch 38/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1552 - val_loss: 0.9778\n",
      "Epoch 39/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1499 - val_loss: 0.9854\n",
      "Epoch 40/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1458 - val_loss: 1.0142\n",
      "Epoch 41/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1419 - val_loss: 1.0151\n",
      "Epoch 42/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1374 - val_loss: 1.0237\n",
      "Epoch 43/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1334 - val_loss: 1.0311\n",
      "Epoch 44/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.1299 - val_loss: 1.0501\n",
      "Epoch 45/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.1265 - val_loss: 1.0555\n",
      "Epoch 46/100\n",
      "8000/8000 [==============================] - 100s 13ms/sample - loss: 0.1229 - val_loss: 1.0818\n",
      "Epoch 47/100\n",
      "8000/8000 [==============================] - 107s 13ms/sample - loss: 0.1193 - val_loss: 1.1153\n",
      "Epoch 48/100\n",
      "8000/8000 [==============================] - 105s 13ms/sample - loss: 0.1164 - val_loss: 1.0839\n",
      "Epoch 49/100\n",
      "8000/8000 [==============================] - 115s 14ms/sample - loss: 0.1130 - val_loss: 1.1079\n",
      "Epoch 50/100\n",
      "8000/8000 [==============================] - 113s 14ms/sample - loss: 0.1100 - val_loss: 1.1169\n",
      "Epoch 51/100\n",
      "8000/8000 [==============================] - 112s 14ms/sample - loss: 0.1070 - val_loss: 1.1244\n",
      "Epoch 52/100\n",
      "8000/8000 [==============================] - 111s 14ms/sample - loss: 0.1037 - val_loss: 1.1227\n",
      "Epoch 53/100\n",
      "8000/8000 [==============================] - 106s 13ms/sample - loss: 0.1009 - val_loss: 1.1344\n",
      "Epoch 54/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.0980 - val_loss: 1.1605\n",
      "Epoch 55/100\n",
      "8000/8000 [==============================] - 100s 13ms/sample - loss: 0.0953 - val_loss: 1.1688\n",
      "Epoch 56/100\n",
      "8000/8000 [==============================] - 103s 13ms/sample - loss: 0.0927 - val_loss: 1.1900\n",
      "Epoch 57/100\n",
      "8000/8000 [==============================] - 114s 14ms/sample - loss: 0.0898 - val_loss: 1.1810\n",
      "Epoch 58/100\n",
      "8000/8000 [==============================] - 102s 13ms/sample - loss: 0.0869 - val_loss: 1.1906\n",
      "Epoch 59/100\n",
      "8000/8000 [==============================] - 109s 14ms/sample - loss: 0.0846 - val_loss: 1.1810\n",
      "Epoch 60/100\n",
      "8000/8000 [==============================] - 106s 13ms/sample - loss: 0.0819 - val_loss: 1.2120\n",
      "Epoch 61/100\n",
      "8000/8000 [==============================] - 117s 15ms/sample - loss: 0.0795 - val_loss: 1.2054\n",
      "Epoch 62/100\n",
      "8000/8000 [==============================] - 112s 14ms/sample - loss: 0.0768 - val_loss: 1.2358\n",
      "Epoch 63/100\n",
      "8000/8000 [==============================] - 112s 14ms/sample - loss: 0.0742 - val_loss: 1.2261\n",
      "Epoch 64/100\n",
      "8000/8000 [==============================] - 110s 14ms/sample - loss: 0.0720 - val_loss: 1.2632\n",
      "Epoch 65/100\n",
      "8000/8000 [==============================] - 106s 13ms/sample - loss: 0.0698 - val_loss: 1.2684\n",
      "Epoch 66/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.0676 - val_loss: 1.2645\n",
      "Epoch 67/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0653 - val_loss: 1.2512\n",
      "Epoch 68/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0634 - val_loss: 1.2705\n",
      "Epoch 69/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0615 - val_loss: 1.2913\n",
      "Epoch 70/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0595 - val_loss: 1.2825\n",
      "Epoch 71/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0576 - val_loss: 1.2834\n",
      "Epoch 72/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0562 - val_loss: 1.2857\n",
      "Epoch 73/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0544 - val_loss: 1.3337\n",
      "Epoch 74/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0526 - val_loss: 1.3054\n",
      "Epoch 75/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0511 - val_loss: 1.3169\n",
      "Epoch 76/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0497 - val_loss: 1.3128\n",
      "Epoch 77/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0483 - val_loss: 1.3166\n",
      "Epoch 78/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0467 - val_loss: 1.3258\n",
      "Epoch 79/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0454 - val_loss: 1.3383\n",
      "Epoch 80/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0444 - val_loss: 1.3336\n",
      "Epoch 81/100\n",
      "8000/8000 [==============================] - 100s 12ms/sample - loss: 0.0431 - val_loss: 1.3462\n",
      "Epoch 82/100\n",
      "8000/8000 [==============================] - 97s 12ms/sample - loss: 0.0427 - val_loss: 1.3526\n",
      "Epoch 83/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0410 - val_loss: 1.3597\n",
      "Epoch 84/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.0398 - val_loss: 1.3673\n",
      "Epoch 85/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0391 - val_loss: 1.3901\n",
      "Epoch 86/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0385 - val_loss: 1.3604\n",
      "Epoch 87/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0371 - val_loss: 1.3827\n",
      "Epoch 88/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0366 - val_loss: 1.3851\n",
      "Epoch 89/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0362 - val_loss: 1.3922\n",
      "Epoch 90/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0353 - val_loss: 1.4054\n",
      "Epoch 91/100\n",
      "8000/8000 [==============================] - 127s 16ms/sample - loss: 0.0344 - val_loss: 1.4015\n",
      "Epoch 92/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0339 - val_loss: 1.4123\n",
      "Epoch 93/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0335 - val_loss: 1.3868\n",
      "Epoch 94/100\n",
      "8000/8000 [==============================] - 104s 13ms/sample - loss: 0.0327 - val_loss: 1.4025\n",
      "Epoch 95/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0327 - val_loss: 1.4052\n",
      "Epoch 96/100\n",
      "8000/8000 [==============================] - 99s 12ms/sample - loss: 0.0319 - val_loss: 1.4226\n",
      "Epoch 97/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0314 - val_loss: 1.4381\n",
      "Epoch 98/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0312 - val_loss: 1.4234\n",
      "Epoch 99/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0306 - val_loss: 1.4222\n",
      "Epoch 100/100\n",
      "8000/8000 [==============================] - 98s 12ms/sample - loss: 0.0307 - val_loss: 1.4316\n",
      "CPU times: user 1h 30min 20s, sys: 1h 9min 12s, total: 2h 39min 33s\n",
      "Wall time: 2h 48min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=100,\n",
    "          epochs=20,\n",
    "          validation_split=0.2\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_input_char_index = { i:char for char,i in input_token_index.items() }\n",
    "reverse_target_char_index = { i:char for char,i in target_token_index.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # генерируем состояние энкодера\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # вход декодера - последовательность из одного слова GO\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index[GO]] = 1.\n",
    "\n",
    "    # выходную последовательность\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    \n",
    "    for i in range(max_decoder_seq_length): \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "\n",
    "        # декодируем символ\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # если очередной символ это EOS\n",
    "        if(sampled_char==EOS): break # то завершаем работу\n",
    "\n",
    "        # обновляем входную последовательность\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # обновляем состояние сети\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what a beautiful woman!  ->   какая красивая женщина! \n",
      "\n",
      "tom will have to leave.  ->   тому придётся уехать. \n",
      "\n",
      "it doesn't matter, tom.  ->   это неважно, том. \n",
      "\n",
      "we'll never forget tom.  ->   мы никогда не забудем тома. \n",
      "\n",
      "do you have news for me?  ->   скажите тому, где вы. \n",
      "\n",
      "why don't you eat meat?  ->   почему ты не ешь мясо? \n",
      "\n",
      "the clothes are drying.  ->   одежда сохнет. \n",
      "\n",
      "no one will be at home.  ->   никого не будет дома. \n",
      "\n",
      "what is tom doing here?  ->   что том здесь делает? \n",
      "\n",
      "tom doesn't know where.  ->   том не знает где. \n",
      "\n",
      "crack is very addictive.  ->   спасибо за ссылку. \n",
      "\n",
      "don't you recognize tom?  ->   скажите это ему, а не мне! \n",
      "\n",
      "tom will do that later.  ->   том сделает это позже. \n",
      "\n",
      "please take care of it.  ->   пожалуйста, позаботьтесь об этом. \n",
      "\n",
      "tell tom what happened.  ->   расскажите тому, что случилось. \n",
      "\n",
      "tom doesn't like chess.  ->   том не любит шахматы. \n",
      "\n",
      "that's hard to believe.  ->   верится с трудом. \n",
      "\n",
      "does she play the piano?  ->   расскажите мне об этом парне. \n",
      "\n",
      "you can't trust anyone.  ->   никому нельзя доверять. \n",
      "\n",
      "let me take your coats.  ->   позвольте мне взять у вас пальто. \n",
      "\n",
      "this'll be interesting.  ->   это будет интересно. \n",
      "\n",
      "you never stop talking.  ->   вы болтаете без умолку. \n",
      "\n",
      "the bar is always open.  ->   бар всегда открыт. \n",
      "\n",
      "doesn't that bother you?  ->   скажите мне, где бу том? \n",
      "\n",
      "he had a blue jacket on.  ->   она мне не подреватесь. \n",
      "\n",
      "do you want to go there?  ->   выклю? \n",
      "\n",
      "he has an ear for music.  ->   она всегда весёт я рамствая. \n",
      "\n",
      "what do you plan to do?  ->   что ты планируешь делать? \n",
      "\n",
      "i'm wearing sunglasses.  ->   я в солнечных очках. \n",
      "\n",
      "are you messing with me?  ->   на и кому тебе очень подвыние? \n",
      "\n",
      "let them do their jobs.  ->   пусть они делают свою работу. \n",
      "\n",
      "you didn't have to ask.  ->   могли бы и не спрашивать. \n",
      "\n",
      "do you know how to swim?  ->   ты со меня простолону? \n",
      "\n",
      "will i see you tonight?  ->   мы с тобой сегодня вечером увидимся? \n",
      "\n",
      "tom sat in front of us.  ->   том сидел напротив нас. \n",
      "\n",
      "tom won't ask for help.  ->   том не попросит о помощи. \n",
      "\n",
      "this doll has big eyes.  ->   у этой куклы большие глаза. \n",
      "\n",
      "what are you all doing?  ->   что вы все делаете? \n",
      "\n",
      "thanks for the tickets.  ->   спасибо за поддержку. \n",
      "\n",
      "i'm washing the dishes.  ->   я мою посуду. \n",
      "\n",
      "that seems risky to me.  ->   мне это кажется рискованным. \n",
      "\n",
      "tom was reading a book.  ->   том читал книгу. \n",
      "\n",
      "can you count in french?  ->   мэри - хорошая актриса. \n",
      "\n",
      "tom wouldn't kiss mary.  ->   том не навредит мэри. \n",
      "\n",
      "aren't you tom's friend?  ->   наши команда очень хорошо справилась. \n",
      "\n",
      "my comment was deleted.  ->   мой комментарий удалили. \n",
      "\n",
      "your days are numbered.  ->   ты был на моей свадьбе. \n",
      "\n",
      "what are you afraid of?  ->   чего вы боитесь? \n",
      "\n",
      "i'm sorry for the mess.  ->   извиняюсь за беспорядок. \n",
      "\n",
      "tom is playing it safe.  ->   том действует наверняка. \n",
      "\n",
      "i'm not wide awake yet.  ->   я ещё не совсем проснулся. \n",
      "\n",
      "she has beautiful eyes.  ->   у неё красивые глаза. \n",
      "\n",
      "he objected to our plan.  ->   мы очень хотили. \n",
      "\n",
      "you're right, as usual.  ->   ты очень груб. \n",
      "\n",
      "your o's look like a's.  ->   ты хороший сосед. \n",
      "\n",
      "they will be very glad.  ->   они очень обрадуются. \n",
      "\n",
      "i've got tom's address.  ->   у меня есть адрес тома. \n",
      "\n",
      "who are we working for?  ->   на кого мы работаем? \n",
      "\n",
      "that wasn't your fault.  ->   это была не ваша вина. \n",
      "\n",
      "who are you describing?  ->   кого ты описываешь? \n",
      "\n",
      "tom told me i was cute.  ->   том сказал мне, что ты умерла. \n",
      "\n",
      "tom is mary's only son.  ->   том — единственный сын мэри. \n",
      "\n",
      "tom is perfect for you.  ->   том идеально тебе подходит. \n",
      "\n",
      "don't make me shoot you.  ->   на сегодня выглядет к там? \n",
      "\n",
      "she let the secret out.  ->   она раскрыла тайну. \n",
      "\n",
      "i'm listening to music.  ->   я слушаю музыку. \n",
      "\n",
      "we're all proud of you.  ->   мы все тобой гордимся. \n",
      "\n",
      "we mustn't tell anyone.  ->   мы не должны никому рассказывать. \n",
      "\n",
      "black looks good on you.  ->   всего мясум не не заверить? \n",
      "\n",
      "you'd better leave now.  ->   вам лучше сейчас уйти. \n",
      "\n",
      "you're reading my mind.  ->   ты на это напросился. \n",
      "\n",
      "are you alone right now?  ->   ну и какие у тебя планы? \n",
      "\n",
      "things stayed the same.  ->   всё осталось по-прежнему. \n",
      "\n",
      "i'm not going with you.  ->   я с вами не пойду. \n",
      "\n",
      "does tom live in boston?  ->   развезяте это напрая? \n",
      "\n",
      "are those your children?  ->   на и кому тебе очвнытны! \n",
      "\n",
      "my mother is a teacher.  ->   моя мать - учительница. \n",
      "\n",
      "tom is our best player.  ->   том, сейчас намного снаг. \n",
      "\n",
      "they're very dangerous.  ->   они очень опасны. \n",
      "\n",
      "my son came to my room.  ->   мой сын пришел в мою комнату. \n",
      "\n",
      "the system worked well.  ->   система работала хорошо. \n",
      "\n",
      "no one agreed with him.  ->   с ним никто не согласился. \n",
      "\n",
      "tom and i've been busy.  ->   мы с томом преподаватели. \n",
      "\n",
      "what time do you leave?  ->   во сколько вы уезжаете? \n",
      "\n",
      "tom will win, i'm sure.  ->   том выиграет, я уверен. \n",
      "\n",
      "don't ask me to do that.  ->   скажите мне, что это шутка. \n",
      "\n",
      "will he ever come back?  ->   он когда-нибудь вернётся? \n",
      "\n",
      "tom fell out of a tree.  ->   том упал с дерева. \n",
      "\n",
      "tom has a great memory.  ->   у тома прекрасная память. \n",
      "\n",
      "tom told me to do that.  ->   том велел мне это сделать. \n",
      "\n",
      "tom paints best in oil.  ->   том лучше всего пишет маслом. \n",
      "\n",
      "did you break something?  ->   разверят очень пробидел? \n",
      "\n",
      "we did that in october.  ->   мы сделали это в октябре. \n",
      "\n",
      "tom must've been drunk.  ->   том, должно быть, был прав. \n",
      "\n",
      "tom visited mary first.  ->   сначала том навестил мэри. \n",
      "\n",
      "tom was wearing gloves.  ->   том был в шертерме. \n",
      "\n",
      "tom left the next year.  ->   на следующий год том уехал. \n",
      "\n",
      "what will become of me?  ->   что со мной будет? \n",
      "\n",
      "the water's cold today.  ->   вода сегодня холодная. \n",
      "\n",
      "black looks good on you.  ->   всего мясум не не заверить? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "ii = np.random.permutation(len(encoder_input_data))[:100]\n",
    "for seq_index in ii:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print( input_texts[seq_index],' -> ', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow: 1.13.1\n",
      "keras: 2.2.4-tf\n",
      "GPU devices:\n",
      "   [['/device:GPU:0', 'device: 0, name: GeForce GT 730, pci bus id: 0000:01:00.0, compute capability: 3.5']]\n",
      "default GPU device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "print('tensorflow:', tf.__version__)\n",
    "print('keras:', keras.__version__)\n",
    "\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print('GPU devices:\\n  ',\n",
    "        [ [x.name, x.physical_device_desc] \n",
    "          for x in device_lib.list_local_devices() \n",
    "          if x.device_type == 'GPU' ]\n",
    "    )\n",
    "    print('default GPU device:', tf.test.gpu_device_name() )\n",
    "\n",
    "else:\n",
    "    print('no GPU device found')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# #Sequence to sequence example in Keras (character-level).\n",
    "\n",
    "# This script demonstrates how to implement a basic character-level\n",
    "# sequence-to-sequence model. We apply it to translating\n",
    "# short English sentences into short French sentences,\n",
    "# character-by-character. Note that it is fairly unusual to\n",
    "# do character-level machine translation, as word-level\n",
    "# models are more common in this domain.\n",
    "\n",
    "# **Summary of the algorithm**\n",
    "\n",
    "# - We start with input sequences from a domain (e.g. English sentences)\n",
    "#     and corresponding target sequences from another domain\n",
    "#     (e.g. French sentences).\n",
    "# - An encoder LSTM turns input sequences to 2 state vectors\n",
    "#     (we keep the last LSTM state and discard the outputs).\n",
    "# - A decoder LSTM is trained to turn the target sequences into\n",
    "#     the same sequence but offset by one timestep in the future,\n",
    "#     a training process called \"teacher forcing\" in this context.\n",
    "#     It uses as initial state the state vectors from the encoder.\n",
    "#     Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "#     given `targets[...t]`, conditioned on the input sequence.\n",
    "# - In inference mode, when we want to decode unknown input sequences, we:\n",
    "#     - Encode the input sequence into state vectors\n",
    "#     - Start with a target sequence of size 1\n",
    "#         (just the start-of-sequence character)\n",
    "#     - Feed the state vectors and 1-char target sequence\n",
    "#         to the decoder to produce predictions for the next character\n",
    "#     - Sample the next character using these predictions\n",
    "#         (we simply use argmax).\n",
    "#     - Append the sampled character to the target sequence\n",
    "#     - Repeat until we generate the end-of-sequence character or we\n",
    "#         hit the character limit.\n",
    "\n",
    "# **Data download**\n",
    "\n",
    "# [English to French sentence pairs.\n",
    "# ](http://www.manythings.org/anki/fra-eng.zip)\n",
    "\n",
    "# [Lots of neat sentence pairs datasets.\n",
    "# ](http://www.manythings.org/anki/)\n",
    "\n",
    "# **References**\n",
    "\n",
    "# - [Sequence to Sequence Learning with Neural Networks\n",
    "#    ](https://arxiv.org/abs/1409.3215)\n",
    "# - [Learning Phrase Representations using\n",
    "#     RNN Encoder-Decoder for Statistical Machine Translation\n",
    "#     ](https://arxiv.org/abs/1406.1078)\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_characters\n",
    "# input_characters\n",
    "# input_texts\n",
    "# output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samples = 10000  # Number of samples to train on.\n",
    "\n",
    "# # Vectorize the data.\n",
    "# input_texts = []\n",
    "# target_texts = []\n",
    "# input_characters = set()\n",
    "# target_characters = set()\n",
    "\n",
    "# with open('../data/text/rus-eng/rus.txt', 'rt', encoding='utf-8') as f:\n",
    "#     lines = f.read().split('\\n')\n",
    "    \n",
    "# for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "#     input_text, target_text = line.split('\\t')\n",
    "#     # We use \"tab\" as the \"start sequence\" character\n",
    "#     # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "#     target_text = '\\t' + target_text + '\\n'\n",
    "#     input_texts.append(input_text)\n",
    "#     target_texts.append(target_text)\n",
    "#     for char in input_text:\n",
    "#         if char not in input_characters:\n",
    "#             input_characters.add(char)\n",
    "#     for char in target_text:\n",
    "#         if char not in target_characters:\n",
    "#             target_characters.add(char)\n",
    "\n",
    "# input_characters = sorted(list(input_characters))\n",
    "# target_characters = sorted(list(target_characters))\n",
    "# num_encoder_tokens = len(input_characters)\n",
    "# num_decoder_tokens = len(target_characters)\n",
    "# max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "# max_decoder_seq_length = max([len(txt) for txt in target_texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "#     for t, char in enumerate(input_text):\n",
    "#         encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        \n",
    "#     for t, char in enumerate(target_text):\n",
    "#         # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "#         decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "#         if t > 0:\n",
    "#             # decoder_target_data will be ahead by one timestep\n",
    "#             # and will not include the start character.\n",
    "#             decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Next: inference mode (sampling).\n",
    "# # Here's the drill:\n",
    "# # 1) encode input and retrieve initial decoder state\n",
    "# # 2) run one step of decoder with this initial state\n",
    "# # and a \"start of sequence\" token as target.\n",
    "# # Output will be the next target token\n",
    "# # 3) Repeat with the current target token and current states\n",
    "\n",
    "# # Define sampling models\n",
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "# decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seq_index in range(100):\n",
    "#     # Take one sequence (part of the training set)\n",
    "#     # for trying out decoding.\n",
    "#     input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     print('-')\n",
    "#     print('Input sentence:', input_texts[seq_index])\n",
    "#     print('Decoded sentence:', decoded_sentence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
