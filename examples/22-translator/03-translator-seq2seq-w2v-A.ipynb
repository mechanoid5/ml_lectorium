{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**чатбот на рекуррентных нейросетях (Keras+TensorFlow)**\n",
    "\n",
    "Евгений Борисов <borisov.e@solarl.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import gzip\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(d): return \"{:,.0f}\".format(d).replace(\",\", \" \")\n",
    "def ppr(d): print('записей:', pp(len(d)) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Учебные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open('../data/text/rus-eng/rus.txt.gz','rt',encoding='utf8') as f: \n",
    "    pair = pd.DataFrame([ p.split('\\t') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('../data/text/pairs.txt','rt',encoding='utf8') as f: \n",
    "#     pair = pd.DataFrame([ p.split('%%') for p in f.read().split('\\n') if p.strip() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair.columns=['Q','A']\n",
    "pair['Q'] = pair['Q'].str.strip()\n",
    "pair['A'] = pair['A'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 336 666\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q</th>\n",
       "      <th>A</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>301106</th>\n",
       "      <td>Can you believe that summer is almost over?</td>\n",
       "      <td>Вы можете поверить, что лето уже почти прошло?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>I screamed.</td>\n",
       "      <td>Я закричал.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301086</th>\n",
       "      <td>At first, the local cowboys laughed at him.</td>\n",
       "      <td>Сначала местные ковбои над ним смеялись.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279086</th>\n",
       "      <td>Tom tried to help us, but he couldn't.</td>\n",
       "      <td>Том пытался нам помочь, но не смог.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201835</th>\n",
       "      <td>Tom's situation was different.</td>\n",
       "      <td>У Тома была другая ситуация.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102234</th>\n",
       "      <td>Ten minus two is eight.</td>\n",
       "      <td>Десять минус два равно восемь.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122095</th>\n",
       "      <td>Can I cancel this ticket?</td>\n",
       "      <td>Могу ли я сдать обратно этот билет?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89594</th>\n",
       "      <td>Tell Tom I'm innocent.</td>\n",
       "      <td>Скажите Тому, что я невиновен.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293418</th>\n",
       "      <td>I think you're putting in too much sugar.</td>\n",
       "      <td>По-моему, вы кладёте слишком много сахара.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Q  \\\n",
       "301106  Can you believe that summer is almost over?   \n",
       "1979                                    I screamed.   \n",
       "301086  At first, the local cowboys laughed at him.   \n",
       "279086       Tom tried to help us, but he couldn't.   \n",
       "201835               Tom's situation was different.   \n",
       "102234                      Ten minus two is eight.   \n",
       "122095                    Can I cancel this ticket?   \n",
       "89594                        Tell Tom I'm innocent.   \n",
       "293418    I think you're putting in too much sugar.   \n",
       "\n",
       "                                                     A  \n",
       "301106  Вы можете поверить, что лето уже почти прошло?  \n",
       "1979                                       Я закричал.  \n",
       "301086        Сначала местные ковбои над ним смеялись.  \n",
       "279086             Том пытался нам помочь, но не смог.  \n",
       "201835                    У Тома была другая ситуация.  \n",
       "102234                  Десять минус два равно восемь.  \n",
       "122095             Могу ли я сдать обратно этот билет?  \n",
       "89594                   Скажите Тому, что я невиновен.  \n",
       "293418      По-моему, вы кладёте слишком много сахара.  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppr(pair)\n",
    "pair.sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 10 000\n"
     ]
    }
   ],
   "source": [
    "pair = pair.iloc[100000:110000]\n",
    "\n",
    "ppr(pair)\n",
    "# pair = pair.sample(1000)\n",
    "# pair = pair.sample(283800)\n",
    "# pair = pair.sample(600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чистим тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_clean'] = pair['Q'].str.lower()\n",
    "pair['Q_clean'] = pair['Q_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "pair['A_clean'] = pair['A'].str.lower()\n",
    "pair['A_clean'] = pair['A_clean'].str.replace(r'([,.?!])', r' \\1 ')\n",
    "\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'(\\W)', ' \\1 ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\W', ' ', s))\n",
    "# pair['A_clean'] = pair['A_clean'].apply(lambda s: re.sub( r'\\b\\d+\\b', ' digit ', s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # добавляем \"служебные\" слова - начало и конец последовательности\n",
    "# pair['Q_clean'] = pair['Q_clean'].str.split() + ['<START>']\n",
    "# pair['A_clean'] = ['<GO>'] + pair['A_clean'].str.split() + ['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_clean'] = pair['Q_clean'].str.split()\n",
    "pair['A_clean'] = pair['A_clean'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Q_clean</th>\n",
       "      <th>A_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104825</th>\n",
       "      <td>[tom, put, on, a, black, wig, .]</td>\n",
       "      <td>[том, надел, чёрный, парик, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100309</th>\n",
       "      <td>[i'm, not, as, rich, as, tom, .]</td>\n",
       "      <td>[я, не, такой, богатый, ,, как, том, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101889</th>\n",
       "      <td>[she, pressed, the, switch, .]</td>\n",
       "      <td>[она, нажала, на, выключатель, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104431</th>\n",
       "      <td>[tom, is, wearing, sandals, .]</td>\n",
       "      <td>[том, в, сандалиях, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102245</th>\n",
       "      <td>[thank, you, for, the, help, .]</td>\n",
       "      <td>[спасибо, тебе, за, помощь, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100328</th>\n",
       "      <td>[i'm, not, going, to, do, it, .]</td>\n",
       "      <td>[я, не, собираюсь, этого, делать, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103606</th>\n",
       "      <td>[tom, did, twenty, pushups, .]</td>\n",
       "      <td>[том, сделал, 20, отжиманий, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105103</th>\n",
       "      <td>[tom, sprained, his, ankle, .]</td>\n",
       "      <td>[том, потянул, лодыжку, .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101231</th>\n",
       "      <td>[let's, play, that, by, ear, .]</td>\n",
       "      <td>[давай, сыграем, это, на, слух, .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Q_clean  \\\n",
       "104825  [tom, put, on, a, black, wig, .]   \n",
       "100309  [i'm, not, as, rich, as, tom, .]   \n",
       "101889    [she, pressed, the, switch, .]   \n",
       "104431    [tom, is, wearing, sandals, .]   \n",
       "102245   [thank, you, for, the, help, .]   \n",
       "100328  [i'm, not, going, to, do, it, .]   \n",
       "103606    [tom, did, twenty, pushups, .]   \n",
       "105103    [tom, sprained, his, ankle, .]   \n",
       "101231   [let's, play, that, by, ear, .]   \n",
       "\n",
       "                                        A_clean  \n",
       "104825           [том, надел, чёрный, парик, .]  \n",
       "100309  [я, не, такой, богатый, ,, как, том, .]  \n",
       "101889        [она, нажала, на, выключатель, .]  \n",
       "104431                   [том, в, сандалиях, .]  \n",
       "102245           [спасибо, тебе, за, помощь, .]  \n",
       "100328     [я, не, собираюсь, этого, делать, .]  \n",
       "103606          [том, сделал, 20, отжиманий, .]  \n",
       "105103               [том, потянул, лодыжку, .]  \n",
       "101231       [давай, сыграем, это, на, слух, .]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lenQ</th>\n",
       "      <th>lenA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.722400</td>\n",
       "      <td>5.270400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.737965</td>\n",
       "      <td>1.175084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               lenQ          lenA\n",
       "count  10000.000000  10000.000000\n",
       "mean       5.722400      5.270400\n",
       "std        0.737965      1.175084\n",
       "min        3.000000      2.000000\n",
       "25%        5.000000      4.000000\n",
       "50%        6.000000      5.000000\n",
       "75%        6.000000      6.000000\n",
       "max        8.000000     11.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# считаем количество слов\n",
    "pair['lenQ'] = pair['Q_clean'].str.len()\n",
    "pair['lenA'] = pair['A_clean'].str.len()\n",
    "pair.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.0, 7.0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# определяем максимальную длинну последовательности\n",
    "pair['lenQ'].quantile(0.95),  pair['lenA'].quantile(0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_clean'] = pair['Q_clean'].apply( lambda t: list(reversed(t)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_len_a_max = pair['lenA'].max()\n",
    "sent_len_q_max = pair['lenQ'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Кодируем тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 256 ms, sys: 3.05 ms, total: 259 ms\n",
      "Wall time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "w2v_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 3 156\n"
     ]
    }
   ],
   "source": [
    "w2v_q = Word2Vec( pair['Q_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)\n",
    "w2v_q_vocab = sorted([w for w in w2v_q.wv.vocab])\n",
    "ppr(w2v_q_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lady : ['middle', 'dogs', 'first', 'ready', 'yesterday']\n",
      "yours : ['!', \"there's\", 'than', 'likes', 'an']\n",
      "diagnosis : ['station', 'puzzled', 'office', 'doubts', 'coca-cola']\n",
      "funny : ['she', 'likes', 'his', 'no', 'down']\n",
      "forgave : ['teasing', 'orders', 'armpits', 'abroad', 'china']\n",
      "suffered : ['cup', 'idea', 'bed', 'doing', 'anymore']\n",
      "aunt : ['seem', 'sure', 'soon', 'open', 'book']\n",
      "fact : ['times', 'surprise', 'friend', 'contact', 'quite']\n",
      "classmates : ['hanging', 'fingers', 'breakfast', 'boat', 'respect']\n",
      "steps : ['kiss', 'am', 'pretty', 'message', 'choice']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    }
   ],
   "source": [
    "ii = np.random.permutation(len(w2v_q_vocab))[:10]\n",
    "for i in ii:\n",
    "    w = w2v_q_vocab[i]\n",
    "    ww = [ v[0] for v in w2v_q.wv.most_similar(w, topn=5) ]\n",
    "    print( w,':',ww )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 6 545\n"
     ]
    }
   ],
   "source": [
    "w2v_a = Word2Vec( pair['A_clean'].values.tolist(), min_count=1, size=w2v_size, window=4, workers=4)\n",
    "w2v_a_vocab = sorted([w for w in w2v_a.wv.vocab])\n",
    "ppr(w2v_a_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "приходил : ['стол', 'приведи', 'заслуживает', 'ненадолго', 'грызть']\n",
      "слушали : ['открывать', 'наконец', 'имеет', 'лекция', 'слышать']\n",
      "обеспечен : ['встать', 'научите', 'морковь', 'книг', 'улицы']\n",
      "даст : ['пострадать', 'кончились', 'начинаются', 'останусь', 'разобрал']\n",
      "улыбнулась : ['твои', 'будем', 'зовут', 'помощь', 'где']\n",
      "лестнице : ['сына', 'поесть', 'нужна', 'будем', 'убить']\n",
      "умнее : ['очередь', 'мысли', 'любовь', 'сесть', 'одного']\n",
      "ездит : ['слегка', 'номер', 'компьютер', 'что-нибудь', 'будь']\n",
      "вине : ['спасла', 'вычистил', 'сохнет', 'выключен', 'поприветствовал']\n",
      "вернёмся : ['включить', 'домашней', 'море', 'укусила', 'продажи']\n"
     ]
    }
   ],
   "source": [
    "ii = np.random.permutation(len(w2v_a_vocab))[:10]\n",
    "for i in ii:\n",
    "    w = w2v_a_vocab[i]\n",
    "    ww = [ v[0] for v in w2v_a.wv.most_similar(w, topn=5) ]\n",
    "    print( w,':',ww )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_code'] = pair['Q_clean'].apply(lambda t: [ w2v_q.wv.get_vector(w) for w in t ] )\n",
    "pair['A_code'] = pair['A_clean'].apply(lambda t: [ w2v_a.wv.get_vector(w) for w in t ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair[['Q_code','A_code']].sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_size = 128\n",
    "\n",
    "PAD = np.zeros(w2v_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair['Q_code'] = pair['Q_code'].apply( lambda t: [PAD]*(sent_len_q_max-len(t)) + t )\n",
    "\n",
    "encoder_input_data = np.stack( pair['Q_code'].values ).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input_data[1,-9:,:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = np.ones(w2v_size)*3\n",
    "EOS = np.ones(w2v_size)*-3\n",
    "\n",
    "sent_len_a_max+=2\n",
    "pair['A_code'] = pair['A_code'].apply( lambda t: [GO] + t + [EOS] + [PAD]*(sent_len_a_max-len(t)-2)  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000, 8, 128), (10000, 12, 128), (10000, 12, 128))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data = np.stack( pair['A_code'].values )[:,:-1,:].astype(np.float32)\n",
    "decoder_target_data = np.stack( pair['A_code'].values )[:,1:,:].astype(np.float32)\n",
    "\n",
    "encoder_input_data.shape, decoder_input_data.shape, decoder_target_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_input_data[2,:11,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Строим нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 256  # размер сети"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "encoder_inputs = Input(shape=(None, w2v_size))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "def custom_activation(x):  return (K.tanh(x) * 4)\n",
    "\n",
    "# model.add(Dense(32 , activation=custom_activation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = Input(shape=(None, w2v_size))\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "\n",
    "# decoder_dense = Dense(w2v_size)\n",
    "# decoder_dense = Dense(w2v_size, activation='softmax')\n",
    "# decoder_dense = Dense(w2v_size, activation='tanh')\n",
    "# decoder_dense = Dense(w2v_size, activation='sigmoid')\n",
    "decoder_dense = Dense(w2v_size, activation=custom_activation)\n",
    "\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 128)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 394240      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  394240      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 128)    32896       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 821,376\n",
      "Trainable params: 821,376\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/keras/utils/losses_utils.py:170: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "model.compile(loss='mse', optimizer='rmsprop')\n",
    "# model.compile(loss='mse', optimizer='adam')\n",
    "# model.compile(loss='mse', optimizer='sgd')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9000 samples, validate on 1000 samples\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "9000/9000 [==============================] - 11s 1ms/sample - loss: 0.3096 - val_loss: 0.1659\n",
      "Epoch 2/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.1204 - val_loss: 0.1410\n",
      "Epoch 3/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0912 - val_loss: 0.1305\n",
      "Epoch 4/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0798 - val_loss: 0.1122\n",
      "Epoch 5/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0710 - val_loss: 0.0946\n",
      "Epoch 6/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0639 - val_loss: 0.0919\n",
      "Epoch 7/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0573 - val_loss: 0.0787\n",
      "Epoch 8/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0526 - val_loss: 0.0827\n",
      "Epoch 9/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0474 - val_loss: 0.0680\n",
      "Epoch 10/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0435 - val_loss: 0.0622\n",
      "Epoch 11/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0403 - val_loss: 0.0586\n",
      "Epoch 12/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0381 - val_loss: 0.0632\n",
      "Epoch 13/50\n",
      "9000/9000 [==============================] - 9s 1ms/sample - loss: 0.0355 - val_loss: 0.0630\n",
      "Epoch 14/50\n",
      "9000/9000 [==============================] - 9s 1ms/sample - loss: 0.0355 - val_loss: 0.0595\n",
      "Epoch 15/50\n",
      "9000/9000 [==============================] - 9s 1ms/sample - loss: 0.0348 - val_loss: 0.0582\n",
      "Epoch 16/50\n",
      "9000/9000 [==============================] - 9s 1ms/sample - loss: 0.0323 - val_loss: 0.0577\n",
      "Epoch 17/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0310 - val_loss: 0.0536\n",
      "Epoch 18/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0304 - val_loss: 0.0566\n",
      "Epoch 19/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0295 - val_loss: 0.0626\n",
      "Epoch 20/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0287 - val_loss: 0.0605\n",
      "Epoch 21/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0280 - val_loss: 0.0541\n",
      "Epoch 22/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0276 - val_loss: 0.0516\n",
      "Epoch 23/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0259 - val_loss: 0.0574\n",
      "Epoch 24/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0257 - val_loss: 0.0538\n",
      "Epoch 25/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0243 - val_loss: 0.0562\n",
      "Epoch 26/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0242 - val_loss: 0.0587\n",
      "Epoch 27/50\n",
      "9000/9000 [==============================] - 11s 1ms/sample - loss: 0.0234 - val_loss: 0.0572\n",
      "Epoch 28/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0231 - val_loss: 0.0615\n",
      "Epoch 29/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0224 - val_loss: 0.0552\n",
      "Epoch 30/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0218 - val_loss: 0.0549\n",
      "Epoch 31/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0212 - val_loss: 0.0534\n",
      "Epoch 32/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0204 - val_loss: 0.0547\n",
      "Epoch 33/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0214 - val_loss: 0.0533\n",
      "Epoch 34/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0196 - val_loss: 0.0755\n",
      "Epoch 35/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0193 - val_loss: 0.0771\n",
      "Epoch 36/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0191 - val_loss: 0.0514\n",
      "Epoch 37/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0183 - val_loss: 0.0963\n",
      "Epoch 38/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0184 - val_loss: 0.0537\n",
      "Epoch 39/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0177 - val_loss: 0.0548\n",
      "Epoch 40/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0178 - val_loss: 0.0543\n",
      "Epoch 41/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0166 - val_loss: 0.0679\n",
      "Epoch 42/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0166 - val_loss: 0.0623\n",
      "Epoch 43/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0158 - val_loss: 0.0639\n",
      "Epoch 44/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0162 - val_loss: 0.0628\n",
      "Epoch 45/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0154 - val_loss: 0.0568\n",
      "Epoch 46/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0150 - val_loss: 0.0631\n",
      "Epoch 47/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0147 - val_loss: 0.0538\n",
      "Epoch 48/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0144 - val_loss: 0.0688\n",
      "Epoch 49/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0137 - val_loss: 0.0586\n",
      "Epoch 50/50\n",
      "9000/9000 [==============================] - 10s 1ms/sample - loss: 0.0132 - val_loss: 0.0587\n",
      "CPU times: user 4min 58s, sys: 1min 50s, total: 6min 49s\n",
      "Wall time: 8min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=100,\n",
    "          epochs=50,\n",
    "          validation_split=0.1\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проверяем результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # генерируем состояние энкодера\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # вход декодера - последовательность из одного слова GO\n",
    "    # output_w2v = w2v_a.wv['<GO>'].reshape([1,1,w2v_size])\n",
    "    output_w2v = GO.reshape([1,1,w2v_size])\n",
    "\n",
    "    # выходная последовательность\n",
    "    decoded_sentence = []\n",
    "    \n",
    "    for i in range(sent_len_a_max): \n",
    "        output_w2v, h, c = decoder_model.predict([output_w2v] + states_value)\n",
    "        \n",
    "        # декодируем cлово\n",
    "        cc = output_w2v.reshape(w2v_size)\n",
    "\n",
    "        tt=cc-EOS\n",
    "        ett = tt.dot(tt.T)/w2v_size\n",
    "        \n",
    "        # print(ett)\n",
    "        # если очередное код слова это EOS\n",
    "        if(ett<2.1): break # то завершаем работу\n",
    "        \n",
    "        w = w2v_a.wv.similar_by_vector(cc)[0][0] \n",
    "                \n",
    "        decoded_sentence.append(w)\n",
    "\n",
    "        # обновляем состояние сети\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return ' '.join(decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You know what they say.  ->  получил рыбалку господина рыбалку плавать приняли пешком приняли скучал сильнее вслепую пойдёшь борту\n",
      "I'm not sure I'm ready.  ->  слегка шанс рыбалку правильно рыбалку продолжать сильнее вслепую пойдёшь борту пробыли останется усну\n",
      "Tom is driving me nuts.  ->  слегка следующего передал мою отдай дворе пойдёшь говорила пойдёшь входили останется водить начинали\n",
      "Are you taller than Tom?  ->  вашего добьётся замечание дневник пловцов продолжать\n",
      "Don't believe the media.  ->  получил приняли фотогеничны мою\n",
      "Tell me you'll do that.  ->  скучает рыбалку рыбалку рыбалку рыбалку приняли видел рыбалку скучал пойдёшь разумно пробыли несовершеннолетний\n",
      "Tom is in great danger.  ->  слегка кошка пойдёшь боитесь пора\n",
      "I've got to keep going.  ->  получил рыбалку придёт французский туда рыбалку расскажи слегка столько приняли продолжать приняли вслепую\n",
      "He loves no one but her.  ->  слегка кошка просите правильно рыбалку скучал приняли продолжать пойдёшь говорила\n",
      "You knew I was married.  ->  получил рыбалку придёт рыбалку плавать приняли скучал приняли вслепую час отмычка пробыли отмычка\n"
     ]
    }
   ],
   "source": [
    "ii = np.random.permutation(len(encoder_input_data))[:10]\n",
    "for seq_index in ii:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print( pair.iloc[seq_index]['Q'],' -> ', decoded_sentence )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_dict = history.history\n",
    "# history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # acc = history.history['acc']\n",
    "# #val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(1, len(loss) + 1)\n",
    "# plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "# plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()   # clear figure\n",
    "# acc_values = history_dict['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "# plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q_min = encoder_input_data.min()\n",
    "# q_max = encoder_input_data.max()\n",
    "# encoder_input_data = (encoder_input_data-q_min)/(q_max-q_min)\n",
    "\n",
    "# q_fact = np.max( [np.abs(encoder_input_data.max()), np.abs(encoder_input_data.min())] )\n",
    "# encoder_input_data = encoder_input_data/q_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input_data.min(),encoder_input_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a_min = decoder_input_data.min()\n",
    "# a_max = decoder_input_data.max()\n",
    "# decoder_input_data  = (decoder_input_data-a_min)/(a_max-a_min)\n",
    "# decoder_target_data = (decoder_target_data-a_min)/(a_max-a_min)\n",
    "\n",
    "# a_fact = np.max( [np.abs(decoder_input_data.max()), np.abs(decoder_input_data.min())] )\n",
    "# decoder_input_data  = decoder_input_data/a_fact\n",
    "# decoder_target_data = decoder_target_data/a_fact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_target_data.min(),decoder_target_data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PAD \n",
    "\n",
    "# x = np.array(range(1,7)).reshape([2,3])\n",
    "# np.pad(x,[[0,3],[0,0]],'constant',constant_values=0)\n",
    "\n",
    "# a = [[1, 2], [3, 4]]\n",
    "# >>> np.pad(a, ((3, 2), (2, 3)), 'minimum')\n",
    "# array([[1, 1, 1, 2, 1, 1, 1],\n",
    "#        [1, 1, 1, 2, 1, 1, 1],\n",
    "#        [1, 1, 1, 2, 1, 1, 1],\n",
    "#        [1, 1, 1, 2, 1, 1, 1],\n",
    "#        [3, 3, 3, 4, 3, 3, 3],\n",
    "#        [1, 1, 1, 2, 1, 1, 1],\n",
    "#        [1, 1, 1, 2, 1, 1, 1]])\n",
    "# A = np.array([1,2,3,4,5])\n",
    "# np.pad(A, (0, 3), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # выбираем последовательности средней длинны\n",
    "# # sent_len_min, sent_len_max = 7,10\n",
    "# sent_len_min, sent_len_max = 5,12\n",
    "\n",
    "# ppr(pair)\n",
    "# pair = pair[\n",
    "#     pair['lenQ'].between(sent_len_min,sent_len_max) \n",
    "#     & pair['lenA'].between(sent_len_min,sent_len_max) \n",
    "#   ]\n",
    "# ppr(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # выстраиваем входные последовательности в обратном порядке\n",
    "# # и выравниваем длинну последовательностей,\n",
    "# # дополняем короткие словом \"служебным\" словом,\n",
    "# pad = ['<PAD>']*sent_len_q_max\n",
    "# # pair['Q_clean'] = pair['Q_clean'].apply( lambda t: pad[len(t):] + list(reversed(t)) )\n",
    "# pair['Q_clean'] = pair['Q_clean'].apply( lambda t: t + pad[len(t):] )\n",
    "\n",
    "# pad = ['<PAD>']*sent_len_a_max\n",
    "# pair['A_clean'] = pair['A_clean'].apply( lambda t: t + pad[len(t):] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair[['Q_clean','A_clean']].sample(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair['A_code'] = pair['A_code'].apply( \n",
    "#     lambda t: np.pad( np.array([GO]+t+[EOS]),\n",
    "#                       [[0,sent_len_a_max-len(t)+2,],[0,0]],\n",
    "#                       mode='constant',\n",
    "#                       constant_values=0) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pair['Q_clean'] = pair['Q_clean'].apply( lambda t: t + pad[len(t):] )\n",
    "\n",
    "# pair['Q_code'] = pair['Q_code'].apply( \n",
    "#     lambda t: np.pad( np.array(t),\n",
    "#                       [[sent_len_q_max-len(t),0],[0,0]],\n",
    "#                       mode='constant',\n",
    "#                       constant_values=0) )\n",
    "\n",
    "# encoder_input_data = np.stack( pair['Q_code'].values ).astype(np.float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
