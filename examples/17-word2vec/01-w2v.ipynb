{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**извлечение признаков из текста на естественном языке: word2vec**\n",
    "\n",
    "Евгений Борисов borisov.e@solarl.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import gzip\n",
    "import numpy as np\n",
    "# import scipy.io\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загружаем предварительно очищенный текст\n",
    "# разрезаем текст на слова\n",
    "# удаляем пустые элементы\n",
    "with gzip.open('../data/text/text.txt.gz','rt') as f: \n",
    "    text = [ w for w in f.read().split() if w ]\n",
    "    \n",
    "# text    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(set(text)) # словарь из текста\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # сохраняем словарь\n",
    "# with open(\"result/words.txt\", \"w\") as f:\n",
    "#     for w in words:\n",
    "#         f.write(\"%s\\n\"%w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заменяем слова в тексте их номерами в словаре\n",
    "vocab =  { words[i]:i for i in range(0,len(words)) }\n",
    "code = [ vocab[w] for w in text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "размер словаря: 355 слов\n",
      "размер текста: 556 слов\n"
     ]
    }
   ],
   "source": [
    "n = len(words) # количество слов в словаре\n",
    "m = len(code) # количество слов в тексте \n",
    "print( \"размер словаря: %i слов\" % n )\n",
    "print( \"размер текста: %i слов\" % m )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# унитарное кодирование словаря (one-hot-encoding)\n",
    "Ve = np.eye( n ) \n",
    "\n",
    "# кодированный текст (последовательность кодов слов)\n",
    "Te = Ve[code,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# формируем учебный набор...\n",
    "\n",
    "c = 3  # размер окна контекста, количество слов перед текущим словом и после него\n",
    "W = [] # слова\n",
    "C = [] # контекст для слов\n",
    "\n",
    "for i in range(c,m-c) :\n",
    "    W.append( Te[i,:] ) # код текущего слова\n",
    "    # контекст для текущего слова\n",
    "    C.append( np.vstack( ( Te[i-c:i,:] , Te[i+1:i+c+1,:] ) ).reshape(1,2*c,n) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 355)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.vstack(W)\n",
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(550, 6, 355)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = np.concatenate(C)\n",
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.savez( \"result/data.npz\", W=W, C=C )\n",
    "# scipy.io.savemat(\"result/data.mat\", dict(W=W, C=C))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ф-ция активации скрытого слоя - линейная\n",
    "# def act(s): return s\n",
    "\n",
    "# ф-ция активации выходного слоя\n",
    "def softmax(s): \n",
    "    e = np.exp(s)\n",
    "    return e/e.sum(axis=1).reshape(s.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_step(W,Vi,Vo):\n",
    "    H = W.dot(Vi) # значения скрытого слоя\n",
    "    U = H.dot(Vo) # состояния выходного слоя\n",
    "    O = softmax(U) # выход сети\n",
    "    return H,U,O\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция потери на учебном примере $i$\n",
    "\n",
    "$$E_i = \\left| \\log\\left( \\sum\\limits_i \\exp(U_i) \\right) - \\sum\\limits_i\\sum\\limits_j (U_i * Q_{ij}) \\right| $$\n",
    "\n",
    "\n",
    "$U_{i}$ состояние выходного слоя для слова $i$     \n",
    "$Q_{ij}$ слово $j$ контекста слова $i$   \n",
    "где ∗ - операция поэлементного умножения векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function [v,w] = w2v_weigth_init(n,k),\n",
    "#    % n = 10 ; % количество слов в словаре\n",
    "#    % k = 30 ; % размер скрытого слоя H\n",
    "#    v = normrnd( zeros(n,k),ones(n,k)*1e-2 ) ; % веса связей от входного к скрытому слою\n",
    "#    w = normrnd( zeros(k,n),ones(k,n)*1e-2 ) ; % веса связей от скрытого к выходному слою\n",
    "# endfunction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function [vn,wn] = w2v_weigth_norm(v,w) ;\n",
    "#    n = norm( [ v(:), w(:) ] ) ;\n",
    "#    vn = v./n;\n",
    "#    wn = w./n;\n",
    "# endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function [vn,wn] = w2v_weigth_add(v,w,dv,dw,a),\n",
    "#    vn = v + dv.*a ;\n",
    "#    wn = w + dw.*a ; \n",
    "# endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_loss(U,C):\n",
    "    n,v,cws = C.shape \n",
    "        # количество примеров\n",
    "        # количество слов в словаре\n",
    "        # размер окна контекста   \n",
    "    \n",
    "    Us = np.log( np.exp(U).sum(axis=1) ).sum(axis=0) ;\n",
    "    \n",
    "    Uo = 0.0;\n",
    "    for i in range(cws): # для всех слов контекста\n",
    "        Ci = C[:,i,:].reshape([n,v]) # набор слов контекста i\n",
    "        Uo += (U*Ci).sum() # значения выходного слоя для слов x контекста i\n",
    "    \n",
    "    return np.abs(Us-Uo)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_grad(C,W,H,O,Vo):\n",
    "    s = C.shape # размеры набора слов контекста\n",
    "    cws = s[1] # размер окна контекста \n",
    "    # sw = Vo.shape # размеры матрицы связей выходного слоя\n",
    "\n",
    "    gVi = gVo = 0.0 \n",
    "    \n",
    "    for i in range(cws):\n",
    "        Ci = C[:,i,:].reshape( s([1,3]) ) # слово i контекста\n",
    "        D = O - Ci # ошибка на слове контекста i\n",
    "        gVo += H.T.dot(D)\n",
    "        gVi += D.T.dot(W).dot(Vo.T)  \n",
    "    \n",
    "    return gVi,gVo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2v_fit_skip_gram\n",
    "#  вычисляем состояния слоёв и выход\n",
    "#  вычисляем ошибку\n",
    "#  вычисляем градиент ф-ции потери\n",
    "#  нормируем значения градиента\n",
    "#  корректируем веса\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# % - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - \n",
    "# function [Vi0,Vo0,er] = w2v_fit_skip_gram(C,W,Vi,Vo),\n",
    "#    a = 0.91; % скорость обучения\n",
    "\n",
    "#    nn = 1000 ;\n",
    "#    er = [ 1e10 ] ; % история изменения ошибки\n",
    "#    for i=1:nn,\n",
    "#       [H,U,O] = w2v_step(W,Vi,Vo) ; % вычисляем состояния слоёв и выход\n",
    "\n",
    "#       er(end+1) = w2v_loss(U,C) ; % вычисляем ошибку \n",
    "#       printf(\"[i] эпоха %i/%i, ошибка обучения: %f     \\r\",i,nn, er(end)) ;\n",
    "\n",
    "#       if( er(end-1) < er(end) ) break; endif; % если ошибка растёт то останавливаем обучение \n",
    "\n",
    "#       [gVi,gVo] = w2v_grad(C,W,H,O,Vo) ; % вычисляем градиент ф-ции потери\n",
    "\n",
    "#       [gVi,gVo] = w2v_weigth_norm(gVi,gVo) ; % нормируем значения градиента\n",
    "\n",
    "#       Vi0 = Vi ; \n",
    "#       Vo0 = Vo ; \n",
    "\n",
    "#       [Vi,Vo] = w2v_weigth_add(Vi,Vo,gVi,gVo,-a) ; % корректируем веса\n",
    "#    endfor\n",
    "\n",
    "#    er(1) = [] ;\n",
    "#    er(end) = [] ;\n",
    "\n",
    "#    printf(\"[i] эпоха %i/%i, ошибка обучения: %f     \\n\",i,nn, er(end)) ;\n",
    "\n",
    "# endfunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # выход сети\n",
    "# def run(x,Vi,Vo): return softmax( x.dot(Vi).dot(Vo) )\n",
    "\n",
    "\n",
    "# # прямой проход\n",
    "# def forward(x,Vi,Vo):\n",
    "#     L = [ x.dot(Vi) ] # состояние (не активированное) скрытого слоя\n",
    "#     L.append( L[0].dot(Vo) ) # состояние (не активированное) выходного слоя\n",
    "#     return L\n",
    "\n",
    "\n",
    "# # обратный проход\n",
    "# def backward(L,y):\n",
    "#     O = act(L[1]) # выход сети\n",
    "#     E = [ (O-y)*act_drv(L[1]) ] # ошибка выходного слоя\n",
    "#     E.insert(0, E[0].dot(W1.T)*act_drv(L[0]) ) # ошибка скрытого слоя\n",
    "#     return E\n",
    "\n",
    "\n",
    "# # градиент\n",
    "# def grad(L,E):\n",
    "#     GW = [ X.T.dot(E[0]) ] # градиент по весам скрытого слоя\n",
    "#     GS = [ E[0].sum(axis=0) ] # градиент по сдвигам скрытого слоя\n",
    "\n",
    "#     O = act(L[0]) # выход скрытого слоя\n",
    "#     GW.append( O.T.dot(E[1]) ) # градиент по весам выходного слоя\n",
    "#     GS.append( E[1].sum(axis=0) ) # градиент по сдвигам выходного слоя\n",
    "\n",
    "#     return GW,GS\n",
    "\n",
    "\n",
    "# # нормируем градиент\n",
    "# def grad_norm(gw,gs):\n",
    "#     mw = np.abs(np.hstack([ gw[0].flatten(), gw[1].flatten(), gs[0], gs[1], ])).max()\n",
    "        \n",
    "#     if mw != 0.0:\n",
    "#         gw[0] /= mw\n",
    "#         gw[1] /= mw\n",
    "#         gs[0] /= mw\n",
    "#         gs[1] /= mw\n",
    "    \n",
    "#     return gw,gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # инициализация весов и сдвигов\n",
    "# W0 = np.random.normal(loc=0.0, scale=0.1, size=[X.shape[1],s_layer])\n",
    "# S0 = np.zeros(s_layer)\n",
    "\n",
    "# W1 = np.random.normal(loc=0.0, scale=0.1, size=[s_layer,y.shape[1] ])\n",
    "# S1 = np.zeros(y.shape[1])\n",
    "\n",
    "# # метод градиентного спуска\n",
    "\n",
    "# a=0.05 # скорость обучения\n",
    "# r=0.001 # регуляризация\n",
    "# m=0.001 # момент\n",
    "\n",
    "# # ex_count = X.shape[0]   # количество примеров\n",
    "\n",
    "# # максимальное число циклов обучения\n",
    "# MAX_ITER = 800\n",
    "\n",
    "# MIN_ERROR = 0.1 # порог минимальной ошибки\n",
    "\n",
    "# err =[1e7] \n",
    "\n",
    "# dW1=dW0=dS0=dS1=0.0\n",
    "\n",
    "# for i in range(MAX_ITER):\n",
    "#     O = run(X) # выход сети\n",
    "#     err.append( loss(O,y) ) # история значений ф-ции потери\n",
    "    \n",
    "#     if err[-1] < MIN_ERROR: # проверяем достижение порога\n",
    "#         break\n",
    "\n",
    "#     L=forward(X) # прямой проход\n",
    "#     E=backward(L,y) # обратный проход\n",
    "#     GW,GS = grad(L,E) # градиент\n",
    "#     GW,GS = grad_norm(GW,GS) # нормируем градиент\n",
    "    \n",
    "    \n",
    "#     dW0 = a*( GW[0]+ r*W0 ) + m*dW0\n",
    "#     dW1 = a*( GW[1]+ r*W1 ) + m*dW1\n",
    "#     dS0 = a*GS[0]+ m*dS0\n",
    "#     dS1 = a*GS[1]+ m*dS1\n",
    "    \n",
    "#     # изменяем веса и сдвиги\n",
    "#     W0 -= dW0\n",
    "#     W1 -= dW1 \n",
    "#     S0 -= dS0\n",
    "#     S1 -= dS1\n",
    "\n",
    "# print('step:',i,'/',MAX_ITER)\n",
    "# print('error:',err[-1],'/',MIN_ERROR)\n",
    "\n",
    "# # изменение ошибки обучения\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.plot(err[2:])\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
