{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# '''\n",
    "# #Sequence to sequence example in Keras (character-level).\n",
    "\n",
    "# This script demonstrates how to implement a basic character-level\n",
    "# sequence-to-sequence model. We apply it to translating\n",
    "# short English sentences into short French sentences,\n",
    "# character-by-character. Note that it is fairly unusual to\n",
    "# do character-level machine translation, as word-level\n",
    "# models are more common in this domain.\n",
    "\n",
    "# **Summary of the algorithm**\n",
    "\n",
    "# - We start with input sequences from a domain (e.g. English sentences)\n",
    "#     and corresponding target sequences from another domain\n",
    "#     (e.g. French sentences).\n",
    "# - An encoder LSTM turns input sequences to 2 state vectors\n",
    "#     (we keep the last LSTM state and discard the outputs).\n",
    "# - A decoder LSTM is trained to turn the target sequences into\n",
    "#     the same sequence but offset by one timestep in the future,\n",
    "#     a training process called \"teacher forcing\" in this context.\n",
    "#     It uses as initial state the state vectors from the encoder.\n",
    "#     Effectively, the decoder learns to generate `targets[t+1...]`\n",
    "#     given `targets[...t]`, conditioned on the input sequence.\n",
    "# - In inference mode, when we want to decode unknown input sequences, we:\n",
    "#     - Encode the input sequence into state vectors\n",
    "#     - Start with a target sequence of size 1\n",
    "#         (just the start-of-sequence character)\n",
    "#     - Feed the state vectors and 1-char target sequence\n",
    "#         to the decoder to produce predictions for the next character\n",
    "#     - Sample the next character using these predictions\n",
    "#         (we simply use argmax).\n",
    "#     - Append the sampled character to the target sequence\n",
    "#     - Repeat until we generate the end-of-sequence character or we\n",
    "#         hit the character limit.\n",
    "\n",
    "# **Data download**\n",
    "\n",
    "# [English to French sentence pairs.\n",
    "# ](http://www.manythings.org/anki/fra-eng.zip)\n",
    "\n",
    "# [Lots of neat sentence pairs datasets.\n",
    "# ](http://www.manythings.org/anki/)\n",
    "\n",
    "# **References**\n",
    "\n",
    "# - [Sequence to Sequence Learning with Neural Networks\n",
    "#    ](https://arxiv.org/abs/1409.3215)\n",
    "# - [Learning Phrase Representations using\n",
    "#     RNN Encoder-Decoder for Statistical Machine Translation\n",
    "#     ](https://arxiv.org/abs/1406.1078)\n",
    "# '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 100 # Number of epochs to train for.\n",
    "latent_dim = 256  # Latent dimensionality of the encoding space.\n",
    "num_samples = 10000  # Number of samples to train on.\n",
    "# Path to the data txt file on disk.\n",
    "data_path = '../data/text/rus-eng/rus.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 10000\n",
      "Number of unique input tokens: 72\n",
      "Number of unique output tokens: 92\n",
      "Max sequence length for inputs: 14\n",
      "Max sequence length for outputs: 60\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'rt', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "    \n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters = sorted(list(input_characters))\n",
    "target_characters = sorted(list(target_characters))\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_token_index = dict( [(char, i) for i, char in enumerate(input_characters)])\n",
    "# target_token_index = dict( [(char, i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "input_token_index = { char:i for i, char in enumerate(input_characters) }\n",
    "target_token_index = { char:i  for i, char in enumerate(target_characters) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_token_index\n",
    "# target_token_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros( (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype='float32')\n",
    "decoder_input_data = np.zeros( (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')\n",
    "decoder_target_data = np.zeros((len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "        \n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, None, 72)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, None, 92)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 256), (None, 336896      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, None, 256),  357376      input_2[0][0]                    \n",
      "                                                                 lstm_1[0][1]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 92)     23644       lstm_2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 717,916\n",
      "Trainable params: 717,916\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 25s 3ms/step - loss: 0.7440 - val_loss: 0.7862\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.6189 - val_loss: 0.6523\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.5311 - val_loss: 0.6008\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.4898 - val_loss: 0.5688\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.4603 - val_loss: 0.5531\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.4352 - val_loss: 0.5275\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.4144 - val_loss: 0.5183\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.3959 - val_loss: 0.5061\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.3785 - val_loss: 0.4928\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 24s 3ms/step - loss: 0.3628 - val_loss: 0.4826\n",
      "CPU times: user 2min 56s, sys: 1min 3s, total: 4min\n",
      "Wall time: 3min 59s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "# model.save('s2s.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next: inference mode (sampling).\n",
    "# Here's the drill:\n",
    "# 1) encode input and retrieve initial decoder state\n",
    "# 2) run one step of decoder with this initial state\n",
    "# and a \"start of sequence\" token as target.\n",
    "# Output will be the next target token\n",
    "# 3) Repeat with the current target token and current states\n",
    "\n",
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model( [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reverse-lookup token index to decode sequences back to something readable.\n",
    "# reverse_input_char_index = dict(  (i, char) for char, i in input_token_index.items())\n",
    "# reverse_target_char_index = dict( (i, char) for char, i in target_token_index.items())\n",
    "\n",
    "reverse_input_char_index = { i:char for char,i in input_token_index.items() }\n",
    "reverse_target_char_index = { i:char for char,i in target_token_index.items() }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're fired.  ->  Ты страсный.\n",
      "\n",
      "I'm so proud.  ->  Я не постраен.\n",
      "\n",
      "He relented.  ->  Он пострелил.\n",
      "\n",
      "It's fun.  ->  Это странно.\n",
      "\n",
      "They help us.  ->  Они победили.\n",
      "\n",
      "You're vain.  ->  Ты страсный.\n",
      "\n",
      "Ask around.  ->  Подерь это.\n",
      "\n",
      "Stop here.  ->  Постаньте его.\n",
      "\n",
      "We're inside.  ->  Мы победием.\n",
      "\n",
      "I apologize.  ->  Я пострали.\n",
      "\n",
      "It was useful.  ->  Это было прасто.\n",
      "\n",
      "I'm cured.  ->  Я не постраен.\n",
      "\n",
      "Go back home.  ->  Иди за мно.\n",
      "\n",
      "Replace it.  ->  Поделжайтесь.\n",
      "\n",
      "He made me go.  ->  Он пострали.\n",
      "\n",
      "I'll miss Tom.  ->  Я пострали.\n",
      "\n",
      "He dug a hole.  ->  Он пострали.\n",
      "\n",
      "We're scared.  ->  Мы победием.\n",
      "\n",
      "Don't forget.  ->  Не простивей.\n",
      "\n",
      "Wake them up.  ->  Подолжайте споть.\n",
      "\n",
      "Stay there.  ->  Поделжайтесь.\n",
      "\n",
      "I need a hat.  ->  Я победула.\n",
      "\n",
      "We feel safe.  ->  Мы победили.\n",
      "\n",
      "Keep trying.  ->  Продолжайте споть.\n",
      "\n",
      "Smell this.  ->  Позволи Тома.\n",
      "\n",
      "It works.  ->  Это было прасто.\n",
      "\n",
      "Pick him up.  ->  Подомите его.\n",
      "\n",
      "Who'll come?  ->  Кто победил?\n",
      "\n",
      "I'm thin.  ->  Я не постраен.\n",
      "\n",
      "I'm a singer.  ->  Я не постраен.\n",
      "\n",
      "Was I wrong?  ->  Можно может пойдить?\n",
      "\n",
      "We are boys.  ->  Мы победили.\n",
      "\n",
      "Tom is crazy.  ->  Том пострелил.\n",
      "\n",
      "Is Tom hungry?  ->  Это странно.\n",
      "\n",
      "Tom needs it.  ->  Том померял.\n",
      "\n",
      "I'm a waiter.  ->  Я не постраен.\n",
      "\n",
      "I'm shocked.  ->  Я не постраен.\n",
      "\n",
      "I am afraid.  ->  Я не пострали.\n",
      "\n",
      "Take care.  ->  Возьми мое.\n",
      "\n",
      "I felt awful.  ->  Я подела себя.\n",
      "\n",
      "God bless you!  ->  Иди за мно.\n",
      "\n",
      "Call a doctor.  ->  Позволи Тома.\n",
      "\n",
      "I need a coat.  ->  Я не постали.\n",
      "\n",
      "Taste it.  ->  Попробуйте это.\n",
      "\n",
      "Stop it.  ->  Простать его.\n",
      "\n",
      "It had snowed.  ->  Это было прасто.\n",
      "\n",
      "You know me.  ->  Ты может пойти.\n",
      "\n",
      "I am hungry.  ->  Я не пострали.\n",
      "\n",
      "Get lost.  ->  Постовайтесь.\n",
      "\n",
      "I'm loaded.  ->  Я не постраен.\n",
      "\n",
      "You're vain.  ->  Ты страсный.\n",
      "\n",
      "You may go.  ->  Ты может пойти.\n",
      "\n",
      "I know now.  ->  Я постоваю.\n",
      "\n",
      "I miss you.  ->  Я не постраен.\n",
      "\n",
      "I'm so happy.  ->  Я не постраен.\n",
      "\n",
      "It was mine.  ->  Это было прасто.\n",
      "\n",
      "I was angry.  ->  Я пострали.\n",
      "\n",
      "I was unlucky.  ->  Я победула.\n",
      "\n",
      "I was invited.  ->  Я пострали.\n",
      "\n",
      "Can you wait?  ->  Вы может пойти?\n",
      "\n",
      "I'm awake.  ->  Я не постраен.\n",
      "\n",
      "Take it back.  ->  Возьми мое.\n",
      "\n",
      "Go sit down.  ->  Иди за мно.\n",
      "\n",
      "We hired Tom.  ->  Мы победили.\n",
      "\n",
      "We are men.  ->  Мы победили.\n",
      "\n",
      "Do they know?  ->  Не победите?\n",
      "\n",
      "I'm not fat.  ->  Я не постраен.\n",
      "\n",
      "I'm ruthless.  ->  Я не постраен.\n",
      "\n",
      "I'll go home.  ->  Я пострали.\n",
      "\n",
      "Tom told him.  ->  Том пострелил.\n",
      "\n",
      "You're sick!  ->  Ты страсный.\n",
      "\n",
      "I rescued her.  ->  Я пострали.\n",
      "\n",
      "We must act.  ->  Мы победили.\n",
      "\n",
      "Shame on you.  ->  Подель это.\n",
      "\n",
      "You're fired.  ->  Ты страсный.\n",
      "\n",
      "Is it broken?  ->  Это странно.\n",
      "\n",
      "That's hers.  ->  Это тровот.\n",
      "\n",
      "Don't respond.  ->  Не простивей.\n",
      "\n",
      "Tom teaches.  ->  Том пострелил.\n",
      "\n",
      "Will you go?  ->  Подель?\n",
      "\n",
      "I am so sick.  ->  Я не пострали.\n",
      "\n",
      "Pick a card.  ->  Подель стакайте.\n",
      "\n",
      "Get well soon!  ->  Постовите Тома.\n",
      "\n",
      "She's stupid.  ->  Она победил.\n",
      "\n",
      "Are you cold?  ->  Ты в безпаести?\n",
      "\n",
      "Tom loves us.  ->  Том пострелил.\n",
      "\n",
      "I was wet.  ->  Я пострали.\n",
      "\n",
      "Why not both?  ->  Кто победил?\n",
      "\n",
      "We're back.  ->  Мы победием.\n",
      "\n",
      "It's bad news.  ->  Это странно.\n",
      "\n",
      "They hate me.  ->  Они победили.\n",
      "\n",
      "I saw him cry.  ->  Я пострали.\n",
      "\n",
      "Stay alert.  ->  Поделжайтесь.\n",
      "\n",
      "I'm a liar.  ->  Я не постраен.\n",
      "\n",
      "I'll stop.  ->  Я пострали.\n",
      "\n",
      "Stay sharp.  ->  Поделжайте споть.\n",
      "\n",
      "I'm wet.  ->  Я не постраен.\n",
      "\n",
      "Did Tom run?  ->  Том померял?\n",
      "\n",
      "Is Tom young?  ->  Том пострал?\n",
      "\n",
      "We like Tom.  ->  Мы победили.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ii = np.random.permutation(len(encoder_input_data))[:100]\n",
    "for seq_index in ii:\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print( input_texts[seq_index],' -> ', decoded_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for seq_index in range(100):\n",
    "#     # Take one sequence (part of the training set)\n",
    "#     # for trying out decoding.\n",
    "#     input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "#     decoded_sentence = decode_sequence(input_seq)\n",
    "#     print('-')\n",
    "#     print('Input sentence:', input_texts[seq_index])\n",
    "#     print('Decoded sentence:', decoded_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'loss'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()   # clear figure\n",
    "# acc_values = history_dict['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "# plt.plot(epochs, acc, 'b', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
