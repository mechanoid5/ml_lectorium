{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**поиск в масиве текста с помощью W2V**\n",
    "\n",
    "Евгений Борисов <esborisov@sevsu.ru>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=XlEHTf93Y8w\n",
    "\n",
    "https://www.youtube.com/watch?v=aZ5se_SW81c\n",
    "\n",
    "https://github.com/girafe-ai/ml-mipt/blob/master/week1_01_word_embeddings/week01_fun_with_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__задача:__ реализовать поиск строк по запросам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__решение:__\n",
    "- кодируем слова w2v (Gensim)\n",
    "- для каждой строки агрегируем список кодов (считаем устреднённый вектор w2v)\n",
    "- кодируем слова запроса и агрегируем список кодов\n",
    "- ищем ближайшие векторы вопросов к вектору запроса (косинусная мера близости)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загружаем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import re\n",
    "import numpy as np\n",
    "from numpy import random as rng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "СТРОК: 7925\n"
     ]
    }
   ],
   "source": [
    "# загружаем текст\n",
    "with gzip.open('../data/dostoevsky-besy-p2.txt.gz','rt',encoding='utf-8') as f: text = f.read()\n",
    "# print(text[100:1000])\n",
    "text = re.split(r'\\n+', re.sub(r'([.;?!])',r'\\1\\n',text) ) \n",
    "print('\\n\\nСТРОК:',len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# применяет список замен pat к строке s\n",
    "def replace_patterns(s,pat):\n",
    "    if len(pat)<1: return s\n",
    "    return  replace_patterns( re.sub(pat[0][0],pat[0][1],s), pat[1:] )\n",
    "\n",
    "# нормализация текста\n",
    "def string_normalizer(s):\n",
    "    pat = [\n",
    "       [r'ё','е',] # замена ё для унификации\n",
    "       ,[r'[^а-я ]+',' '] # оставляем только буквы и пробел\n",
    "       ,[r'^- *',' ']\n",
    "       ,[r' +',' '] # удаляем повторы пробелов\n",
    "    ]\n",
    "    return replace_patterns(s.lower(),pat).strip()\n",
    "\n",
    "text = list(map(string_normalizer,text))\n",
    "\n",
    "# разрезаем текст на слова\n",
    "text = [ [ w.strip() for w in s.split() if w.strip() ] for s in text ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7925\n",
      "2238\n"
     ]
    }
   ],
   "source": [
    "# удаляем короткие и очень длинные строки\n",
    "print( len(text) )\n",
    "text = [ s for s in text if 7<len(s)<17  ]\n",
    "print( len(text) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "я знаю что даже кириллов который к ним почти вовсе не принадлежит доставил об вас сведения\n",
      "другого впрочем оттенка не будет вовсе приняты меры\n",
      "одно из самых последних изящнейших беллетристических вдохновений семена егоровича оно называется\n",
      "он топнул опять ногой слюня брызгала с его губ\n",
      "я во первых вовсе не такой уж мягкий а во вторых\n",
      "вскричал я догадавшись старые басни да неужто вы верили до сих пор\n",
      "я вас предупредил чтобы вы все таки имели в виду\n",
      "на некоторые жалобы и запросы положено было систематически не отвечать\n",
      "а у вас так тщательно сохранилось это письмо\n",
      "с вашим умом вы бы могли понять это в негодовании пробормотал шатов\n"
     ]
    }
   ],
   "source": [
    "for i in rng.permutation(len(text))[:10]:   print(' '.join( text[i]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## загружаем W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://nlpub.ru/Russian_Distributional_Thesaurus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -c http://panchenko.me/data/dsl-backup/w2v-ru/tenth.norm-sz500-w7-cb0-it5-min5.w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.1 s, sys: 2.43 s, total: 15.5 s\n",
      "Wall time: 15.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "w2v_file = 'w2v/tenth.norm-sz500-w7-cb0-it5-min5.w2v'\n",
    "w2v_model = KeyedVectors.load_word2vec_format(w2v_file, binary=True, unicode_errors='ignore')\n",
    "w2v_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 2641862\n"
     ]
    }
   ],
   "source": [
    "words = list(w2v_model.vocab.keys())\n",
    "vocab_size = len(words)\n",
    "print('Vocab size', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "устроимъ : ['медоваромъ', 'поeхать', 'увѣряю', 'увeрены', 'лeснымъ']\n",
      "тяжек : ['тяжел', 'тяжкий', 'долог', 'труден', 'томителен']\n",
      "запази : ['означаваше', 'ласанин', 'стайнър', 'тъга', 'задължения']\n",
      "нащупаете : ['—\\xa0просуньте', 'ощупывайте', 'ощупайте', 'уплотните', 'простучите']\n",
      "regionis : ['gotthi', 'halani', 'transeuntes', 'athanaricus', 'amplae']\n",
      "танька, — : ['полинка,\\xa0—', 'анька,\\xa0—', 'ираида,\\xa0—', '—\\xa0командирша', 'иришка,\\xa0—']\n",
      "ралайята : ['зиккур', 'дармштайн', 'гонзорской', 'элтайна', 'абадосса']\n",
      "неманципируемые : ['манципируемые', 'mancipi', 'оборотоспособности', 'суперфиций', 'непотребляемые']\n",
      "коралин : ['тайах,\\xa0–', 'поторопить,\\xa0–', 'упрямица,\\xa0–', 'риба,\\xa0–', '–\\xa0извини,–']\n",
      "посвящен, – : ['автарх,\\xa0–', 'недостаточно…\\xa0–', 'брек,\\xa0–', 'кейптауне,\\xa0–', 'куинс,\\xa0–']\n"
     ]
    }
   ],
   "source": [
    "for i in rng.permutation(vocab_size)[:10]:\n",
    "    w = words[i]\n",
    "    ww = [ v[0] for v in w2v_model.most_similar(w,topn=5) ]\n",
    "    print( w,':',ww )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## кодируем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кодируем слова w2v (Gensim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_words_encode(t): \n",
    "    return np.array([ w2v_model.get_vector(w) \n",
    "                     for w in t \n",
    "                     if w in w2v_model.vocab.keys() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "петр степанович даже не посмотрел на нее взял ножницы и начал возиться с ними  :  14 слов\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14, 500)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = rng.randint(len(text))\n",
    "\n",
    "print( ' '.join(text[i]), ' : ' , len(text[i]), 'слов' )\n",
    "\n",
    "x = w2v_words_encode( text[i] )\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для каждой строки агрегируем список кодов \n",
    "# (считаем устреднённый вектор w2v, как вариант - w2v*idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# кодируем слова запроса и агрегируем список кодов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ищем ближайшие векторы вопросов к вектору запроса (косинусная мера близости)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
