{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**классификатор текстов LSTM на Keras+TensorFlow**\n",
    "\n",
    "Евгений Борисов <borisov.e@solarl.ru>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://habr.com/ru/company/dca/blog/274027/\n",
    "# http://neuro.compute.dtu.dk/wiki/Sentiment_analysis#Corpora\n",
    "# http://help.sentiment140.com/for-students/\n",
    "# http://study.mokoron.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200  \n",
    "import re\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(d): return \"{:,.0f}\".format(d).replace(\",\", \" \")\n",
    "def ppr(d): print('записей:', pp(len(d)) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ю. В. Рубцова. Построение корпуса текстов для настройки тонового классификатора // Программные продукты и системы, 2015, №1(109), –С.72-78\n",
    "\n",
    "http://study.mokoron.com\n",
    "\n",
    "– id: уникальный номер сообщения в системе twitter;\n",
    "– tdate: дата публикации сообщения (твита);\n",
    "– tmane: имя пользователя, опубликовавшего сообщение;\n",
    "– ttext:  текст сообщения (твита);\n",
    "– ttype: поле в котором в дальнейшем будет указано к кому классу относится твит (положительный, отрицательный, нейтральный);\n",
    "– trep: количество реплаев к данному сообщению. В настоящий момент API твиттера не отдает эту информацию;\n",
    "– tfav: число сколько раз данное сообщение было добавлено в избранное другими пользователями;\n",
    "– tstcount: число всех сообщений пользователя в сети twitter;\n",
    "– tfol: количество фоловеров пользователя (тех людей, которые читают пользователя);\n",
    "– tfrien: количество друзей пользователя (те люди, которых читает пользователь);\n",
    "– listcount: количество листов-подписок в которые добавлен твиттер-пользователь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = ['id', 'tdate', 'tmane', 'ttext', 'ttype', 'trep', 'tfav', 'tstcount', 'tfol', 'tfrien', 'listcount','unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 111 923\n"
     ]
    }
   ],
   "source": [
    "neg = pd.read_csv('../data/text/twit/negative.csv.gz',sep=';',header=None)\n",
    "ppr(neg)\n",
    "neg.columns = ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 114 910\n"
     ]
    }
   ],
   "source": [
    "pos = pd.read_csv('../data/text/twit/positive.csv.gz',sep=';')\n",
    "ppr(pos)\n",
    "pos.columns = ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 226 833\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([pos,neg],sort=False)[['id','ttext', 'ttype']]\n",
    "ppr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3825</th>\n",
       "      <td>409574548292395008</td>\n",
       "      <td>Я просто не думаю, их головы в нем. =( #INSTANTFOLLOWBACK</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59589</th>\n",
       "      <td>416257774264549376</td>\n",
       "      <td>RT @katermark: @Miss_Daft Алин, этот мужчина мне спать не дает!!!((( я на всю музыку врубаю, чтобы его заглушить((((</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95342</th>\n",
       "      <td>422646008267685888</td>\n",
       "      <td>Снег вернулся в Россию из Америки ... А Sumerian records все ещё не предлагает мне контракт... Разочарования  :-(</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15730</th>\n",
       "      <td>411108356510982144</td>\n",
       "      <td>@smirnovatanyaa ахаха ну и это, а ещё мне надоело не высыпаться(</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88534</th>\n",
       "      <td>421499236702633984</td>\n",
       "      <td>так и знал,что что-то с этими пельменями не так\\nнечего было их есть\\nживот терь сильно болит(</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17500</th>\n",
       "      <td>409371681967202304</td>\n",
       "      <td>@greendayvm завалиии... он уже 3 недели ждёт, лах:D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88573</th>\n",
       "      <td>410823593216708608</td>\n",
       "      <td>RT @migeruwegida: nagios, collectd или monit? с чем я проведу ночь? :)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94301</th>\n",
       "      <td>422409301094047744</td>\n",
       "      <td>Да уж, сухари  с хот-догом, а на вкус,  как с копченой колбасой(((!!</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97664</th>\n",
       "      <td>422813678295977985</td>\n",
       "      <td>по телеку такое: \"Анна Сергеевна, вы играли Снегурочку\". эээм биг бро из уочин ми? о_О</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31711</th>\n",
       "      <td>412966033633181696</td>\n",
       "      <td>Не облизываю крышечки от актимеля, потому что оставляю их для Леи. А она осталась в другой стране с мамой. Скучаю очень по своей собаченьке(</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  \\\n",
       "3825   409574548292395008   \n",
       "59589  416257774264549376   \n",
       "95342  422646008267685888   \n",
       "15730  411108356510982144   \n",
       "88534  421499236702633984   \n",
       "17500  409371681967202304   \n",
       "88573  410823593216708608   \n",
       "94301  422409301094047744   \n",
       "97664  422813678295977985   \n",
       "31711  412966033633181696   \n",
       "\n",
       "                                                                                                                                              ttext  \\\n",
       "3825                                                                                      Я просто не думаю, их головы в нем. =( #INSTANTFOLLOWBACK   \n",
       "59589                          RT @katermark: @Miss_Daft Алин, этот мужчина мне спать не дает!!!((( я на всю музыку врубаю, чтобы его заглушить((((   \n",
       "95342                             Снег вернулся в Россию из Америки ... А Sumerian records все ещё не предлагает мне контракт... Разочарования  :-(   \n",
       "15730                                                                              @smirnovatanyaa ахаха ну и это, а ещё мне надоело не высыпаться(   \n",
       "88534                                                так и знал,что что-то с этими пельменями не так\\nнечего было их есть\\nживот терь сильно болит(   \n",
       "17500                                                                                           @greendayvm завалиии... он уже 3 недели ждёт, лах:D   \n",
       "88573                                                                        RT @migeruwegida: nagios, collectd или monit? с чем я проведу ночь? :)   \n",
       "94301                                                                          Да уж, сухари  с хот-догом, а на вкус,  как с копченой колбасой(((!!   \n",
       "97664                                                        по телеку такое: \"Анна Сергеевна, вы играли Снегурочку\". эээм биг бро из уочин ми? о_О   \n",
       "31711  Не облизываю крышечки от актимеля, потому что оставляю их для Леи. А она осталась в другой стране с мамой. Скучаю очень по своей собаченьке(   \n",
       "\n",
       "       ttype  \n",
       "3825      -1  \n",
       "59589     -1  \n",
       "95342     -1  \n",
       "15730     -1  \n",
       "88534     -1  \n",
       "17500      1  \n",
       "88573      1  \n",
       "94301     -1  \n",
       "97664     -1  \n",
       "31711     -1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext'].apply(lambda t:[ w.strip() for w in t.split() if w.strip() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'^http.*',' url ', w.strip() ) for w in t  ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'[:;]-*[)D]',' happysmile ', w.strip() )for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'\\)\\)\\)*',' happysmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'[:;]\\*',' kisssmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r':\\(',' sadsmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'\\(\\(\\(*',' sadsmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = [ ' '.join(s) for s in data['ttext_clean'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].str.lower()\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda s: re.sub( r'\\W', ' ', s))\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda s: re.sub( r'_', ' ', s))\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda s: re.sub( r'\\b\\d+\\b', ' digit ', s)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda t:[ w.strip() for w in t.split() if w.strip() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена буквенно-цифровых кодов\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t: [w for w in t if not re.match( r'\\b.*\\d+.*\\b', w) ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[['ttext_clean']]\n",
    "# data[['ttext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 151\n"
     ]
    }
   ],
   "source": [
    "with gzip.open('../data/text/stop-nltk.txt.gz','rt',encoding='utf-8') as f: \n",
    "    stopwords = set([ w.strip() for w in  f.read().split() if w.strip() ] )\n",
    "ppr(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление лишних слов\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda t:[w for w in t if w not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# from Stemmer import Stemmer\n",
    "# # pacman -S python-pystemmer\n",
    "# # pip install pystemmer\n",
    "\n",
    "# # стемминг, выделение основы слова\n",
    "# data['ttext_clean'] = data['ttext_clean'].apply( lambda t:Stemmer('russian').stemWords(t) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление коротких слов\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda t:[w for w in t if len(w)>2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[ data['ttext_clean'].str.len()<1 ][['ttext_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 226 833\n",
      "записей: 226 826\n"
     ]
    }
   ],
   "source": [
    "ppr(data)\n",
    "data = data[ data['ttext_clean'].str.len()>0 ].reset_index(drop=True) \n",
    "ppr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>ttext_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>115459</th>\n",
       "      <td>409054091214454784</td>\n",
       "      <td>@Irtnka @BilanOfficial в Билановском трио, как и Волчков у Градского, набрал 120% в общей сумме. Он по голосу и мастерству рядом не стоял(</td>\n",
       "      <td>-1</td>\n",
       "      <td>[irtnka, bilanofficial, билановском, трио, волчков, градского, набрал, digit, общей, сумме, голосу, мастерству, рядом, стоял]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48574</th>\n",
       "      <td>410018554281328640</td>\n",
       "      <td>Океан Эльзы – Я не сдамся без бою,  девиз по жизни!)</td>\n",
       "      <td>1</td>\n",
       "      <td>[океан, эльзы, сдамся, бою, девиз, жизни]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77788</th>\n",
       "      <td>410713699922771968</td>\n",
       "      <td>@KazanzevaMaria 19 баллов :)\\nНо в блазен такой пздц попался.Все бы ничего, если б словарь норм был, а тема была ehrenamtliches engagement</td>\n",
       "      <td>1</td>\n",
       "      <td>[kazanzevamaria, digit, баллов, happysmile, блазен, пздц, попался, словарь, норм, тема, ehrenamtliches, engagement]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id  \\\n",
       "115459  409054091214454784   \n",
       "48574   410018554281328640   \n",
       "77788   410713699922771968   \n",
       "\n",
       "                                                                                                                                             ttext  \\\n",
       "115459  @Irtnka @BilanOfficial в Билановском трио, как и Волчков у Градского, набрал 120% в общей сумме. Он по голосу и мастерству рядом не стоял(   \n",
       "48574                                                                                         Океан Эльзы – Я не сдамся без бою,  девиз по жизни!)   \n",
       "77788   @KazanzevaMaria 19 баллов :)\\nНо в блазен такой пздц попался.Все бы ничего, если б словарь норм был, а тема была ehrenamtliches engagement   \n",
       "\n",
       "        ttype  \\\n",
       "115459     -1   \n",
       "48574       1   \n",
       "77788       1   \n",
       "\n",
       "                                                                                                                          ttext_clean  \n",
       "115459  [irtnka, bilanofficial, билановском, трио, волчков, градского, набрал, digit, общей, сумме, голосу, мастерству, рядом, стоял]  \n",
       "48574                                                                                       [океан, эльзы, сдамся, бою, девиз, жизни]  \n",
       "77788             [kazanzevamaria, digit, баллов, happysmile, блазен, пздц, попался, словарь, норм, тема, ehrenamtliches, engagement]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## строим датасет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### дополняем и перестраиваем текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab = ['<PAD>','<START>','<UNK>'] + sorted(set([ w for t in data_train['ttext_clean'] for w in t if w ]))\n",
    "# ppr(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'] + ['<START>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_max = data['ttext_clean'].str.len().max()\n",
    "n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = ['<PAD>']*n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ttext_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>124817</th>\n",
       "      <td>[твитнуть, забуду, хотя, забуду, url, &lt;START&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65198</th>\n",
       "      <td>[allons, школы, пришла, сижу, сериал, смотрю, &lt;START&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169339</th>\n",
       "      <td>[cio, optimal, vrsoloviev, andrey, tlt, digit, разбираетесь, людях, это, святые, олигархи, радеющие, народ, свой, &lt;START&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                       ttext_clean\n",
       "124817                                                                              [твитнуть, забуду, хотя, забуду, url, <START>]\n",
       "65198                                                                       [allons, школы, пришла, сижу, сериал, смотрю, <START>]\n",
       "169339  [cio, optimal, vrsoloviev, andrey, tlt, digit, разбираетесь, людях, это, святые, олигархи, радеющие, народ, свой, <START>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['ttext_clean']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t: pad[len(t):] + list(reversed(t)) \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ttext_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>155913</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, sadsmile, собак, любит, фрэнк, кофе, любит, ше...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65402</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, happysmile, соснин...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144096</th>\n",
       "      <td>[&lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;PAD&gt;, &lt;START&gt;, sadsmile, болииииит, сильно, очень, sadsmile, sadsmile, копч...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                    ttext_clean\n",
       "155913  [<PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <START>, sadsmile, собак, любит, фрэнк, кофе, любит, ше...\n",
       "65402   [<PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <START>, happysmile, соснин...\n",
       "144096  [<PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <PAD>, <START>, sadsmile, болииииит, сильно, очень, sadsmile, sadsmile, копч..."
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[['ttext_clean']].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 s, sys: 419 ms, total: 35.8 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "w2v_size = 256\n",
    "\n",
    "w2v = Word2Vec( data['ttext_clean'].values, min_count=1, size=w2v_size, window=4, workers=4)\n",
    "\n",
    "# with open('result/Word2Vec.pkl', 'wb') as f: pickle.dump(w2v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 239 404\n"
     ]
    }
   ],
   "source": [
    "w2v_vocab = sorted([w for w in w2v.wv.vocab])\n",
    "ppr(w2v_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_code'] = data['ttext_clean'].apply(lambda t: [ w2v.wv.get_vector(w) for w in t ] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### разделяем данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 32 000\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "\n",
    "data_train = data.sample(batch_size*500).reset_index(drop=True)\n",
    "ppr(data_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 194 826\n"
     ]
    }
   ],
   "source": [
    "data_test = data[ ~data['id'].isin( data_train['id'] ) ].reset_index(drop=True)\n",
    "ppr(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 31, 256)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.stack([ np.vstack(s) for s in  data_train['ttext_code'] ])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194826, 31, 256)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = np.stack([ np.vstack(s) for s in  data_test['ttext_code'] ])\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32000, 2)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = data_train['ttype'].values\n",
    "y_train = OneHotEncoder(categories='auto').fit_transform(y_train.reshape(-1,1) ).todense().astype(np.float32)\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194826, 2)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = data_test['ttype'].values\n",
    "y_test = OneHotEncoder(categories='auto').fit_transform(y_test.reshape(-1,1) ).todense().astype(np.float32)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('X.npy',X_train)\n",
    "# np.save('y.npy',y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## строим нейросеть "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_size=64\n",
    "\n",
    "data_dim = X_train.shape[2]\n",
    "time_steps = X_train.shape[1]\n",
    "num_classes = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(512, input_shape=(time_steps, data_dim)))  \n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "32000/32000 [==============================] - 113s 4ms/step - loss: 0.4194 - acc: 0.7815\n",
      "Epoch 2/10\n",
      "32000/32000 [==============================] - 114s 4ms/step - loss: 0.2822 - acc: 0.8524\n",
      "Epoch 3/10\n",
      "32000/32000 [==============================] - 112s 4ms/step - loss: 0.2539 - acc: 0.8623\n",
      "Epoch 4/10\n",
      "32000/32000 [==============================] - 113s 4ms/step - loss: 0.2337 - acc: 0.8696\n",
      "Epoch 5/10\n",
      "32000/32000 [==============================] - 119s 4ms/step - loss: 0.2381 - acc: 0.8745\n",
      "Epoch 6/10\n",
      "32000/32000 [==============================] - 116s 4ms/step - loss: 0.2220 - acc: 0.8816\n",
      "Epoch 7/10\n",
      "32000/32000 [==============================] - 112s 4ms/step - loss: 0.2164 - acc: 0.8870\n",
      "Epoch 8/10\n",
      "32000/32000 [==============================] - 113s 4ms/step - loss: 0.2143 - acc: 0.8908\n",
      "Epoch 9/10\n",
      "32000/32000 [==============================] - 113s 4ms/step - loss: 0.2054 - acc: 0.8965\n",
      "Epoch 10/10\n",
      "32000/32000 [==============================] - 116s 4ms/step - loss: 0.2011 - acc: 0.8991\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2ab4190c88>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history = model.fit(X_train,y_train, batch_size=batch_size, epochs=10, )  \n",
    "# validation_data=(X_val, y_val),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194826/194826 [==============================] - 375s 2ms/step\n",
      "[0.2127477115502639, 0.8935460359506391]\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "results = model.evaluate(X_test,y_test)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history_dict = history.history\n",
    "# history_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import matplotlib.pyplot as plt\n",
    "\n",
    "# acc = history.history['acc']\n",
    "# val_acc = history.history['val_acc']\n",
    "# loss = history.history['loss']\n",
    "# val_loss = history.history['val_loss']\n",
    "\n",
    "# epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# # \"bo\" is for \"blue dot\"\n",
    "# plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# # b is for \"solid blue line\"\n",
    "# plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "# plt.title('Training and validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.clf()   # clear figure\n",
    "# acc_values = history_dict['acc']\n",
    "# val_acc_values = history_dict['val_acc']\n",
    "\n",
    "# plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "# plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "# plt.title('Training and validation accuracy')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import sequence\n",
    "# from keras.utils import np_utils\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features = 100000\n",
    "# maxlen = X.shape[0]\n",
    "# # batch_size = 32\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "# # model.add(LSTM(64, return_sequences=True))\n",
    "# model.add(LSTM(64))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Dense(2))\n",
    "# model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X, y, \n",
    "#     batch_size=batch_size, \n",
    "#     nb_epoch=1 # , show_accuracy=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import LSTM\n",
    "# from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dim = 16\n",
    "# timesteps = 8\n",
    "# num_classes = 2\n",
    "\n",
    "# num_ex = 1000\n",
    "\n",
    "# x_train = np.random.random((num_ex, timesteps, data_dim))\n",
    "# y_train = np.random.randint(1,3,num_ex)\n",
    "\n",
    "# x_train.shape\n",
    "\n",
    "# # [ пример, элемент посл., вектор ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# y_train = np.random.randint(1,3,num_ex)\n",
    "# y_train = OneHotEncoder(categories='auto').fit_transform(y_train.reshape(-1,1) ).todense()\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "# model = Sequential()\n",
    "\n",
    "# # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32,return_sequences=True,input_shape=(timesteps, data_dim)))  \n",
    "\n",
    "# # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32,return_sequences=True))  \n",
    "\n",
    "# model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "# model = Sequential()\n",
    "\n",
    "# # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32,input_shape=(timesteps, data_dim)))  \n",
    "\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',\n",
    "#               optimizer='rmsprop',\n",
    "#               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(x_train, y_train,\n",
    "#           batch_size=64, epochs=115,\n",
    "#           # validation_data=(x_val, y_val)\n",
    "#          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
