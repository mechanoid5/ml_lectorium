{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**классификатор текстов LSTM на Keras+TensorFlow**\n",
    "\n",
    "Евгений Борисов <borisov.e@solarl.ru>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://habr.com/ru/company/dca/blog/274027/\n",
    "# http://neuro.compute.dtu.dk/wiki/Sentiment_analysis#Corpora\n",
    "# http://help.sentiment140.com/for-students/\n",
    "# http://study.mokoron.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.max_colwidth = 200  \n",
    "import re\n",
    "import gzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(d): return \"{:,.0f}\".format(d).replace(\",\", \" \")\n",
    "def ppr(d): print('записей:', pp(len(d)) )  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Данные"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Ю. В. Рубцова. Построение корпуса текстов для настройки тонового классификатора // Программные продукты и системы, 2015, №1(109), –С.72-78\n",
    "\n",
    "http://study.mokoron.com\n",
    "\n",
    "– id: уникальный номер сообщения в системе twitter;\n",
    "– tdate: дата публикации сообщения (твита);\n",
    "– tmane: имя пользователя, опубликовавшего сообщение;\n",
    "– ttext:  текст сообщения (твита);\n",
    "– ttype: поле в котором в дальнейшем будет указано к кому классу относится твит (положительный, отрицательный, нейтральный);\n",
    "– trep: количество реплаев к данному сообщению. В настоящий момент API твиттера не отдает эту информацию;\n",
    "– tfav: число сколько раз данное сообщение было добавлено в избранное другими пользователями;\n",
    "– tstcount: число всех сообщений пользователя в сети twitter;\n",
    "– tfol: количество фоловеров пользователя (тех людей, которые читают пользователя);\n",
    "– tfrien: количество друзей пользователя (те люди, которых читает пользователь);\n",
    "– listcount: количество листов-подписок в которые добавлен твиттер-пользователь."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff = ['id', 'tdate', 'tmane', 'ttext', 'ttype', 'trep', 'tfav', 'tstcount', 'tfol', 'tfrien', 'listcount','unk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 111 923\n"
     ]
    }
   ],
   "source": [
    "neg = pd.read_csv('../data/text/twit/negative.csv.gz',sep=';',header=None)\n",
    "ppr(neg)\n",
    "neg.columns = ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 114 910\n"
     ]
    }
   ],
   "source": [
    "pos = pd.read_csv('../data/text/twit/positive.csv.gz',sep=';')\n",
    "ppr(pos)\n",
    "pos.columns = ff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 226 833\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([pos,neg],sort=False)[['id','ttext', 'ttype']]\n",
    "ppr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7075</th>\n",
       "      <td>409092007999860736</td>\n",
       "      <td>#С_ДНЁМ_РОЖДЕНИЯ! @TheFuckDePolice \\nСчастья тебе, удачи, везения, любви, и побольше незабываемых впечатлений в жизни!) #МираДобраКотяток!))</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94203</th>\n",
       "      <td>422403742521372672</td>\n",
       "      <td>@cherry96moon тебя мне не хватало на хоре 2 года. Не с кем поржать было:(</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17610</th>\n",
       "      <td>409372604185972736</td>\n",
       "      <td>RT @AnnaUglova: @Skinny_Ger вот вот, всё возможно)) так что если всё съедите, как в тагане киндеры</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19903</th>\n",
       "      <td>409409077672828928</td>\n",
       "      <td>Присоединяйтесь :) \\n#анекдот \\n#ВзаимныйФолловинг \\n#ЧитаюВзаимно \\n#rufollowback \\n#followback</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26705</th>\n",
       "      <td>409580250570719233</td>\n",
       "      <td>RT @LanaRey_: @Heilig_99 я замечаю, но молчу :D \\nи вообще,я соскучился :с</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98645</th>\n",
       "      <td>411055804306161664</td>\n",
       "      <td>RT @Shkolina_1997: Скучновато было, но мне нравки;) http://t.co/eruVPmfDEl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95265</th>\n",
       "      <td>411011432172769280</td>\n",
       "      <td>Обзавёлся жёлтым хромом... Просто так, на поглазеть...)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109685</th>\n",
       "      <td>424590900770394112</td>\n",
       "      <td>\"@DaryMalyavskaya: Что? Диета? А давай купим тебе пол кило мороженого?\" Знакомо. Папа столько всего накупил:(</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34779</th>\n",
       "      <td>409769560255250432</td>\n",
       "      <td>RT @vitalich_ololo: Кстати, мне сегодня гадали по руке)  судя по ней, Господь нервничал, когда зачали Виталича)</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37511</th>\n",
       "      <td>409847655280287744</td>\n",
       "      <td>А сейчас, джентльмены, перейдем к народному пению. :-D #ff</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id  \\\n",
       "7075    409092007999860736   \n",
       "94203   422403742521372672   \n",
       "17610   409372604185972736   \n",
       "19903   409409077672828928   \n",
       "26705   409580250570719233   \n",
       "98645   411055804306161664   \n",
       "95265   411011432172769280   \n",
       "109685  424590900770394112   \n",
       "34779   409769560255250432   \n",
       "37511   409847655280287744   \n",
       "\n",
       "                                                                                                                                               ttext  \\\n",
       "7075    #С_ДНЁМ_РОЖДЕНИЯ! @TheFuckDePolice \\nСчастья тебе, удачи, везения, любви, и побольше незабываемых впечатлений в жизни!) #МираДобраКотяток!))   \n",
       "94203                                                                      @cherry96moon тебя мне не хватало на хоре 2 года. Не с кем поржать было:(   \n",
       "17610                                            RT @AnnaUglova: @Skinny_Ger вот вот, всё возможно)) так что если всё съедите, как в тагане киндеры    \n",
       "19903                                               Присоединяйтесь :) \\n#анекдот \\n#ВзаимныйФолловинг \\n#ЧитаюВзаимно \\n#rufollowback \\n#followback   \n",
       "26705                                                                     RT @LanaRey_: @Heilig_99 я замечаю, но молчу :D \\nи вообще,я соскучился :с   \n",
       "98645                                                                     RT @Shkolina_1997: Скучновато было, но мне нравки;) http://t.co/eruVPmfDEl   \n",
       "95265                                                                                        Обзавёлся жёлтым хромом... Просто так, на поглазеть...)   \n",
       "109685                                 \"@DaryMalyavskaya: Что? Диета? А давай купим тебе пол кило мороженого?\" Знакомо. Папа столько всего накупил:(   \n",
       "34779                                RT @vitalich_ololo: Кстати, мне сегодня гадали по руке)  судя по ней, Господь нервничал, когда зачали Виталича)   \n",
       "37511                                                                                     А сейчас, джентльмены, перейдем к народному пению. :-D #ff   \n",
       "\n",
       "        ttype  \n",
       "7075        1  \n",
       "94203      -1  \n",
       "17610       1  \n",
       "19903       1  \n",
       "26705       1  \n",
       "98645       1  \n",
       "95265       1  \n",
       "109685     -1  \n",
       "34779       1  \n",
       "37511       1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## очистка данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext'].apply(lambda t:[ w.strip() for w in t.split() if w.strip() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'^http.*',' url ', w.strip() ) for w in t  ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'[:;]-*[)D]',' happysmile ', w.strip() )for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'\\)\\)\\)*',' happysmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'[:;]\\*',' kisssmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r':\\(',' sadsmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t:[ re.sub(r'\\(\\(\\(*',' sadsmile ', w.strip() ) for w in t ]\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = [ ' '.join(s) for s in data['ttext_clean'] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].str.lower()\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda s: re.sub( r'\\W', ' ', s))\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda s: re.sub( r'_', ' ', s))\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda s: re.sub( r'\\b\\d+\\b', ' digit ', s)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda t:[ w.strip() for w in t.split() if w.strip() ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# замена буквенно-цифровых кодов\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t: [w for w in t if not re.match( r'\\b.*\\d+.*\\b', w) ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[['ttext_clean']]\n",
    "# data[['ttext']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 151\n"
     ]
    }
   ],
   "source": [
    "with gzip.open('../data/text/stop-nltk.txt.gz','rt',encoding='utf-8') as f: \n",
    "    stopwords = set([ w.strip() for w in  f.read().split() if w.strip() ] )\n",
    "ppr(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление лишних слов\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda t:[w for w in t if w not in stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time \n",
    "\n",
    "# from Stemmer import Stemmer\n",
    "# # pacman -S python-pystemmer\n",
    "# # pip install pystemmer\n",
    "\n",
    "# # стемминг, выделение основы слова\n",
    "# data['ttext_clean'] = data['ttext_clean'].apply( lambda t:Stemmer('russian').stemWords(t) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаление коротких слов\n",
    "data['ttext_clean'] = data['ttext_clean'].apply(lambda t:[w for w in t if len(w)>2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[ data['ttext_clean'].str.len()<1 ][['ttext_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 226 833\n",
      "записей: 226 826\n"
     ]
    }
   ],
   "source": [
    "ppr(data)\n",
    "data = data[ data['ttext_clean'].str.len()>0 ].reset_index(drop=True) \n",
    "ppr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>ttext</th>\n",
       "      <th>ttype</th>\n",
       "      <th>ttext_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>121763</th>\n",
       "      <td>409988515750232065</td>\n",
       "      <td>Как всегда, моего самого сильного программиста нет под рукой, когда он так нужен... Ууу :(</td>\n",
       "      <td>-1</td>\n",
       "      <td>[моего, самого, сильного, программиста, рукой, нужен, ууу, sadsmile]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45615</th>\n",
       "      <td>409987749975183360</td>\n",
       "      <td>RT @ponaditazej: Какая попаболь чувствуется в этом тексте :)   А как красиво сформирован несвязный поток мыслей…</td>\n",
       "      <td>1</td>\n",
       "      <td>[ponaditazej, попаболь, чувствуется, тексте, happysmile, красиво, сформирован, несвязный, поток, мыслей]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70515</th>\n",
       "      <td>410469301649285121</td>\n",
       "      <td>@AIrzhanov атрофларига кометаларимни сочиб ташлайман))))</td>\n",
       "      <td>1</td>\n",
       "      <td>[airzhanov, атрофларига, кометаларимни, сочиб, ташлайман, happysmile]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        id  \\\n",
       "121763  409988515750232065   \n",
       "45615   409987749975183360   \n",
       "70515   410469301649285121   \n",
       "\n",
       "                                                                                                                   ttext  \\\n",
       "121763                        Как всегда, моего самого сильного программиста нет под рукой, когда он так нужен... Ууу :(   \n",
       "45615   RT @ponaditazej: Какая попаболь чувствуется в этом тексте :)   А как красиво сформирован несвязный поток мыслей…   \n",
       "70515                                                           @AIrzhanov атрофларига кометаларимни сочиб ташлайман))))   \n",
       "\n",
       "        ttype  \\\n",
       "121763     -1   \n",
       "45615       1   \n",
       "70515       1   \n",
       "\n",
       "                                                                                                     ttext_clean  \n",
       "121763                                      [моего, самого, сильного, программиста, рукой, нужен, ууу, sadsmile]  \n",
       "45615   [ponaditazej, попаболь, чувствуется, тексте, happysmile, красиво, сформирован, несвязный, поток, мыслей]  \n",
       "70515                                      [airzhanov, атрофларига, кометаларимни, сочиб, ташлайман, happysmile]  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## строим датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['<PAD>','<START>','<UNK>'] + sorted(set([ w for t in data['ttext_clean'] for w in t if w ]))\n",
    "ppr(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# w2v = Word2Vec( common_texts, min_count=1, size=256, window=4, workers=4)\n",
    "\n",
    "# # with open('result/Word2Vec.pkl', 'wb') as f: pickle.dump(w2v, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = { w:n for n,w in enumerate(vocab) }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'] + ['<START>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max = data['ttext_clean'].str.len().max()\n",
    "n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad = ['<PAD>']*n_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean'] = data['ttext_clean'].apply(\n",
    "    lambda t: pad[len(t):] + list(reversed(t)) \n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_code'] = data['ttext_clean'].apply(lambda t: [ vocab[w] for w in t ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['ttext_code'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)//32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppr(data)\n",
    "data = data.sample(32*7088).reset_index(drop=True)\n",
    "ppr(data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack( data['ttext_code'].values).astype(np.float32 ) # , axis=-1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y = data['ttype'].values\n",
    "y = OneHotEncoder(categories='auto').fit_transform(y.reshape(-1,1) ).todense().astype(np.float32)\n",
    "y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X.npy',X)\n",
    "np.save('y.npy',y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.load('X.npy')\n",
    "y = np.load('y.npy')\n",
    "vocab_size = int(X.max())\n",
    "\n",
    "X.shape , y.shape, vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## строим нейросеть "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=226826\n",
    "# for i in range(1,n//2):\n",
    "#     if n%i==0: print(i)\n",
    "# # 23\n",
    "# # 46\n",
    "# # 4931\n",
    "# # 9862"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps=X.shape[1]\n",
    "batch_size=32\n",
    "num_classes=y.shape[1]\n",
    "\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size=64\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(\n",
    "       input_dim=vocab_size, # e.g, 10 if you have 10 words in your vocabulary\n",
    "       output_dim=embedding_size, # size of the embedded vectors\n",
    "       input_length=time_steps,\n",
    "       batch_input_shape=(batch_size,time_steps)\n",
    "    ))\n",
    "\n",
    "model.add(LSTM(\n",
    "       32, \n",
    "       return_sequences=False, \n",
    "       stateful=False)\n",
    "    )\n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y, batch_size=batch_size, epochs=10, )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing import sequence\n",
    "# from keras.utils import np_utils\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers.core import Dense, Dropout, Activation\n",
    "# from keras.layers.embeddings import Embedding\n",
    "# from keras.layers.recurrent import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features = 100000\n",
    "# maxlen = X.shape[0]\n",
    "# # batch_size = 32\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "# # model.add(LSTM(64, return_sequences=True))\n",
    "# model.add(LSTM(64))\n",
    "# # model.add(Dropout(0.5))\n",
    "# model.add(Dense(2))\n",
    "# model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='binary_crossentropy',\n",
    "#               optimizer='adam',\n",
    "#               class_mode=\"binary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     X, y, \n",
    "#     batch_size=batch_size, \n",
    "#     nb_epoch=1 # , show_accuracy=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result = model.predict_proba(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dim = 16\n",
    "timesteps = 8\n",
    "num_classes = 2\n",
    "\n",
    "num_ex = 1000\n",
    "\n",
    "x_train = np.random.random((num_ex, timesteps, data_dim))\n",
    "y_train = np.random.randint(1,3,num_ex)\n",
    "\n",
    "x_train.shape\n",
    "\n",
    "# [ пример, элемент посл., вектор ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "y_train = np.random.randint(1,3,num_ex)\n",
    "y_train = OneHotEncoder(categories='auto').fit_transform(y_train.reshape(-1,1) ).todense()\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # expected input data shape: (batch_size, timesteps, data_dim)\n",
    "# model = Sequential()\n",
    "\n",
    "# # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32,return_sequences=True,input_shape=(timesteps, data_dim)))  \n",
    "\n",
    "# # returns a sequence of vectors of dimension 32\n",
    "# model.add(LSTM(32,return_sequences=True))  \n",
    "\n",
    "# model.add(LSTM(32))  # return a single vector of dimension 32\n",
    "\n",
    "# model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "\n",
    "# returns a sequence of vectors of dimension 32\n",
    "model.add(LSTM(32,input_shape=(timesteps, data_dim)))  \n",
    "\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train,\n",
    "          batch_size=64, epochs=115,\n",
    "          # validation_data=(x_val, y_val)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
