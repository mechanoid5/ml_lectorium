{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**извлечение признаков из текста на естественном языке**\n",
    "\n",
    "классификатор текстов\n",
    "\n",
    "частотный анализ, понижаем значение признака для частых слов (IDF)\n",
    "\n",
    "Евгений Борисов borisov.e@solarl.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 3196\n"
     ]
    }
   ],
   "source": [
    "# загружаем тексты\n",
    "data = pd.read_pickle('../data/text/news.pkl')\n",
    "print('записей:',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3127</th>\n",
       "      <td>Восток-Медиа (vostokmedia.com) Дальневосточный фестиваль художественных\\nремесел \"Живая нить времен\" пройдет в Хабаровске. В нем примут участие\\nмастера художественных промыслов и декоративно-прик...</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>560</th>\n",
       "      <td>Названы возможные причины пожара с гибелью троих молодых людей в Витебском районе\\n\\nопубликовано: 3 декабря 2016 в 14:20\\n\\nобновлено: 5 декабря 2016 в 12:17\\n\\nTUT.BY\\n\\nТрагедия случилась в дер...</td>\n",
       "      <td>incident</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         text  \\\n",
       "3127  Восток-Медиа (vostokmedia.com) Дальневосточный фестиваль художественных\\nремесел \"Живая нить времен\" пройдет в Хабаровске. В нем примут участие\\nмастера художественных промыслов и декоративно-прик...   \n",
       "560   Названы возможные причины пожара с гибелью троих молодых людей в Витебском районе\\n\\nопубликовано: 3 декабря 2016 в 14:20\\n\\nобновлено: 5 декабря 2016 в 12:17\\n\\nTUT.BY\\n\\nТрагедия случилась в дер...   \n",
       "\n",
       "           tag  \n",
       "3127   culture  \n",
       "560   incident  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CountVectorizer + TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    tt = [ t for t in text.split() if t ]\n",
    "    tt = [ t.lower()  for t in tt ] # приведение в lowercase\n",
    "    tt = [ re.sub( r'https?://[\\S]+', 'url', t)  for t in tt ]  # замена интернет ссылок\n",
    "    tt = [ re.sub( r'[\\w\\./]+\\.[a-z]+', 'url', t) for t in tt  ]  # замена интернет ссылок \n",
    "    tt = [ re.sub( r'<[^>]*>', '', t)  for t in tt ] # удаление html тагов\n",
    "    tt = [ re.sub( r'\\W', '', t)  for t in tt ] # удаление лишних символов (НЕ буква и НЕ цифра)\n",
    "    tt = [ re.sub( r'\\b\\d+\\b', 'digit', t ) for t in tt ] # замена цифр\n",
    "    return ' '.join( [ t.strip() for t in tt if t ] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function preprocessor at 0x7f60463ecbf8>,\n",
       "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TfidfVectorizer = CountVectorizer + TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# понижаем значение признака для частых слов (IDF)\n",
    "tf = TfidfVectorizer(preprocessor=preprocessor,use_idf=True)\n",
    "tf.fit( data['text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85058"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# размер словаря\n",
    "len(tf.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## формируем датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3196, 85058)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.transform( data['text'] ) # .todense()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto': 0,\n",
       " 'culture': 1,\n",
       " 'economics': 2,\n",
       " 'health': 3,\n",
       " 'incident': 4,\n",
       " 'politics': 5,\n",
       " 'realty': 6,\n",
       " 'reclama': 7,\n",
       " 'science': 8,\n",
       " 'social': 9,\n",
       " 'sport': 10,\n",
       " 'tech': 11,\n",
       " 'woman': 12}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = { t:i for i,t in enumerate(sorted(set(data['tag']))) }\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 1, ..., 8, 5, 9])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['tag'].map(labels).values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def get_seed(): t = time() ; return int(((t%1)/(t//1))*1e11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((319, 85058), (319,), (2877, 85058), (2877,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.9, random_state=get_seed() )\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='hinge',max_iter=1000)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( classification_report(y_train,o) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7511296489398679"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.79      0.81       224\n",
      "           1       0.65      0.77      0.70       323\n",
      "           2       0.86      0.48      0.62       256\n",
      "           3       1.00      0.18      0.30        85\n",
      "           4       0.72      0.95      0.82       389\n",
      "           5       0.69      0.91      0.78       538\n",
      "           6       0.80      0.14      0.24        56\n",
      "           7       0.72      0.29      0.41        45\n",
      "           8       0.88      0.96      0.91       205\n",
      "           9       0.69      0.19      0.29       129\n",
      "          10       0.95      0.92      0.93       339\n",
      "          11       0.73      0.62      0.67       260\n",
      "          12       0.37      0.71      0.49        28\n",
      "\n",
      "   micro avg       0.75      0.75      0.75      2877\n",
      "   macro avg       0.76      0.61      0.61      2877\n",
      "weighted avg       0.77      0.75      0.73      2877\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test,o) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "\n",
    "cm = confusion_matrix(y_test,o)\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion matrix')\n",
    "plt.colorbar()\n",
    "\n",
    "classes = sorted(labels.keys())\n",
    "\n",
    "tick_marks = np.arange(len(classes))\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_inv = { labels[k]:k for k in labels}\n",
    "# labels_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag: auto\n",
      "predict: auto\n",
      "- - - - - - - - - - - - - - - - - - \n",
      "\n",
      "В интернете впервые опубликованы полноразмерные компьютерные изображения внедорожника Marussia F1, разрабатывавшегося компанией Marussia Motors.\n",
      "\n",
      "Автомобиль Marussia F1 разрабатывался компанией в течение 2009-2010 годов по техническому заданию, предполагавшему создание внедорожника средних размеров розничной стоимостью около 1,7 миллиона рублей.\n",
      "\n",
      "Автором внешнего вида Marussia F1 стал молодой дизайнер Иван Борисов, который затем ушел в Научный автомоторный институт (НАМИ). По каким-то причинам руководство Marussia Motors предпочло этому варианту более эксцентричную модель Marussia F2.\n",
      "\n",
      "Характерно, что в голосовании на сайте drom.ru большинство участников - 71 процент - заявили, что дизайн Marussia F1 им не нравится. И всего лишь 21 процент голосов принадлежит тем, у кого фотографии вызвали положительный отклик.\n",
      "\n",
      "Напомним, что компания Marussia Motors была создана в 2008 году. Инвесторы проекта заявляли о намерении наладить мелкосерийный выпуск эксклюзивных автомобилей. Однако в 2014 году компания была распущена в связи с тяжелым финансовым положением и закрылась с большими долгами перед сотрудниками и кредиторами.\n",
      "\n",
      "Подписывайтесь на канал Царьград в Telegram или на рассылку, чтобы первыми узнавать о важнейших событиях дня\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(data))\n",
    "print('tag:',data.iloc[i,1])\n",
    "print('predict:',labels_inv[o[i]])\n",
    "print('- - - - - - - - - - - - - - - - - - \\n')\n",
    "print(data.iloc[i,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# le = LabelEncoder()\n",
    "# le.fit(data['tag'])\n",
    "# print( list(le.classes_) )\n",
    "# y = le.transform(data['tag']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.pipeline import Pipeline\n",
    "# text_clf = Pipeline([\n",
    "#                 ('tfidf', TfidfVectorizer()),\n",
    "#                 ('clf', SGDClassifier(loss='hinge')),\n",
    "#                 ])\n",
    "# text_clf.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sebastian Raschka   Python Machine Learning  - Packt Publishing Ltd, 2015"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
