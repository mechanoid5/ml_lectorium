{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**извлечение признаков из текста на естественном языке**\n",
    "\n",
    "классификатор текстов\n",
    "\n",
    "частотный анализ с очисткой стоп-слов (TF)\n",
    "\n",
    "Евгений Борисов borisov.e@solarl.ru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тексты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "записей: 3196\n"
     ]
    }
   ],
   "source": [
    "# загружаем тексты\n",
    "data = pd.read_pickle('../data/text/news.pkl')\n",
    "print('записей:',len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2549</th>\n",
       "      <td>\\r\\nЛетом прошлого года астрономы зафиксировали необычно яркую вспышку на расстоянии в 4 миллиарда световых лет от Солнечной системы. Было заявлено, что во Вселенной родилась самая яркая в истории...</td>\n",
       "      <td>science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>Бывший губернатор Сахалинской области Александр Хорошавин и члены его семьи — жена и совершеннолетний сын — оспаривают антикоррупционный закон \"О контроле за соответствием расходов лиц, замещающих...</td>\n",
       "      <td>politics</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                         text  \\\n",
       "2549  \\r\\nЛетом прошлого года астрономы зафиксировали необычно яркую вспышку на расстоянии в 4 миллиарда световых лет от Солнечной системы. Было заявлено, что во Вселенной родилась самая яркая в истории...   \n",
       "1440  Бывший губернатор Сахалинской области Александр Хорошавин и члены его семьи — жена и совершеннолетний сын — оспаривают антикоррупционный закон \"О контроле за соответствием расходов лиц, замещающих...   \n",
       "\n",
       "           tag  \n",
       "2549   science  \n",
       "1440  politics  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  CountVectorizer + TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Stemmer import Stemmer\n",
    "# pacman -S python-pystemmer\n",
    "# pip install pystemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords= [\n",
    "    'и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она', \n",
    "    'так', 'его', 'но',  'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее', \n",
    "    'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда', \n",
    "    'даже', 'ну', 'вдруг', 'ли', 'если', 'уже', 'или',  'ни', 'быть', 'был', 'него', 'до', \n",
    "    'вас', 'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', \n",
    "    'может', 'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем',\n",
    "    'была', 'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', \n",
    "    'ж', 'тогда', 'кто','этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', \n",
    "    'этом', 'один', 'почти', 'мой', 'тем','чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем',\n",
    "    'всех', 'никогда', 'можно', 'при', 'наконец', 'два','об', 'другой', 'хоть', 'после', \n",
    "    'над', 'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них','какая', 'много', \n",
    "    'разве', 'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда',\n",
    "    'лучше', 'чуть', 'том', 'нельзя', 'такой', 'им', 'более', \n",
    "    'всегда', 'конечно', 'всю', 'между']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessor(text):\n",
    "    tt = [ t for t in text.split() if t ]\n",
    "    # tt = [ t.lower()  for t in tt ] # приведение в lowercase\n",
    "    tt = [ re.sub( r'https?://[\\S]+', 'url', t)  for t in tt ]  # замена интернет ссылок\n",
    "    tt = [ re.sub( r'[\\w\\./]+\\.[a-z]+', 'url', t) for t in tt  ]  # замена интернет ссылок \n",
    "    tt = [ re.sub( r'<[^>]*>', '', t)  for t in tt ] # удаление html тагов\n",
    "    tt = [ re.sub( r'\\W', '', t)  for t in tt ] # удаление лишних символов (НЕ буква и НЕ цифра)\n",
    "    tt = [ t for t in tt if t not in stopwords ] # удаление (предлогов)\n",
    "    tt = Stemmer('russian').stemWords( tt ) # стемминг, выделение основы слова\n",
    "    tt = [ re.sub( r'\\b\\d+\\b', 'digit', t ) for t in tt ] # замена цифр\n",
    "    tt = [ t for t in tt if len(t)>2 ] # удаление коротких слов\n",
    "    return ' '.join( [ t.strip() for t in tt if t ] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "        lowercase=False, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2',\n",
       "        preprocessor=<function preprocessor at 0x7fb50d3cd378>,\n",
       "        smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "        sublinear_tf=False, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, use_idf=False, vocabulary=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# ручная очистка\n",
    "tf = TfidfVectorizer(\n",
    "    preprocessor=preprocessor,\n",
    "    lowercase=False,\n",
    "    stop_words=None,\n",
    "    use_idf=False,\n",
    "    norm='l2')\n",
    "\n",
    "tf.fit( data['text'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44173"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tf.vocabulary_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## формируем датасеты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3196, 44173)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = tf.transform( data['text'] )\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'auto': 0,\n",
       " 'culture': 1,\n",
       " 'economics': 2,\n",
       " 'health': 3,\n",
       " 'incident': 4,\n",
       " 'politics': 5,\n",
       " 'realty': 6,\n",
       " 'reclama': 7,\n",
       " 'science': 8,\n",
       " 'social': 9,\n",
       " 'sport': 10,\n",
       " 'tech': 11,\n",
       " 'woman': 12}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = { t:i for i,t in enumerate(sorted(set(data['tag']))) }\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 1, 1, ..., 8, 5, 9])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data['tag'].map(labels).values\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "def get_seed(): t = time() ; return int(((t%1)/(t//1))*1e11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((319, 44173), (319,), (2877, 44173), (2877,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.9, random_state=get_seed() )\n",
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## обучаем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "       l1_ratio=0.15, learning_rate='optimal', loss='hinge', max_iter=1000,\n",
       "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "       power_t=0.5, random_state=None, shuffle=True, tol=None,\n",
       "       validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "clf = SGDClassifier(loss='hinge',max_iter=1000)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## тестируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_train,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print( classification_report(y_train,o) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7400069516857838"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84       222\n",
      "           1       0.71      0.85      0.77       313\n",
      "           2       0.68      0.61      0.65       249\n",
      "           3       0.74      0.27      0.40        85\n",
      "           4       0.80      0.84      0.82       399\n",
      "           5       0.77      0.86      0.82       542\n",
      "           6       0.82      0.24      0.37        58\n",
      "           7       0.00      0.00      0.00        50\n",
      "           8       0.82      0.77      0.80       208\n",
      "           9       0.37      0.24      0.29       130\n",
      "          10       0.75      0.94      0.83       332\n",
      "          11       0.64      0.71      0.67       254\n",
      "          12       0.00      0.00      0.00        35\n",
      "\n",
      "   micro avg       0.74      0.74      0.74      2877\n",
      "   macro avg       0.61      0.55      0.56      2877\n",
      "weighted avg       0.71      0.74      0.72      2877\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print( classification_report(y_test,o) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x900 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import itertools\n",
    "\n",
    "classes = sorted(labels.keys())\n",
    "cm = confusion_matrix(y_test,o)\n",
    "tick_marks = np.arange(len(classes))\n",
    "\n",
    "plt.figure(figsize=(10,9))\n",
    "\n",
    "plt.xticks(tick_marks, classes, rotation=45)\n",
    "plt.yticks(tick_marks, classes)\n",
    "\n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment=\"center\",\n",
    "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "plt.title('Confusion matrix')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = clf.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_inv = { labels[k]:k for k in labels}\n",
    "# labels_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tag: politics\n",
      "predict: politics\n",
      "- - - - - - - - - - - - - - - - - - \n",
      "\n",
      "277\n",
      "\n",
      "Республиканец Митт Ромни, который еще во время президентской гонки 2012 года называл Российскую Федерацию главным врагом Соединенных Штатов, похоже, все-таки не станет главой американского внешнеполитического ведомства при президентстве Дональда Трампа.\n",
      "\n",
      "В понедельник, 12 декабря, Ромни выступил с заявлением, из которого американские журналисты сделали вывод, что новоиспеченный хозяин Белого дома Дональд Трамп больше не рассматривает его кандидатуру на пост госсекретаря США, передает \"Российский Диалог\" со ссылкой на CNN.\n",
      "\n",
      "Заявление республиканца последовало практически сразу после того, как Трамп объявил, что во вторник утром объявит кандидата на пост главы внешнеполитического ведомства.\n",
      "\n",
      "Ранее СМИ сообщали, что больше всех шансов возглавить Госдеп имеет бизнесмен Рекс Тиллерсон, который является критиком антироссийских санкций.\n",
      "\n",
      "В Москве считают, что назначение Тиллерсона может направить российско-американские отношения в правильное русло.\n",
      "\n",
      "В частности, сенатор Алексей Пушков уверен: Трамп своими назначениями показывает, что он не видит причин для конфликта с Россией.\n"
     ]
    }
   ],
   "source": [
    "i = np.random.randint(len(data))\n",
    "print('tag:',data.iloc[i,1])\n",
    "print('predict:',labels_inv[o[i]])\n",
    "print('- - - - - - - - - - - - - - - - - - \\n')\n",
    "print(data.iloc[i,0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocessor(text):\n",
    "#     tt = [ t for t in text.split() if t ]\n",
    "#     tt = [ re.sub( r'https?://[\\S]+', 'url', t)  for t in tt ]  # замена интернет ссылок\n",
    "#     tt = [ re.sub( r'[\\w\\./]+\\.[a-z]+', 'url', t) for t in tt  ]  # замена интернет ссылок \n",
    "#     tt = [ re.sub( r'<[^>]*>', '', t)  for t in tt ] # удаление html тагов\n",
    "#     tt = [ re.sub( r'\\W', '', t)  for t in tt ] # удаление лишних символов (НЕ буква и НЕ цифра)\n",
    "#     tt = [ re.sub( r'\\b\\d+\\b', 'digit', t ) for t in tt ] # замена цифр\n",
    "#     return ' '.join( [ t.strip() for t in tt if t ] )\n",
    "    \n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# stemmer = Stemmer('russian')\n",
    "# analyzer = CountVectorizer().build_analyzer()\n",
    "# def stemmed_words(doc): return [ Stemmer('russian').stemWord(w) for w in analyzer(doc) ]\n",
    "# vect = CountVectorizer(lowercase=True,preprocessor=preprocessor,analyzer=stemmed_words)\n",
    "# vect.fit( data['text'] )\n",
    "\n",
    "# # размер словаря\n",
    "# print(len(vect.vocabulary_))\n",
    "\n",
    "\n",
    "# from sklearn.feature_extraction.text import TfidfTransformer\n",
    "# tf = TfidfTransformer(use_idf=False, norm='l2')\n",
    "# data_vect = vect.transform( data['text'] )\n",
    "# tf.fit( data_vect )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
