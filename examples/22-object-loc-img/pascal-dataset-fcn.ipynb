{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__конвертор датасета PASCAL для семантического сегментатора изображений__\n",
    "\n",
    "Евгений Борисов borisov.e@solarl.ru"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PASCAL VOC2007, VOC2012 http://host.robots.ox.ac.uk/pascal/VOC/\n",
    "#\n",
    "# !wget -с http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtrainval_06-Nov-2007.tar\n",
    "# !wget -с http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\n",
    "# !wget -с http://host.robots.ox.ac.uk/pascal/VOC/voc2007/VOCtest_06-Nov-2007.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOC           # path:  /home/yang/dataset/VOC\n",
    "# ├── test\n",
    "# |    └──VOCdevkit\n",
    "# |        └──VOC2007 (from VOCtest_06-Nov-2007.tar)\n",
    "# └── train\n",
    "#      └──VOCdevkit\n",
    "#          └──VOC2007 (from VOCtrainval_06-Nov-2007.tar)\n",
    "#          └──VOC2012 (from VOCtrainval_11-May-2012.tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/YunYang1994/TensorFlow2.0-Examples/tree/master/5-Image_Segmentation/FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join as pjoin\n",
    "from os import listdir\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "    \n",
    "# from utils import colormap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT_FOLDER = 'data/pascal/VOC'\n",
    "RESULT_FOLDER = 'data/pascal_my'\n",
    "IM_W, IM_H = 256,256\n",
    "# IM_W, IM_H = 224,224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !mkdir data/pascal_my"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls data/pascal/VOC/train/VOCdevkit/VOC2007/JPEGImages/*.jpg > data/pascal/files_input_train_2007.txt\n",
    "# !ls data/pascal/VOC/train/VOCdevkit/VOC2012/JPEGImages/*.jpg > data/pascal/files_input_train_2012.txt\n",
    "# !ls data/pascal/VOC/train/VOCdevkit/VOC2007/SegmentationClass/*.png > data/pascal/files_output_train_2007.txt\n",
    "# !ls data/pascal/VOC/train/VOCdevkit/VOC2012/SegmentationClass/*.png > data/pascal/files_output_train_2012.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(d):\n",
    "    return [\n",
    "            [f,f.split('.')[0]] for f in listdir(d) \n",
    "        ]\n",
    "\n",
    "def make_file_pair(d):\n",
    "    fi = get_files( pjoin(d,'JPEGImages') )\n",
    "    fo = get_files( pjoin(d,'SegmentationClass') )\n",
    "    \n",
    "    df = pd.DataFrame(fi).merge(pd.DataFrame(fo), on=[1] )\n",
    "    df.columns = ['fname_img','dname','fname_msk']\n",
    "    \n",
    "    df['dname'] = d\n",
    "    df['fname_img'] = df['fname_img'].apply(lambda s: '%s/%s'%('JPEGImages',s) )\n",
    "    df['fname_msk'] = df['fname_msk'].apply(lambda s: '%s/%s'%('SegmentationClass',s) )\n",
    "        \n",
    "    return df[['dname','fname_img','fname_msk']]\n",
    "\n",
    "\n",
    "def pascal_segmentation_files(d):\n",
    "    df = pd.concat([\n",
    "            make_file_pair( pjoin(d,'train/VOCdevkit/VOC2007') ),\n",
    "            make_file_pair( pjoin(d,'train/VOCdevkit/VOC2012') )\n",
    "        ])\n",
    "\n",
    "    df['is_train'] = True\n",
    "    \n",
    "    df = pd.concat([df,make_file_pair( pjoin(d,'test/VOCdevkit/VOC2007') ) ])\n",
    "\n",
    "    return df.fillna(False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "files = pascal_segmentation_files(DATA_ROOT_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = pd.concat([\n",
    "        files,\n",
    "        pd.DataFrame([\n",
    "                Image.open( pjoin(p,fi) ).size + \\\n",
    "                Image.open( pjoin(p,fo) ).size\n",
    "                for p,fi,fo,_ in files.values.tolist()\n",
    "            ],columns=['wi','hi','wm','hm'])\n",
    "    ],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len( files.query('wi != wm') )==0\n",
    "assert len( files.query('hi != hm') )==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAME = ['background','aeroplane','bicycle','bird','boat',\n",
    "           'bottle','bus','car','cat','chair','cow','diningtable',\n",
    "           'dog','horse','motorbike','person','potted plant',\n",
    "           'sheep','sofa','train','tv/monitor']\n",
    "\n",
    "\n",
    "# RGB color for each class\n",
    "COLORS = [[0,0,0],[128,0,0],[0,128,0], [128,128,0], [0,0,128],\n",
    "            [128,0,128],[0,128,128],[128,128,128],[64,0,0],[192,0,0],\n",
    "            [64,128,0],[192,128,0],[64,0,128],[192,0,128],\n",
    "            [64,128,128],[192,128,128],[0,64,0],[128,64,0],\n",
    "            [0,192,0],[128,192,0],[0,64,128]]\n",
    "\n",
    "CLASS_IDX = { i:n for i,n in enumerate(CLASS_NAME)}\n",
    "\n",
    "COLORMAP = { tuple(c):i for i,c in  enumerate(COLORS) }\n",
    "\n",
    "RGB_MEAN = np.array([0.485, 0.456, 0.406])\n",
    "\n",
    "RGB_STD = np.array([0.229, 0.224, 0.225])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "files.to_csv(pjoin(RESULT_FOLDER,'files.csv'),index=False,sep='\\t')\n",
    "\n",
    "with open(pjoin(RESULT_FOLDER,'class_idx.pkl'),'wb') as f: pickle.dump(CLASS_IDX,f)\n",
    "with open(pjoin(RESULT_FOLDER,'colormap.pkl'),'wb') as f: pickle.dump(COLORMAP,f)\n",
    "    \n",
    "np.save(pjoin(RESULT_FOLDER,'rgb_mean.npy'), RGB_MEAN, )\n",
    "np.save(pjoin(RESULT_FOLDER,'rgb_std.npy'), RGB_STD, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# json.dumps(CLASS_IDX)\n",
    "# json.dumps(COLORMAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_img(f,resize=(IM_W,IM_H)):\n",
    "    return np.array(\n",
    "        Image.open(f)\\\n",
    "            .resize(size=resize,resample=Image.NEAREST )\\\n",
    "            .convert('RGB')\n",
    "        )\n",
    "\n",
    "def augmentate_data(img):\n",
    "    # randomly shift contrast\n",
    "    x = np.clip(img**np.random.uniform(0.8,1.2), 0, 255)\n",
    "    # randomly shift brightness\n",
    "    x = np.clip( x*np.random.uniform(0.5, 2.0), 0, 255)\n",
    "    return x\n",
    "\n",
    "def normalize_data(x,rgb_mean=RGB_MEAN,rgb_std=RGB_STD):\n",
    "    return (x/255.-rgb_mean)/rgb_std\n",
    "\n",
    "\n",
    "def nparray_as_tuple(x):\n",
    "    s = x.shape\n",
    "    return [ tuple(p) for p in x.reshape(s[0]*s[1],s[2])  ]\n",
    "\n",
    "def colors_as_index(x,colormap=COLORMAP):\n",
    "    s = x.shape\n",
    "    return np.array( list(map( \n",
    "        lambda c: colormap[c] if c in colormap else 0, \n",
    "        nparray_as_tuple(x) \n",
    "    ))).reshape(s[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:01<00:00, 130.81it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test_aug = np.vstack([\n",
    "        normalize_data(\n",
    "            augmentate_data(\n",
    "                load_img(pjoin(p,fi))\n",
    "            )\n",
    "        )[np.newaxis,:]\n",
    "        for p,fi in tqdm( files.query('~is_train')[['dname','fname_img']].values.tolist() )\n",
    "    ]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 256, 256, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(pjoin(RESULT_FOLDER,'x_test_aug.npy'), x_test_aug, )\n",
    "x_test_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [00:00<00:00, 382.66it/s]\n"
     ]
    }
   ],
   "source": [
    "x_test = np.vstack([\n",
    "        normalize_data( load_img(pjoin(p,fi)) )[np.newaxis,:]\n",
    "        for p,fi in tqdm( files.query('~is_train')[['dname','fname_img']].values.tolist() )\n",
    "    ]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 256, 256, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(pjoin(RESULT_FOLDER,'x_test.npy'), x_test, )\n",
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel x_test\n",
    "%xdel x_test_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [01:37<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "y_test = np.vstack([\n",
    "        colors_as_index(load_img(pjoin(p,fo)))[np.newaxis,:]\n",
    "        for p,fo in tqdm( files.query('~is_train')[['dname','fname_msk']].values.tolist() )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 256, 256)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(pjoin(RESULT_FOLDER,'y_test.npy'), y_test, )\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3335/3335 [00:21<00:00, 157.97it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train_aug = np.vstack([\n",
    "        normalize_data(\n",
    "            augmentate_data(\n",
    "                load_img(pjoin(p,fi))\n",
    "            )\n",
    "        )[np.newaxis,:]\n",
    "        for p,fi in tqdm( files.query('is_train')[['dname','fname_img']].values.tolist() )\n",
    "    ]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3335, 256, 256, 3)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(pjoin(RESULT_FOLDER,'x_train_aug.npy'), x_train_aug, )\n",
    "x_train_aug.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel x_train_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3335/3335 [00:08<00:00, 377.63it/s]\n"
     ]
    }
   ],
   "source": [
    "x_train = np.vstack([\n",
    "        normalize_data( load_img(pjoin(p,fi)) )[np.newaxis,:]\n",
    "        for p,fi in tqdm( files.query('is_train')[['dname','fname_img']].values.tolist() )\n",
    "    ]).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3335, 256, 256, 3)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(pjoin(RESULT_FOLDER,'x_train.npy'), x_train, )\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3335/3335 [25:53<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "y_train = np.vstack([\n",
    "        colors_as_index(load_img(pjoin(p,fo)))[np.newaxis,:]\n",
    "        for p,fo in tqdm( files.query('is_train')[['dname','fname_msk']].values.tolist() )\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3335, 256, 256)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.save(pjoin(RESULT_FOLDER,'y_train.npy'), y_train, )\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%xdel y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # files\n",
    "# f='data/pascal/VOC/test/VOCdevkit/VOC2007/SegmentationClass/006303.png'\n",
    "# x = load_img(f)\n",
    "\n",
    "# x.shape\n",
    "\n",
    "# from matplotlib import pyplot as plt\n",
    "# plt.imshow(xc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
